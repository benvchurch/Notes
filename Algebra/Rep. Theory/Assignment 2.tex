\documentclass[12pt]{extarticle}
\include{AlgebraCommands}

\begin{document}
\atitle{2}

\section*{Problem 1.}

Let $k$ be a field of characteristic zero. Define the subspaces,
\begin{align*}
W_1 & = \{(t, \cdots, t) \mid t \in k \} \\
W_2 & = \{(t_1, \cdots, t_n) \mid \sum_{i = 1}^n t_i = 0\}
\end{align*}
Define the map $p_1 : k^n \to W_1$ by $(t_1, \cdots, t_n) \mapsto (a(v), \cdots, a(v))$ where $a(v) = \frac{1}{n} \sum_{i = 1}^n t_n$. Clearly, $p_1$ is linear and for $(t, \cdots, t) \in W_1$ we have $a = \frac{1}{n} (nt) = t$ so $p_1(w) = (t, \cdots t)$. Finally, given any $t \in k^n$ take $v = (tn, 0, \cdots, 0) \in k^n$ then $p_1(v) = (t, \cdots, t)$ so $W_1 \subset \Im{p_1}$ but clearly $\Im{p_1} \subset W_1$ so $\Im{p_1} = W_1$. Therefore, $p_1$ is a projection map. Furthermore, $v \in \ker{p_1} \iff a(v) = 0 \iff \sum_{i = 1}^n t_i = 0$ so $\ker{p_1} = W_2$. Thus, $k^n = W_1 \oplus W_2$. \bigskip \\
Similarly, let $p_2 : k^n \to W_2$ be given by, $p_2 = \id_{k^n} - p_1$ so $p_2(t_1, \cdots, t_n) = (t_1 - a(v), \cdots, t_n - a(v))$. As we have seen on the previous homework, $p_2$ has image $W_2$ and kernel $W_1$. 

\section*{Problem 2.}

Let $v_1 \in \R^2$ be the vector $(1, -3)$ and let $L_1 = \vspan{v_1}$.

\begin{enumerate}
\item Let $v_2 \in \R^2 \sm L_1$ and $L_2 = \vspan{v_2}$. Then, because $v_2 \notin L_1$ the set $\{v_1, v_2\}$ is independent which implies that $L_1 \cap L_2 = \varnothing$. Furthermore, $\dim{\R^2} = 2$ so $\{v_1, v_2\}$ being independent is also a basis. Therefore, $L_1 + L_2 = \R^2$ so $\R^2 = L_1 \oplus L_2$. 

\item Let $v_2 = (-4, 9)$. Define $p : \R^2 \to \R^2$
such that $p(v_1) = v_1$ and $p(v_2) = 0$. The kernel of $p$ is nontrivial (since $v_2 \in \ker{p}$) but not full (because $v_1 \notin \ker{p}$). Thus $\dim{\ker{p}} = 1$. Thus, the kernel is spanned by any nonzero element. In particular, $\ker{p} = \vspan{v_2} = L_2$. Similarly, if $v \in L_1$ then $v = c v_1$ for $c \in \R$ so $p(v) = p (cv_1) = c p(v_1) = cv_1 = v$ so $p(v) = v$ on $L_1$. This shows that $L_1 \subset \Im{p}$. However, by rank-nullity, $\dim{\Im{p}} = 1$ and $\dim{L_1} = 1$ so $\Im{p} = L_1$. 
\item 
In the basis $\{v_1, v_2\}$ the matrix of $p$ satisfying $p(v_1) = v_1$ and $p(v_2) = 0$ is given by,
\[ A = 
\begin{pmatrix}
1 & 0 \\
0 & 0 
\end{pmatrix} 
\]
Now, define the change of basis matrix $C$ such that $C(e_1) = v_1$ and $C(e_2) = v_2$ i.e.
\[ C = 
\begin{pmatrix}
1 & -4 \\
-3 & 9 
\end{pmatrix} 
\quad \text{ with inverse } \quad C^{-1} = 
\begin{pmatrix}
-3 & -4/3 \\
-1 & -1/3 
\end{pmatrix} 
\]
Therefore, in the standard basis, $p$ is given by the matrix,
\[ A' = C A C^{-1} = 
\begin{pmatrix}
-3 & -4/3 \\
9 & 4
\end{pmatrix} 
\]

\item $\tr{A'} = -3 + 4 = 1$ and likewise $\tr{A} = 1 + 0 = 1$.
\end{enumerate}

\section*{Problem 3.}

Let $V$ be a $k$-vectorspace. Consider the map $\Phi : \Hom{k}{V} \to V$ given by, $\Phi(h) = h(1)$ where $h : k \to V$ is any element of $\Hom{k}{V}$. We must show that $\Phi$ is an isomorphism. First, suppose thatt $h \in \ker{\Phi}$ then $h(1) = 0$ so for any $r \in k$ we have $h(k) = h(1 \cdot k) = h(1) h(k) = 0$ so $h$ is the zero map. Thus, $\Phi$ is injective. Furthermore, for any $v \in V$ consider the map $\phi_v \in \Hom{k}{V}$ given by $\phi_v(c) = cv$. Clearly, $\phi_v$ is linear and $\Phi(\phi_v) = \phi_v(1) = v$ so $\Phi$ is surjective. Finally, for $c_1, c_2 \in k$ and $h_1, h_2 \in \Hom{k}{V}$ consider,
\[\Phi(c_1 h_1 + c_2 h_2) = (c_1 h_1 + c_2 h_2)(1) = c_1  h_1(1) + c_2 h_2(1) = c_1 \Phi(h_1) + c_2 \Phi(h_2) \]
so $\Phi$ is linear. Therefore, $\Hom{k}{V} \cong V$.\bigskip\\
Furthermore, $\{ B : k \times V \to W \mid B \: \text{ is bilinear} \} \cong \Hom{k \otimes V}{W}$ via the universal property of the tensor product. However, $k \otimes V \cong \Hom{k^*}{V} \cong \Hom{k}{V} \cong V$ were I have used the previous result and the fact that $k^*$ is naturally isomorphic to $k$ because $k$ has a natural choice of basis, namely $\{1\}$. Thus, there is a natural isomorphism,  
\[\{ B : k \times V \to W \mid B \: \text{ is bilinear} \} \cong \Hom{V}{W}\]
\section*{Problem 4.}
Let $V$ and $W$ be finite-dimensional vector spaces with bases, $v_1, \cdots, v_n$ and $w_1, \cdots, w_n$ respectively.   
\begin{enumerate}
\item Let $F : V \to W$ be a linear map with matrix $A$ such that $F(v_i) = A_{ji} w_j$. Then, consider the matrix of $F^* : W^* \to V^*$ with respect to the dual bases $v_1^*, \cdots, v_n^*$ and $w_1^*, \cdots, w_n^*$. Consider,
\[ (F^*(w_i^*))(v_k) = (w_i^* \circ F)(v_k) = w_i^*(A_{jk} w_j) = A_{jk} \delta_{ij} = A_{ik} \]
Therefore,
\[ F^*(w_i^*) = A_{ik} v^*_k = (A^\top)_{ki} v_k^*\]
so the matrix for $F^*$ is $A^\top$.

\item Let $V$ and $W$ be finite-dimensional $k$-vectorspaces. Consider the map $\Phi : \Hom{V}{W} \to \Hom{W^*}{V^*}$ given by $\Phi : F \mapsto F^*$. First, we show that $F \mapsto F^*$ is an injective linear map. This does not depend on the finite dimensional assumption. Suppose $F^*$ is the zero map. Therefore, for any $\phi \in W^*$ the map $F^*(\phi) = \phi \circ F$ is the zero map. However, there exists a $\phi$ which is nonzero on any $w \in W \sm \{0\}$. Thus, $F$ must be the zero map so $\Phi : F \mapsto F^*$ is injective. Furthermore, $\Phi(F + G) = (F + G)^*$ which is a map such that $(F + G)^*(\phi) = \phi \circ (F + G) = \phi \circ F + \phi \circ G = F^*(\phi) + G^*(\phi)$ so $(F + G)^* = F^* + G^*$. Thus, $\Phi$ is linear. \bigskip \\ 
Now, we need the fact that $V$ and $W$ are finite-dimensional. We know that $\dim{\Hom{V}{W}} = (\dim{V})(\dim{W})$ and likewise $\dim{\Hom{W^*}{V^*}} = (\dim{W^*})(\dim{V^*}) = (\dim{V})(\dim{W})$. Thus, $\dim{\Hom{W^*}{V^*}} = \dim{\Hom{V}{W}}$ so because $\Phi : \Hom{V}{W} \to \Hom{W^*}{V^*}$ is a linear injection it must also be a surjection and thus an isomorphism. 

\item For a map $F : V \to V$ we know that if the matrix of $F$ is $A$ then the matrix of $F^*$ is $A^\top$. Thus, $\tr{F^*} = \tr{A^\top} = \tr{A} = \tr{F}$. 
\end{enumerate}

\section*{Problem 5.}

Let $v_1, \cdots, v_n$ be a basis of $V_1$ and $w_1, \cdots, w_n$ be a basis of $V_2$ such that $v_i \otimes w_j$ forms a basis of $V_1 \otimes V_2$. Let $A$ be the matrix of $F_1 : V_1 \to V_1$ and $B$ the matrix of $F_2 : V_2 \to V_2$ such that (using summation convention) $F_1(v_i) = A_{ji}v_j$ and $F_2(w_i) = B_{ji}(w_i)$. Then, 
\[(F_1 \otimes F_2)(v_i \otimes w_j) = F_1(v_i) \otimes F_2(w_j) = (A_{ai} v_a) \otimes (B_{bj} v_b) = \sum_{a, b} A_{ai} B_{bj} v_a \otimes v_b\]
Therefore, the matrix of $F_1 \otimes F_2$ is $A_{ai}B_{bj}$. Thus, 
\[ \tr{F_1 \otimes F_2} = \sum_{a,b} A_{aa}B_{bb} = \sum_{a = 1}^n A_{aa} \sum_{b = 1}^n B_{bb} = (\tr{F_1}) (\tr{F_2}) \] 
\bigskip \\
Similarly, let $F_1 : V_1 \to V_1$ and $F_2 : V_2 \to V_2$ be linear. Consider the linear map $(F_2)_* \circ (F_1)^* : \Hom{V_1}{V_2} \to \Hom{V_1}{V_2}$. A basis for $\Hom{V_1}{V_2}$ can be written as $v_i^* w_j$ where $v_i^*$ is an element of the dual basis and $(v_i^* w_j)(v) = v_i^*(v) \cdot w_j$. Thus,
\begin{align*}
((F_2)_* \circ (F_1)^*)(v_i^* w_j)(v_l) & = (F_2)_*(v_i^* w_j \circ F_1)(v_l) = F_2 \circ (v_i^* w_j) \circ F_1(v_l) = F_2(v_i^*(A_{al} v_a) w_j) 
\\
& = F_2(A_{al} v_i^*(v_a) w_j) = A_{al} F_2(\delta_{ia} w_j) = A_{il} B_{rj}w_r 
\end{align*}
Therefore,
\[ ((F_2)_* \circ (F_1)^*)(v_i^* w_j) = A_{il} B_{rj} v^*_l w_r\]
so the trace becomes,
\[ \tr{ ((F_2)_* \circ (F_1)^*) } = \sum_{i, j} A_{ii} B_{jj} = \sum_{i = 1}^{n} A_{ii} \sum_{j = 1}^n B_{jj} = (\tr{F_1}) (\tr{F_2}) \] 

\section*{Problem 6.}

Let $A \in GL(n, \C)$ be diagonalizable. Suppose that every eigenvalue of $A$ has absolute value $1$ then $\lambda^{-1} = \bar{\lambda}$. However, since $A$ is diagonalizable, $\tr{A} = \sum_{i = 1}^n \lambda_i$ counting multiplicity if necessary. However, if $A v = \lambda v$ then $A^{-1} \lambda v = v$ so $A^{-1} v = \frac{1}{\lambda}v$ and visa versa. Thus, the eigenvalues of $A^{-1}$ are exactly one over the eigenvalues of $A$. Therefore, 
\[\tr{A^{-1}} = \sum_{i = 1}^n \frac{1}{\lambda_i} = \sum_{i = 1}^n \bar{\lambda_i} = \overline{\tr{A}}\]

\section*{Problem 7.}
Let $A : \R^n \to \R^n$ be an invertivle matrix. Then, consider $(A A^{-1})^\top = (A^{-1})^\top A^\top = I^\top = I$ and $(A^{-1} A)^\top = A^\top (A^{-1})^\top = I^\top = I$. Therefore, $(A^{-1})^\top$ is an inverse of $A^\top$. By the uniqueness of inverses, $(A^{-1})^\top = (A^\top)^{-1}$. 
\section*{Lemmas}


\end{document}