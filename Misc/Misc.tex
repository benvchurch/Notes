\documentclass[12pt]{extarticle}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[a4paper, total={6in, 9in}]{geometry}
\usepackage{tikz-cd}
 
\usepackage{amsthm, amssymb, amsmath, centernot}
\usepackage{revsymb}
\usepackage{xspace}
\usepackage{hyperref}

\usepackage{calligra,mathrsfs}
\DeclareMathOperator{\calHom}{\mathscr{H}\text{\kern -3pt {\calligra\large om}}}
\DeclareMathOperator{\calExt}{\mathscr{E}\text{\kern -3pt {\calligra\large xt}}}
\DeclareMathOperator{\calTor}{\mathscr{T}\text{\kern -3pt {\calligra\large or}}}
\DeclareMathOperator{\calEnd}{\mathscr{E}\text{\kern -3pt {\calligra\large nd}}}
\DeclareMathOperator{\calDer}{\mathscr{D}\text{\kern -3pt {\calligra\large er}}}


\newcommand{\shHom}[3]{\calHom_{#1} \! \left( #2, #3 \right)}
\newcommand{\shExt}[4]{\calExt^{\: \: \: #1}_{#2}\left( #3, #4 \right)}
\newcommand{\shTor}[4]{\calTor^{\: \: \: #1}_{#2}\left( #3, #4 \right)}
\newcommand{\shEnd}[2]{\calEnd_{#1} \! \left( #2 \right)}
\newcommand{\shDer}[2]{\calDer\left( #1, #2 \right)}
\newcommand{\Hom}[3]{\mathrm{Hom}_{#1}\left( #2, #3 \right)}

\DeclareMathOperator{\im}{\mathrm{Im}}

\newcommand{\T}{\mathscr{T}}

\newcommand{\notimplies}{%
  \mathrel{{\ooalign{\hidewidth$\not\phantom{=}$\hidewidth\cr$\implies$}}}}
 
\renewcommand\qedsymbol{$\square$}
\newcommand{\cont}{$\boxtimes$}
\newcommand{\divides}{\mid}
\newcommand{\ndivides}{\centernot \mid}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Zplus}{\mathbb{Z}^{+}}
\newcommand{\Primes}{\mathbb{P}}

\DeclareMathOperator{\colim}{\mathrm{colim}}

\newcommand{\Ob}[1]{\mathrm{Ob}(#1)}
\newcommand{\cat}[1]{\mathcal{#1}}
\newcommand{\id}{\mathrm{id}}
\newcommand{\catHom}[3]{\mathrm{Hom}_{#1}\left( #2, #3 \right)}
\newcommand{\End}[1]{\mathrm{End}\left(#1\right)}
\newcommand{\Top}{\mathbf{Top}}
\newcommand{\pTop}{\mathbf{Top}_{\bullet}}
\newcommand{\Set}{\mathbf{Set}}
\newcommand{\pSet}{\mathbf{Set}_\bullet}
\newcommand{\hTop}{\mathbf{hTop}}
\newcommand{\phTop}{\mathbf{hTop}_{\bullet}}
\renewcommand{\Im}[1]{\mathrm{Im}(#1)}
\newcommand{\homspace}[2]{\left< #1, #2 \right>}
\newcommand{\rp}{\mathbb{RP}}
\newcommand{\coker}[1]{\mathrm{coker}\: #1}

\renewcommand{\d}[1]{ \mathrm{d}#1 \:}
\newcommand{\dn}[2]{ \mathrm{d}^{#1} #2 \:}
\newcommand{\deriv}[2]{\frac{\d{#1}}{\d{#2}}}
\newcommand{\nderiv}[3]{\frac{\dn{#1}{#2}}{\d{#3^{#1}}}}
\newcommand{\pderiv}[2]{\frac{\partial{#1}}{\partial{#2}}}
\newcommand{\npar}[3]{\frac{\partial^{#1}{#2}}{\partial{#3}^{#1}}}
\newcommand{\fderiv}[2]{\frac{\delta #1}{\delta #2}}

\theoremstyle{definition}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{example}[theorem]{Example}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{remark}{Remark}
\newtheorem{question}[theorem]{QUESTION}

\newenvironment{definition}[1][Definition:]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}


\newenvironment{lproof}{\begin{proof} \renewcommand{\qedsymbol}{}}{\end{proof}}
\renewcommand{\mod}[3]{\: #1 \equiv #2 \: mod \: #3 \:}
\newcommand{\nmod}[3]{\: #1 \centernot \equiv #2 \: mod \: #3 \:}
\newcommand{\ndiv}{\hspace{-4pt}\not \divides \hspace{2pt}}
\newcommand{\gen}[1]{\langle #1 \rangle}
\newcommand{\hook}{\hookrightarrow}
\newcommand{\Tor}[4]{\mathrm{Tor}^{#1}_{#2} \left( #3, #4 \right)}
\newcommand{\Ext}[4]{\mathrm{Ext}^{#1}_{#2} \left( #3, #4 \right)}

\tikzset{
    labl/.style={anchor=south, rotate=90, inner sep=.5mm}
}

\renewcommand{\bf}[1]{\mathbf{#1}}
\newcommand{\res}{\mathrm{res}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\G}{\mathcal{G}}
\renewcommand{\O}{\mathcal{O}}
\newcommand{\m}{\mathfrak{m}}

\newcommand{\GL}[1]{\mathrm{GL}\left(#1\right)}
\newcommand{\SL}[1]{\mathrm{SL}\left(#1\right)}
\newcommand{\PGL}[1]{\mathrm{PGL}\left(#1\right)}
\newcommand{\PSL}[1]{\mathrm{PSL}\left(#1\right)}

\newcommand{\Orth}[1]{\mathrm{O}\left(#1\right)}
\newcommand{\U}[1]{\mathrm{U}\left(#1\right)}
\newcommand{\SO}[1]{\mathrm{SO}\left(#1\right)}
\newcommand{\SU}[1]{\mathrm{SU}\left(#1\right)}
\newcommand{\g}{\mathfrak{g}}
\newcommand{\h}{\mathfrak{h}}
\newcommand{\gl}[1]{\mathfrak{gl}\left(#1\right)}
\newcommand{\Lie}[1]{\mathrm{Lie}\left(#1 \right)}
\newcommand{\Aut}[1]{\mathrm{Aut}\left(#1 \right)}

\newcommand{\C}{\mathbb{C}}
\renewcommand{\H}{\mathbb{H}}
\newcommand{\Hil}{\mathcal{H}}
\newcommand{\inner}[2]{\left< #1, #2 \right>}
\renewcommand{\P}{\mathbb{P}}
\newcommand{\PAU}[1]{\mathrm{PAU}\left( #1 \right)}
\newcommand{\CP}{\mathbb{CP}}
\newcommand{\Cl}{\mathrm{C} \ell}
\newcommand{\fchar}[1]{\mathrm{char}(#1)}

\newcommand{\sm}{\! \setminus \!}
\renewcommand{\empty}{\varnothing}
\newcommand{\embed}{\hookrightarrow}
\newcommand{\onto}{\twoheadrightarrow}
\newcommand{\ad}{\mathrm{ad}}
\newcommand{\Gm}{\mathbb{G}_m}
\newcommand{\A}{\mathbb{A}}

\begin{document}

\tableofcontents

\section{Thoughts On Uniformization}

\renewcommand{\Im}[1]{\mathfrak{Im} \left[ #1 \right]}
\renewcommand{\Re}[1]{\mathfrak{Re} \left[ #1 \right]}


\begin{theorem}
Every simply-connected Riemann surface is biholomorphic to exactly one of,
\begin{enumerate}
\item $\C$ the complex plane
\item $\h$ the upper half-plane
\item $\hat{\C}$ the Riemann sphere
\end{enumerate}
\end{theorem}

\begin{remark}
Let's give some examples of this theorem.
\end{remark}

\begin{proposition}
There does not exist a surjective holomorphic map $f : \C \to \h$. In particular $\C$ and $\h$ cannot be biholomorphic.
\end{proposition}

\begin{proof}
Given a map $f : \C \to \h$, consider $\exp{(i f)} : \C \to \C$ which is holomorphic and bounded since,
\[ | e^{if(z)}| = e^{-\Im{f(z)}} < 1 \]
since $f : \C \to \h$ implies that $\Im{f(z)} > 0$. By Liouville's theorem, this implies that $\exp{(if)}$ is constant and thus so is $f : \C \to \h$. 
\end{proof}

\begin{remark}
Since $\hat{\C}$ is the only of the three which is compact this proves that all three lie in distict biholomorphism classes.
\end{remark}

\begin{example}
An open wedge,
\[ W_\alpha = \{ r e^{i \theta} \in \C \mid r > 0 \text{ and } \theta \in (0, \alpha) \} \]
is biholomorphic to the upper half plane via $z \mapsto z^{\pi /\alpha} = \exp{(\pi / \alpha \log{z})}$ which is well-defined on $W_\alpha$ since it contains no loops about hte origin.  
\end{example}

\begin{example}
The open unit disc $D \subset \C$ is biholomorphic to $\h$ via the map $g : D \to \h$ defined as,
\[ g(z) = i \frac{1 + z}{1 - z} \]
First, note that $g$ is holomorphic on $D$ since it does not contain $1$. Furthermore, 
\[ g(z) = i \frac{(1 + z)(1 - \bar{z})}{|1 - z|^2} = i \frac{1 + z - \bar{z} - |z|^2}{|1 - z|^2} = - \frac{2 \Im{z}}{|1 - z|^2} + i \frac{1 - |z|^2}{|1 - z|^2} \]
Since $|z|^2 < 1$ we have $\Im{g(z)} > 0$. Furthermore, notice that,
\[ g^{-1}(z) = \frac{z - i}{z + i} \] 
is holomorphic everywhere on $\h$ since it does not include $-i$ so $g$ is a biholomorphism. 
\end{example}

\begin{example}
There are many non-simply connected non-biholomorphic Riemann surfaces (for example there are uncountably many innequivalent complex torii). Another cute example is $X = \C \setminus \{ 0 \}$ and $\C \setminus \overline{D}$. These cannot be biholomorphic since $Y$ admits a nonconstant bounded holomorphic function, $z^{-1}$, however I claim that $X$ does not. To see this, consider bounded holomorphic $f : X \to \C$. By Riemann, if we view $f : \C \to \C$ it has at worst a removable singularity at $z = 0$ and thus extends to a holomorphic function $\tilde{f} : \C \to \C$ which is bounded. By Liouville, $\tilde{f}$ and consequently $f$ are bounded. 
\end{example}

\section{The Only Commpact Connected Complex Lie Groups are Tori}

\begin{theorem}
Every compact connected complex lie group is isomorphic to $\C^g / \Lambda$ where $\Lambda$ is a lattice in $\C^g$. 
\end{theorem}

\newcommand{\Ad}{\mathrm{Ad}}

\begin{proof}
Let $G$ be a compact conected complex lie group of dimension $g$. Consider the adoint action $\Ad : G \to \GL{\g}$ which is a map of complex lie groups and, in particular, is holomorphic. Since $G$ is compact $Ad(G)$ is compact and thus closed but, assuming $\Ad$ is nonconstant, $\Ad(G)$ is open by the open mapping theorem so $\Ad(G)$ is the maximal connected component of $\GL{\g}$ which contains the matricies $\lambda \id$ for any $\lambda \in \C$ so the map $\det \circ \Ad : G \to \R$ is surjective contradicitng the compactness of $G$. Therefore $\Ad$ must be constant and since $\Ad(e) = I$ it must send $g \to I$. Therefore $g \cdot \xi \cdot g^{-1} = \xi$ for all $\xi \in \g$ and $g \in G$ which implies that $\forall X, Y \in \g : [X, Y] = 0$ (note that $\mathrm{ad} = \d{\Ad}$ and $\mathrm{ad}_\xi(X) = [\xi, X] = 0$) so the Lie algebra is abelian. Thus, the idenity map $\id : \g \to \g$ lifts to a covering map $\C^g \to G$ which implies that $\C^g / \Lambda = G$ where $\Lambda = G$ is a discrete subgroup of full rank since $G$ is compact. 
\end{proof}

\section{$G$-Structures on Manifolds}

\newcommand{\proj}{\mathrm{proj}}

\begin{definition}
Let $M$ be a smooth $n$-manifold and $\pi_E : E \to M$ be a rank $k$ vector bundle. Then the frame bundle $\pi_F : F(E) \to M$ is the principal $\GL{k}$-bundle of frames $F_x$, which are linear isomorphisms $p : \R^k \to E_x$. Then,
\[ F(E) = \coprod_{x \in M} F_x \]
Choosing local trivializations of $E$,
\begin{center}
\begin{tikzcd}
\pi_E^{-1}(U_\alpha) \arrow[dr, "\pi_E"] \arrow[rr, "\varphi_\alpha"] &  & U_\alpha \times V \arrow[dl, "\proj_1"]
\\
& U_\alpha 
\end{tikzcd}
\end{center}
Then we impose a toplogy and smooth structure on $F(E)$ via a smooth local trivialization,
\begin{center}
\begin{tikzcd}
\pi_F^{-1}(U_\alpha) \arrow[dr, "\pi_F"] \arrow[rr, "\tilde{\varphi}_\alpha"] &  & U_\alpha \times \GL{k} \arrow[dl, "\proj_1"]
\\
& U_\alpha 
\end{tikzcd}
\end{center}
where $\tilde{\varphi}_\alpha(x, p) = (x, \varphi_{\alpha, x} \circ p)$ where $\varphi_{\alpha, x} : E_x \to \R^k$ is given by $\proj_2 \circ \varphi_\alpha(x, -)$. 
\end{definition}

\begin{definition}
In particular, for $E = TM$ the corresponding frame bundle $F_{M} = F_{TM}$ is called the frame bundle of $M$. For charts $(U_\alpha, \varphi_\alpha)$ on $M$ we can form corresponding charts $(\tilde{U}_\alpha, \tilde{\varphi}_\alpha)$ on $TM$ via,
\[ \tilde{\varphi}_\alpha^{-1} : \varphi_\alpha(U_\alpha) \times \R^n \to TM \quad \quad \quad \tilde{\varphi}_\alpha^{-1}(x, v) = (\varphi_\alpha^{-1}(x), \d{\varphi}_\alpha^{-1}(v)) \]
which form a local trivialization of $TM$ over $U_\alpha$. 
Then the frame bundle has a local trivialization given by,
\begin{center}
\begin{tikzcd}
\pi_F^{-1}(U_\alpha) \arrow[dr, "\pi_F"] \arrow[rr, "\tilde{\varphi}_\alpha"] &  & U_\alpha \times \GL{n} \arrow[dl, "\proj_1"]
\\
& U_\alpha 
\end{tikzcd}
\end{center}
where $\tilde{\varphi}_\alpha(x, p) = (x, \d{\varphi}_\alpha \circ p)$. 
\end{definition}

\begin{definition}
Given a principal $G$ bundle $\pi_P : P \to X$, a \textit{reduction of the structure group} via $\phi : H \to G$ is the princple $H$-bundle $\pi_Q : Q \to X$ and an $G$-isomorphism $\psi_Q : Q \times_\phi G \to P$ of principal bundles. 
\end{definition}

\begin{proposition}
Given $\phi : H \to G$ then any equivariant map of principal bundles $f : Q \to P$ over $X$ induces an isomorphism $f : Q \times_\phi G \to P$.
\end{proposition}

\begin{proof}
Consider the map $f([q, g]) = f(q) \cdot g$ which is an equivariant morphism of bundles over $X$ since,
\[ f([q, g] \cdot \tilde{g}) = f([q, g \tilde{g}]) = f(q) \cdot (g\tilde{g}) = (f(q) \cdot g) \cdot \tilde{g} = f([q, g]) \cdot \tilde{g} \]
Furthermore, this map is well-defined since $[q, \phi(h) g] = [q \cdot h, g]$ and
\[ f([q \cdot h, g]) = f(q \cdot h) \cdot g = f(q) \cdot (\phi(h)g) = f([q, \phi(h)g]) \]
It remains to show that this map is an isomorphism.  First, suppose that,
\[ f([q_1, g_1]) = f([q_2, g_2]) \]
Since $Q$ is a principal bundle, $\exists ! h \in H : q_2 = q_1 \cdot h$ so $[q_2, g_2] = [q_1, \phi(h) g_2]$. Then, we know that,
\[ f(q_1) \cdot g_1 = f(q_1) \cdot (\phi(h) g_2) \]
However, $G$ acts freely on the fibers so $g_1 = \phi(h) g_2$. Therfore, 
\[ [q_1, g_1] = [q_1, \phi(h) g_2] = [q_2, g_2] \]
 so $f$ is injective. Finally, since $G$ acts transitively on fibers so for any $x \in X$ choose a lift $q_x \in Q$ then the entire fiber $\pi_P^{-1}(x)$ is in the image of $f([q_x, g]) = f(q_x) \cdot g$ since this action is transitive. 
\end{proof}

\begin{corollary}
Isomorphisms of principal bundles $f : Q \times_\phi G \to P$ are equivalent to equivariant morphisms $f : Q \to P$.
\end{corollary}

\begin{proof}
We have proven that a morphism $f : Q \to P$ induces an isomorphism $f : Q \times_\phi G \to P$. Conversely, if $f : Q \times_\phi G \to P$ is an isomorphism of principal bundles then consider the map $\iota : Q \to Q \times_\phi G$ via $\iota(q) = [q, e]$. This map is equivariant since,
\[ \iota(q \cdot h) = [q \cdot h, e] = [q, \phi(h)] = [q, e] \cdot \phi(h) = \iota(q) \cdot \phi(g) \]
Then $f \circ \iota : Q \to P$ is equivariant.
\end{proof}

\begin{definition}
Consider a smooth $n$-manifold $M$ with frame bundle $\pi_F : F \to M$. For a Lie group $G$ and a $G$-representation $\rho : G \to \GL{n}$, a $G$-structure on $F$ is a reduction via $\rho$ of $\pi_F : F \to M$ to a principal $G$-bundle $\pi_P : P \to M$.   
\end{definition}

\begin{remark}
If $\iota : G \to \GL{n}$ is the inclusion of a Lie subgroup $G \subset \GL{n}$ (equivalently $\iota$ is the fundamental representation) then a $G$-structure on $M$ is simply a principal $G$-bundle $\pi_G : F_G \to M$ which is an equivariant subbundle $\iota : F_G \to F$ of the frame bundle. 
\end{remark}

\begin{proposition}
A $\SL{n}$-structure on $M$ is equivalent to a choice of volume form. 
\end{proposition}

\begin{proof}
Given a volume form $\omega \in \Omega^n(M)$ define the bundle $F_{SL}$ of frames pulling back $\omega$ to the standard volume form on $\R^n$ i.e. 
\[ F_{SL} = \{ (x, p) \in F_{GL} \mid p^*(\omega) = e^1 \wedge \cdots \wedge e^n \} \]
This is a principal $\SL{n}$-bundle since for $g \in \SL{n}$ we have,
\[ (p \circ g)^*(\omega) = g^* \circ p^*(\omega) = g^*(e^1 \wedge \cdots \wedge e^n) = (\det{g}) \: e^1 \wedge \cdots \wedge e^n = e^1 \wedge \cdots \wedge e^n \]
and furthermore, $\SL{n}$ acts freely on $\GL{n}$-torsors and transitively since it contains every volume preserving linear isomorphism. 
\bigskip\\
Conversely, given an $\SL{n}$-sturcture, $\iota : F_{SL} \to F_{M}$ we may construct a volume form $\omega \in \Omega^n(M)$ via, $\omega_x = (p^{-1})^*(e^1 \wedge \cdots \wedge e^n)$ for any $p \in \iota(\pi_{SL}^{-1}(x))$. This is well-defined becuase, since the action of $\SL{n}$ is transitive on fibers of $F_{SL}$, any other lift is $p \circ g$ for $g \in \SL{n}$ and,
\[ ((p \circ g)^{-1})^*(e^1, \dots, e^n) = (p^{-1})^* \circ (g^{-1})^*(e^1 \wedge \dots \wedge e^n) = (p^{-1})^*(e^1 \wedge \dots \wedge e^n) \]
since $\deg{g^{-1}} = 1$. Furthermore, this form is nonvanishing since $\det{p^{-1}} \neq 0$ since $p : \R^n \to T_x M$ is an isomorphism. 
\end{proof}



\begin{proposition}
A $\Orth{n}$-structure on $M$ is equivalent to a choice of Riemannian metric. 
\end{proposition}

\begin{proof}
Given a metric $g \in \mathrm{Sym}^2(T^*M)$ define the bundle $F_{O}$ of frames pulling back $g$ to the standard metric form on $\R^n$ i.e. 
\[ F_{O} = \{ (x, p) \in F_{GL} \mid p^*(g) = e^1 \otimes e^1 + \cdots + e^n \otimes e^n \} \]
This is a principal $\O{n}$-bundle since for $q \in \Orth{n}$ we have,
\[ (p \circ q)^*(g) = q^* \circ p^*(g) = q^*(e^1 \otimes e^1 + \cdots + e^n \otimes e^n) = e^1 \otimes e^1 + \cdots + e^n \otimes e^n \]
since $q$ is orthogonal. Furthermore, $\O{n}$ acts freely on $\GL{n}$-torsors and transitively since it contains every linear isometry. 
\bigskip\\
Conversely, given an $\Orth{n}{n}$-sturcture, $\iota: F_{O} \subset F_{M}$ we may construct a metric $g \in \mathrm{Sym}^2(T^*M)$ via, $g_x = (p^{-1})^*(e^1 \otimes e^1 + \cdots + e^n \otimes e^n)$ for any $p \in \iota(\pi_{SL}^{-1}(x))$. This is well-defined becuase, since the action of $\Orth{n}{n}$ is transitive on fibers of $F_{O}$, any other lift is $p \circ q$ for $q \in \Orth{n}$ and,
\begin{align*}
((p \circ q)^{-1})^*(e^1 \otimes e^1 + \cdots + e^n \otimes e^n) & = (p^{-1})^* \circ (q^{-1})^*(e^1 \otimes e^1 + \cdots + e^n \otimes e^n) 
\\
& = (p^{-1})^*(e^1 \otimes e^1 + \cdots + e^n \otimes e^n)
\end{align*}
since $q$ is orthogonal. Furthermore, this form is nonvanishing since $\det{p^{-1}} \neq 0$ since $p : \R^n \to T_x M$ is an isomorphism. 
\end{proof}

\section{Ideas for Splash}

\subsection{Actually, Homology is just the Euler Characteristic but More}

\subsection{Intersection Numbers: The Nonsense Begins}

\subsection{Poincare-Hopf: a Treatice of Pictorial Handwavery}

\subsection{The Hairy Ball Theorem}

\subsection{Complex Geometry 101: why is everything so Rigid?}

\subsection{Please Don't Tell Me You're Going to Talk About Schemes!?}

\section{Why Schemes, Why Sheaves}

\begin{remark}
All maps $\mathrm{Spec}{\C[z]} \to \mathrm{Spec}{\C[z]}$ are given by $z \mapsto p(z)$ where $p \in \C[z]$ is a polynomial and on the tangent space via the derivative $1 \mapsto p(\mu)$ at $T_\mu$. 
\end{remark}

\section{Traffic}

Consider a compressible fluid in 1D with $v = c(\rho_{\text{crit.}} - \rho)$. Via the continuity equation,
\[ \pderiv{\rho}{t} + \pderiv{v \rho}{x} = 0 \]
which implies that,
\[ \pderiv{\rho}{t} + v \pderiv{\rho}{x} + \rho \pderiv{v}{x} = \pderiv{\rho}{t} + c(\rho_{\text{crit}.} - \rho) \pderiv{\rho}{x} - c \rho \pderiv{\rho}{x} = 0 \]
Therefore,
\[ \pderiv{\rho}{t} + c(\rho_{\text{crit}.} - 2 \rho) \pderiv{\rho}{x} = 0 \]
For perturbations about a fixed density $\rho(t,x) = \rho_0 + \epsilon(t, x)$. Then we find,
\[ \pderiv{\epsilon}{t} + c(\rho_{\text{crit}.} - 2 \rho_0 ) \pderiv{\epsilon(t, x)}{x} = 0 \]
This is a left-traveling wave equation solved by,
\[ \epsilon(t, x) = \epsilon_0(x - c_{\text{eff}} t ) \]
where the effective sound speed is,
\[ c_{\text{eff}} = c(\rho_{\text{crit}.} - 2 \rho_0) \] 


\section{Gases}

Consider adiabatic expansion,
\[ \d{U} = - P \d{V} \]
with equation of state,
\[ PV = (\gamma - 1) U \]
and $N kT = (\gamma - 1) U$.
Then, consider,
\[ P \d{V} + V \d{P} +  (\gamma - 1) P \d{V} = 0 \]
Therefore, 
\[ V \d{P} + \gamma P \d{V} = 0 \]
which implies that,
\[ PV^\gamma = C \]
Furthermore, for constant volume process, $\d{U} = \d{Q}$ and thus,
\[ C_V = \pderiv{Q}{T} \bigg|_V  = \frac{N k}{\gamma - 1}  \]
For isobaric processes, $\d{U} = \d{Q} - P \d{V}$ and,
\[ P \d{V} = (\gamma - 1) \d{U} \]
which implies that $\d{Q} = \gamma \d{U}$ and thus, 
\[ C_P = \pderiv{Q}{T} \bigg|_P = \frac{\gamma N k}{\gamma - 1} \]
Therefore,
\[ \gamma = C_P / C_V \]



\section{Radiation}

\subsection{The Wave Equations}

We start with Maxwell's equations,
\begin{align*}
\nabla \cdot E & = \rho
\\
\nabla \cdot B & = 0
\\
\nabla \times E & = - \frac{1}{c} \pderiv{B}{t}
\\
\nabla \times B &= \frac{1}{c} J + \frac{1}{c} \pderiv{E}{t}
\end{align*}

\subsection{The Wave Equations for Fields}

Now consider,
\begin{align*}
\nabla \times (\nabla \times E) = - \frac{1}{c} \pderiv{}{t} (\nabla \times B) = - \frac{1}{c^2} \pderiv{J}{t} - \frac{1}{c^2} \npar{2}{E}{t}
\end{align*}
Furthermore,
\[ \nabla \times (\nabla \times E) = \nabla (\nabla \cdot E) - \nabla^2 E = \nabla \rho - \nabla^2 E \]
Therefore,
\[ \nabla^2 E  - \frac{1}{c^2} \npar{2}{E}{t} = \nabla \rho + \frac{1}{c^2} \pderiv{J}{t} \] 
Likewise,
\begin{align*}
\nabla \times (\nabla \times B) = \frac{1}{c} \nabla \times J + \frac{1}{c} \pderiv{}{t} (\nabla \times E) = \frac{1}{c} \nabla \times J - \frac{1}{c^2} \npar{2}{B}{t} 
\end{align*}
Furthermore, 
\[ \nabla \times (\nabla \times B) = \nabla (\nabla \cdot B) - \nabla^2 B = - \nabla^2 B \]
and thus we find the wave equation,
\[ \nabla^2 B - \frac{1}{c^2} \npar{2}{B}{t} = - \frac{1}{c} (\nabla \times J) \]

\subsection{The Wave Equations for Potentials}

Notice that $\nabla \cdot B = 0$ implies that $B = \nabla \times A$ for some vector field $A$. Therefore,
\[ \nabla \times E + \frac{1}{c} \nabla \times \pderiv{A}{t} = 0 \]
which implies that,
\[ E + \frac{1}{c} \pderiv{A}{t} = - \nabla \phi \]
for some scalar field $\phi$. 
Therefore, plugging in, we have,
\begin{align*}
\nabla \cdot \left(\nabla \phi + \frac{1}{c} \pderiv{A}{t} \right) & = - \rho
\\
\nabla \times (\nabla \times A) + \frac{1}{c} \left( \nabla \pderiv{\phi}{t} + \frac{1}{c} \pderiv{A}{t} \right) & = \frac{1}{c} J 
\end{align*}
We can simplify these equations using,
\[ \nabla \times (\nabla \times A) = \nabla (\nabla \cdot A) - \nabla^2 A \]
to give,
\begin{align*}
\nabla^2 \phi + \frac{1}{c} \pderiv{}{t} \nabla \cdot A & = - \rho 
\\
\frac{1}{c^2} \npar{2}{A}{t}  - \nabla^2 A + \nabla \left( \nabla \cdot A + \frac{1}{c} \pderiv{\phi}{t} \right) & = \frac{1}{c} J 
\end{align*}
Now we choose the Lorentz gauge,
\[ \nabla \cdot A + \frac{1}{c} \pderiv{\phi}{t} = 0 \]
which vastly simplifies the equations to give,
\begin{align*}
\frac{1}{c^2} \npar{2}{}{t} \phi - \nabla^2 \phi  & = \rho 
\\
\frac{1}{c^2} \npar{2}{}{t} A - \nabla^2 A & = \frac{1}{c} J 
\end{align*}

\subsection{Radial Solution to the Wave Equation}

We consider the multipole expansion of a charge distribution at the origin. For simplicitly we will only consider the first two moments $Q$ and $p$. As the charge distribution moves, $Q$ is fixed so only $p$ changes. Then we have,
\[ J = \dot{p} \delta^3(\vec{r}) \]
Now we consider the solution to this radial problem. We suppose that $A(\vec{r}, t) = A(r, t)$ is a function of only $r$ and $t$. Then we know that,
\[ \nabla^2 = \frac{1}{r} \npar{2}{}{r} r \]
so the radial equation becomes,
\[ \frac{1}{c^2} \npar{2}{}{t} (rA) - \npar{2}{}{r} (rA) = \frac{r}{c} J \]
This has a solution,
\[ A(r,t) = \frac{f(t - r/c)}{4 \pi r} \]
which satisfies the wave equation away from the origin and to fix e behavior at $r = 0$ we can calculate,
\[ \int_{B^3} \left[ \frac{1}{c^2} \npar{2}{}{t} A - \nabla^2 A \right] \d{V} = \frac{1}{c} \int_{B^3} J \: \d{V} = \frac{\dot{p}}{c} \]
We know that the lefthand side vanishes everywhere except $r = 0$ so we may integrate over vanishingly small radius but the first term
\[ \int_{B^3} \frac{1}{c^2} \npar{2}{}{t} A \: \d{V} = \int_0^r \frac{1}{c^2} \npar{2}{}{t} \frac{f(t - r/c)}{4 \pi r c} 4 \pi r^2 \d{r} = \int_0^r \frac{1}{c^2} \npar{2}{}{t} f(t - r/c) \frac{r}{c} \d{r}  \xrightarrow{r \to 0} 0 \]
Thus the left hand side becomes,
\[ - \lim_{r \to 0} \int_{B^3} \nabla^2 A_i \: \d{V} = - \lim_{r \to 0}  \int_{B^3} \nabla \cdot (\nabla A_i) \: \d{V} = - \lim_{r \to 0} \int_{S^2} \nabla A_i \cdot \d{A} \]
Now we compute,
\[ \nabla A_i = \frac{f_i'(t - r/c)}{4 \pi r} (- \frac{\vec{r}}{rc}) - \frac{f_i(t - r/c)}{4 \pi r^3} \vec{r} \]
And thus,
\begin{align*}
- \lim_{r \to 0} & = \int_{S^2} \left[ \frac{f_i'(t - r/c)}{4 \pi r} (- \frac{\vec{r}}{rc}) - \frac{f_i(t - r/c)}{4 \pi r^3} \vec{r} \right]  \cdot \d{A} 
\\
& = - \lim_{r \to 0} = \left[ \frac{f_i'(t - r/c)}{4 \pi r} (- \frac{\vec{r}}{rc}) - \frac{f_i(t - r/c)}{4 \pi r^3} \vec{r} \right]  4 \pi r^2
\\
& = \lim_{r \to 0} [ r f_i'(t - r/c) + f_i(t - r / c) ] = f_i(t) 
\end{align*}
Therefore, we find that,
\[ f(t) = \frac{\dot{p}(t)}{c} \]
which means that our solution is,
\[ A(r, t) = \frac{\dot{p}(t - r/c)}{4 \pi r c} \]

\subsection{Computing the Scalar Potential}

Now we must introduce a scalar potential to ensure the Lorentz gauge condition,
\[ \nabla \cdot A + \frac{1}{c} \pderiv{}{t} \phi = 0 \]
First we need to compute the divergence,
\begin{align*}
\nabla \cdot A & = \partial_i \frac{\dot{p}_i(t - r /c)}{4 \pi r c} =  - \frac{\dot{p}_i(t - r /c)}{4 \pi r^3 c} x_i + \frac{\ddot{p}(t - r/c)}{4 \pi r c} \left( - \frac{x_i}{rc} \right) = - \frac{\vec{r} \cdot \dot{p}}{4 \pi r^3 c}  - \frac{\vec{r} \cdot \ddot{p}}{4 \pi r^2 c^2} 
\end{align*}
Therfore, we immediately see that if we set,
\[ \phi = \frac{Q}{4 \pi r} + \frac{\vec{r} \cdot p}{4\pi r^3}  + \frac{\vec{r} \cdot \dot{p}}{4 \pi r^2 c} = \frac{Q}{4 \pi r} + \frac{\vec{r}}{4 \pi r^3} \cdot \left( p + \frac{r}{c} \dot{p} \right)  \]
then the Lorentz gauge will be satisfied. We need to verfiy that this satisfies this solution for $\phi$ satisfies the wave equation. Suppose that $\dot{p}$ is constant then we can expand,
\[ p(t - r/c) = p(t) - \frac{r}{c} \dot{p}(t) \]
so we have,
\[ \tilde{p}(r, t - r/c) = p(r - r/c) + \frac{r}{c} \dot{p}(r - r/c) = p(t) \]
Therefore, in this case the potential satisfies the Poisson equation,
\[ - \nabla^2 \phi = \rho \]
at all times since $\tilde{p}(r, t - r/c)$ is independent of position. Furthermore, note that,
\[ \partial_i \tilde{p} = \partial_i \left( p + \frac{r}{c} \dot{p} \right) = - \frac{x_i}{rc} \dot{p} + \frac{x_i}{rc} \dot{p} - \frac{r}{c} \ddot{p} \frac{x_i}{rc} = - \frac{x_i}{c^2} \ddot{p} \]
Consider, 
\[ W = \left( \frac{1}{c^2} \npar{2}{}{t} - \nabla^2 \right) \phi - \rho \]
which expands to
\begin{align*}
W & = \frac{1}{c^2} \frac{\vec{r}}{4 \pi r^3} \cdot \ddot{\tilde{p}} - \partial_i \left( \partial_i \frac{\vec{r}}{4 \pi r^3} \cdot \tilde{p} + \frac{\vec{r}}{4 \pi r^3} \cdot \partial_i \tilde{p} \right) - \nabla^2 \left( \frac{Q}{4 \pi r} \right) - \rho
\\
& = \frac{1}{c^2} \frac{\vec{r}}{4 \pi r^3} \cdot \ddot{\tilde{p}} - \left( \frac{\vec{r}}{4 \pi r^3} \right) \cdot \nabla^2 \tilde{p} - 2 \partial_i \left( \frac{\vec{r}}{4 \pi r^3} \right) \cdot \partial_i \tilde{p} - \nabla^2 \left( \frac{\vec{r}}{4 \pi r^3} \right) \cdot \tilde{p} - \nabla^2 \left( \frac{Q}{4 \pi r} \right) - \rho
\end{align*}
Consider,
\[ \nabla^2 \tilde{p} = - \partial_i \left( \frac{x_i}{c^2} \ddot{p} \right) = - \frac{3}{c^2} \ddot{p} + \frac{x_i}{c^2} \dddot{p} \frac{x_i}{rc} = \frac{1}{c^2} \left( -3 \ddot{p} + \frac{r}{c} \dddot{p} \right) = \frac{1}{c^2}  \ddot{\tilde{p}} - \frac{4}{c^2} \ddot{p} \]
Therefore, plugging in,
\begin{align*}
\frac{1}{c^2} & \frac{\vec{r}}{4 \pi r^3} \cdot \ddot{\tilde{p}} - \left( \frac{\vec{r}}{4 \pi r^3} \right) \cdot \nabla^2 \tilde{p} - 2 \partial_i \left( \frac{\vec{r}}{4 \pi r^3} \right) \cdot \partial_i \tilde{p}
\\
& = \frac{1}{c^2} \frac{\vec{r}}{4 \pi r^3} \cdot \ddot{\tilde{p}} - \left( \frac{\vec{r}}{4 \pi r^3} \right) \cdot \left( \frac{1}{c^2} \ddot{\tilde{p}} - \frac{4}{c^2} \ddot{p} \right) - 2 \partial_i \left( \frac{\vec{r}}{4 \pi r^3} \right) \cdot \left( - \frac{x_i}{c^2} \ddot{p} \right)
\\
& =  \left( \frac{\vec{r}}{4 \pi r^3} \right) \cdot \frac{4}{c^2} \ddot{p} + \frac{2}{c^2} \left( \frac{\vec{r}}{4 \pi r^3} - 3 \frac{\vec{r}}{4 \pi r^3} \frac{x_i x_i}{r^2} \right) \cdot \ddot{p} 
\\
& = \frac{1}{c^2} \left( \frac{\vec{r}}{4 \pi r^3}  \right) \cdot [4 + 2 - 6]  \ddot{p} = 0
\end{align*}
Therefore,
\[ W = - \nabla^2 \left( \frac{\vec{r}}{4 \pi r^3} \right) \cdot \tilde{p} - \nabla^2 \left( \frac{Q}{4 \pi r} \right) - \rho \]
Now since $r \neq 0$ we know that,
\[ \nabla^2 \left( \frac{Q}{4 \pi r} \right) = 0 \quad \text{and} \quad \nabla^2 \left( \frac{\vec{r}}{4 \pi r^3} \right) = 0 \]
which implies that $W = 0$ for $r \neq 0$ since $\rho = 0$. Now, in the limit $r \to 0$ we can expand,
\[ \tilde{p}(r,t) = p(t) + \left( \frac{r}{c} \right)^2 \ddot{p}(t) + O(r^3) \] 
Therefore,
\[ W = - \nabla^2 \left( \frac{\vec{r}}{4 \pi r^3} \right) \ddot{p}(t) \left[ \left( \frac{r}{c} \right)^2 + O(r^3) \right] - \nabla^2 \left( \frac{\vec{r}}{4 \pi r^3} \right) \cdot p(t) - \nabla^2 \left( \frac{Q}{4 \pi r} \right) - \rho \]
we know with constant $p$ the potential satisfies the Poisson equation so we have,
\[ W = - \nabla^2 \left( \frac{\vec{r}}{4 \pi r^3} \right) \ddot{p}(t)  \left[ \left( \frac{r}{c} \right)^2 + O(r^3) \right] \]
in the limit $r \to 0$. However, note that,
\[ \nabla^2 \left( \frac{\vec{r}}{4 \pi r^3} \right) = \nabla \delta^3(r) \]
Therefore,
\[  \nabla \delta^3(r) \cdot r^2 = \delta^3(r) \cdot \nabla r^2 = 0 \]
since $r^2$ and higher powers have zero derivative at $r = 0$. Therefore we have shown,
\[ W = 0 \]
and it satisfies the boundary conditions at $r = 0$. 
 
\subsection{Computing the Fields} 

Now we compute the field.
\begin{align*}
B & = \nabla \times A = \epsilon_{ijk} \partial_j \frac{\dot{p}_k(t - r/c)}{4 \pi r c} = \epsilon_{ijk} \left(  \frac{\ddot{p}_k(t - r/c)}{4 \pi r c} \left( - \frac{x_j}{rc} \right) - \frac{\dot{p}_k(t - r/c)}{4 \pi r^2 c} \frac{x_j}{r} \right)
\\
& = - \frac{1}{4 \pi r^3 c^2} \epsilon_{ijk} x_j \left( r \ddot{p}_k(t - r/c) + c \dot{p}_k(t - r/c) \right)
\\
& = - \frac{\hat{r} \times  \ddot{p}}{4 \pi r c^2} - \frac{\hat{r} \times \dot{p}}{4 \pi r^2} 
\end{align*} 

\begin{align*}
E & = - \nabla \phi - \frac{1}{c} \pderiv{A}{t}
\\
& = \frac{Q \vec{r}}{4 \pi r^3} - \frac{1}{4 \pi r^3} \tilde{p} + \frac{3 \vec{r}}{4 \pi r^5} (\vec{r} \cdot \tilde{p}) + \frac{\vec{r} \cdot \ddot{p}}{4 \pi r^3 c^2} \vec{r} - \frac{\ddot{p}}{4 \pi r c^2}
\\
& = \frac{Q \vec{r}}{4 \pi r^3} + \frac{1}{4 \pi r^3} [3 \hat{r} (\hat{r} \cdot \tilde{p}) - \tilde{p}] + \frac{1}{4 \pi r c^2} [\hat{r} (\hat{r} \cdot \ddot{p}) - \ddot{p} ]
\end{align*}
Note that we have radiation fields,
\begin{align*}
E_{\text{rad}} & = \frac{1}{4 \pi r c^2} [\hat{r} (\hat{r} \cdot \ddot{p}) - \ddot{p} ] = \frac{1}{4 \pi r c^2} \hat{r} \times (\hat{r} \times \ddot{p}) 
\\
B_{\text{rad}} & = - \frac{1}{4 \pi r c^2} \hat{r} \times \ddot{p} 
\end{align*}
so we see that $E_{\text{rad}} = - \hat{r} \times B_{\text{rad}}$ and $B_{\text{rad}} = \hat{r} \times E_{\text{rad}}$. 
 
\subsection{The Poynting Vector}

Consider the power,
\begin{align*}
P & = J \cdot E = c \left( \nabla \times B - \frac{1}{c} \pderiv{E}{t} \right) \cdot E
\\
& = c (\nabla \times B) \cdot E - \pderiv{}{t} \left( \tfrac{1}{2} E^2 \right) 
\end{align*}
Furthermore, we can write,
\begin{align*}
(\nabla \times B) \cdot E & = \epsilon_{ijk} E_i \partial_j B_k = \epsilon_{ijk} \partial_j (E_i B_k) - \epsilon_{ijk} B_k \partial_j E_i = - \nabla \cdot (E \times B)  + B \cdot (\nabla \times E) 
\\ 
& = - \nabla \cdot (E \times B) - B \cdot \frac{1}{c} \pderiv{B}{t} = - \nabla \cdot (E \times B) - \frac{1}{c} \pderiv{}{t} (\tfrac{1}{2} B^2) 
\end{align*}
Therefore,
\[ P = - \nabla \cdot c(E \times B) - \pderiv{}{t} \left( \tfrac{1}{2} E^2 + \tfrac{1}{2} B^2 \right) \]
which implies that if we define,
\[ S = c (E \times B) \quad \quad \quad U = \tfrac{1}{2} E^2 + \tfrac{1}{2} B^2 \]
Then we have,
\[ \pderiv{}{t} U + \nabla \cdot S + P = 0 \]
which is the continuity of energy. 
 
\subsection{Computing the Poynting Vector}

Plugging in,
\begin{align*}
S & = c(E \times B) = - c \left( \frac{Q \vec{r}}{4 \pi r^3} + \frac{1}{4 \pi r^3} [3 \hat{r} (\hat{r} \cdot \tilde{p}) - \tilde{p}] + \frac{1}{4 \pi r c^2} [ \hat{r} (\hat{r} \cdot \ddot{p}) - \ddot{p} ] \right) \times \left( \frac{\hat{r} \times  [r \ddot{p} + c \dot{p}]}{4 \pi r^2 c^2} \right) 
\\
& = -\frac{1}{16 \pi^2 r^4 c} \left( \left[ Q +  \frac{3}{r}  (\hat{r} \cdot \tilde{p})  + \frac{r}{c} (\hat{r} \cdot \ddot{p}) \right]  \hat{r} - \frac{1}{r}  \tilde{p} - \frac{r}{c^2}  \ddot{p}  \right) \times \left( \hat{r} \times  [r \ddot{p} + c \dot{p}] \right) 
\end{align*} 
Let us now consider the far field poynting vector,
\begin{align*}
S_{FF} & = -\frac{1}{16 \pi^2 r^3 c^3} \left[ \hat{r} (\hat{r} \cdot \ddot{p}) - \ddot{p} \right] \times  \left( \hat{r} \times  \ddot{p} \right)
\\
& = -\frac{1}{16 \pi^2 r^3 c^3} \left( \hat{r} [\hat{r} (\hat{r} \cdot \ddot{p}) - \ddot{p}] \cdot \ddot{p}  - \ddot{p}  [(\hat{r} \cdot \ddot{p}) - (\hat{r} \cdot \ddot{p}) ] \right)
\\
& = \frac{\hat{r}}{16 \pi^2 r^2 c^3} \left( \ddot{p}^2  - (\hat{r} \cdot \ddot{p})^2  \right)
\\
& = \frac{\hat{r}}{16 \pi^2 r^2 c^3} \left[ \ddot{p} - \hat{r} (\hat{r} \cdot \ddot{p}) \right]^2
\\
& = \frac{\hat{r} \ddot{p}_\perp^2}{16 \pi^2 r^2 c^3} 
\end{align*}
Therefore,
\[ \deriv{P}{\Omega} = \frac{\ddot{p}_\perp^2}{16 \pi^2 c^3} = \frac{\ddot{p}^2 \sin^2{\theta}}{16 \pi^2 c^3}  \]
Furthermore we can calculate the total power radiated by the dipole,
\[ P = \int_{S^2} S_{FF} \cdot \d{A} = \int_{S^2} \frac{\ddot{p}_\perp^2}{16 \pi^2 c^3} \d{\Omega} = \int_{-1}^1 \frac{\ddot{p}^2}{8 \pi c^3} \sin^2{\theta} \: \d{(\cos{\theta})} = \frac{\ddot{p}^2}{6 \pi c^3} \]

\subsection{Scattering}

If an incident wave of frequency $\omega$ and some polarization has energy transport Poynting vector $\vec{S}$ giving the energy flux and the scattering site radiates an averaged angular power spectrum $\left< \deriv{P}{\Omega} \right>$
then we define the differential scattering cross section at that frequency and polarization to be,
\[ \deriv{\sigma}{\Omega} = \frac{1}{\left< |S| \right>} \left< \deriv{P}{\Omega} \right> \]
For example, for dipole radiatiors,
\[ \left< \deriv{P}{\Omega} \right> = \frac{\ddot{p}^2_\perp}{16 \pi^2 c^3} \]
and thus,
\[ \deriv{\sigma}{\Omega} = \frac{1}{16 \pi^2 c^3} \cdot \frac{\left< \ddot{p}^2_\perp \right>}{\left< |S| \right>} \]
For a particle of charge $q$ we can write,
\[ p = q \vec{q} \]
and therefore,
\[ \ddot{p} = q \vec{a} \]
which implies that,
\[ \deriv{\sigma}{\Omega} = \frac{q^2}{16 \pi^2 c^3} \cdot \frac{\left< a^2_\perp \right>}{\left< |S| \right>} \]
For a charged particle, we will generically have,
\[ \vec{a} = \frac{q}{m} \vec{E} \]
and the Poynting vector for incident coherent radiation is,
\[ \vec{S} = c(E \times B) = c (E \times (\hat{k} \times E)) = c \hat{k} E^2 \]
which implies that,
\[ |S| = c E^2 \]
Therefore we find that the cross section has the form,
\[ \deriv{\sigma}{\Omega} = \left( \frac{q^2}{4 \pi m c^2} \right)^2 \cdot \frac{\left< E_\perp^2 \right>}{\left< E^2 \right>} = r_0^2 \cdot \frac{\left< E_\perp^2 \right>}{\left< E^2 \right>} \]
where we have defined the effective electromagnetic radius of the particle,
\[ r_0 = \frac{q^2}{4 \pi m c^2} = \left( \frac{q}{e} \right)^2 \alpha {\lambdabar}_C \]
where, 
\[ \alpha = \frac{e^2}{4\pi \hbar c} \quad \quad \quad \lambdabar_C = \frac{\hbar}{mc} \]
are the fine structure constant and the reduced Compton wavelength respectivly. 
Finally, the total cross section is defind via,
\[ \sigma = \frac{\left< P \right>}{\left< |S| \right>} \]
We can use our previous fomula for the total power radiated,
\[ P = \frac{\ddot{p}^2}{6 \pi c^3} \]
to compute the total cross section as,
\[ \sigma = \frac{q^2}{6 \pi c^3} \cdot \frac{\left< a^2 \right>}{\left< |S| \right>} \]
Furthermore, we generically have,
\[ a^2 = \frac{q^2}{m^2} E^2 = \frac{q^2}{m^2 c} \cdot |S| \]
so the ratio in question becomes,
\[ \frac{\left< a^2 \right>}{\left< |S| \right>} = \frac{a^2}{|S|} = \frac{q^2}{m^2 c} \]
Thus, we have a generic formula for Thomson scattering, the classical scattering cross section of free charged particles,
\[ \sigma_T = \frac{q^4}{6 \pi m^2 c^4} = \frac{8 \pi}{3} \left( \frac{q^2}{4 \pi m c^2} \right)^2 = \frac{8 \pi r_0^2}{3} \]
known as the Thomson cross section. 


\subsection{Scattering a Linearly Polarized Wave}

Consider an incoming plane wave with linear polarization which may be written in the form, 
\begin{align*}
\vec{E}(\vec{r}, t) & = \vec{E}_0 \cos{(\vec{k} \cdot \vec{r} - \omega t)} 
\\
\vec{B}(\vec{r}, t) & = (\hat{k} \times \vec{E}_0) \cos{(\vec{k} \cdot \vec{r} - \omega t)} 
\\
\vec{S} & = \hat{k} c E_0^2 \cos^2{(\vec{k} \cdot \vec{r} - \omega t)} 
\end{align*}
Then we have,
\[ F = q \vec{E} \]
and therefore,
\[ \vec{a} = \frac{q}{m} \vec{E} \]
Then we have,
\[ \deriv{P}{\Omega} = \frac{q^2 a^2}{16 \pi^2 c^3} [1 - (\hat{r} \cdot \hat{a})^2] \]
Plugging in,
\[ \deriv{P}{\Omega} = \frac{q^4 E_0^2}{16 \pi^2 m^2 c^3} [1 - (\hat{r} \cdot \hat{E}_0)^2] \cos^2{(\vec{k} \cdot \vec{r} - \omega t)}  \]
Time averaging gives,
\[ \left< \deriv{P}{\Omega} \right> = \frac{q^4 E_0^2}{32 \pi^2 m^2 c^3} [1 - (\hat{r} \cdot \hat{E}_0)^2]  \]
Then, noting that,
\[ \left< |S| \right> = c \tfrac{1}{2} E_0^2 \]
we find that,
\[ \deriv{\sigma}{\Omega} = \left( \frac{q^2}{4 \pi m c^2} \right)^2 [1 - (\hat{r} \cdot \hat{E}_0)^2] \]

\subsection{Scattering with Arbitrary Polarization}

Consider an arbitrary incoming coherent plane wave which may be decomposed into right and left handed components,
\begin{align*}
\vec{E}(\vec{r}, t) & = \Re{  E_R  (\hat{e}_1 + i \hat{e_2}) e^{i (\vec{k} \cdot \vec{r} - \omega t)} + E_L (\hat{e}_1 - i \hat{e_2}) e^{i (\vec{k} \cdot \vec{r} - \omega t)} }
\\
\vec{B}(\vec{r}, t) & = \hat{k} \times \vec{E}
\\
\vec{S} & = c ( E \times B) = c E^2 \hat{k} 
\end{align*}
Therefore, consider the time average,
\begin{align*}
\left< E^2 \right> & = \tfrac{1}{4} \left< (E_\C + \bar{E}_\C)^2 \right>
\\
& = \tfrac{1}{4} \left< E_\C^2 \right> + \tfrac{1}{2} \left< E_\C \cdot \bar{E}_\C \right> + \tfrac{1}{4} \left< \bar{E}_\C^2 \right>
\end{align*}
However, any term with pure phase time dependence averages to zero so the first and last terms are zero. Thus we have,
\begin{align*}
\left< E^2 \right> & = \tfrac{1}{2} \left< E_\C \cdot \bar{E}_\C \right> 
\\
& = \tfrac{1}{2} \left( E_R (\hat{e}_1 + i \hat{e_2})  + E_L (\hat{e}_1 - i \hat{e_2}) \right) \cdot \left( \bar{E}_R (\hat{e}_1 - i \hat{e_2})  + \bar{E}_L (\hat{e}_1 + i \hat{e_2}) \right)  
\\
& = |E_R|^2 + |E_L|^2
\end{align*}
Furthermore,
\[ \vec{a} = \frac{q}{m} \vec{E} \]
so we need to compute,
\begin{align*}
\left< E_\perp^2 \right> & = \left< E^2 - (\hat{r} \cdot E)^2  \right> = \left< E^2 \right> - \hat{r} \cdot \left< \vec{E} \otimes \vec{E} \right> \cdot \hat{r}
\end{align*}
Now,
\begin{align*}
\left< E \otimes E \right> & = \tfrac{1}{2} \left< E_\C \otimes \bar{E}_\C \right> 
\\
& = \tfrac{1}{2} \left( E_R (\hat{e}_1 + i \hat{e}_2) + E_L (\hat{e}_1 - i \hat{e}_2) \right) \otimes \left( \bar{E}_R (\hat{e}_1 - i \hat{e}_2)  + \bar{E}_L (\hat{e}_1 + i \hat{e}_2) \right)  
\\
& = \tfrac{1}{2} \left( |E_R|^2 (\hat{e}_1 \otimes \hat{e}_1 + \hat{e}_2 \otimes \hat{e}_2) + |E_L|^2 (\hat{e}_1 \otimes \hat{e}_1 + \hat{e}_2 \otimes \hat{e}_2)  \right)
\\
& + \Re{ E_R \bar{E}_L (\hat{e}_1  + i \hat{e}_2) \otimes (\hat{e}_1 + i \hat{e}_2) }
\end{align*}
Therefore,
\begin{align*}
\left< E_\perp^2 \right> & = \left< E^2 - (\hat{r} \cdot E)^2  \right>
\\
& = \tfrac{1}{2} [ 1 +  (\hat{r} \cdot \hat{k})^2 ] \: (|E_R|^2 + |E_L|^2) + \Re{E_R \bar{E}_L (r_1 + i r_2)^2}
\end{align*}
\[ \deriv{\sigma}{\Omega} = \left( \frac{q^2}{4 \pi m c^2} \right)^2  \left[ \tfrac{1}{2} [ 1 +  (\hat{r} \cdot \hat{k})^2 ] + \frac{\Re{E_R \bar{E}_L}}{|E_R|^2 + |E_L|^2} (r_1^2 - r_2^2) - \frac{\Im{E_R \bar{E}_L}}{|E_R|^2 + |E_L|^2} (2 r_1 r_2)  \right] \]
We define Stokes parameters,
\begin{align*}
Q & = 2 \frac{\Re{E_R \bar{E}_L}}{|E_R|^2 + |E_L|^2}
\\
U & = - 2 \frac{\Im{E_R \bar{E}_L}}{|E_R|^2 + |E_L|^2}
\\
V & = \frac{|E_R|^2 - |E_L|^2}{|E_R|^2 + |E_L|^2}
\end{align*}
Therefore, we find that,
\[ \deriv{\sigma}{\Omega} = \left( \frac{q^2}{4 \pi m c^2} \right)^2  \left[ \tfrac{1}{2} [ 1 +  (\hat{r} \cdot \hat{k})^2 ] + \tfrac{1}{2} (r_1^2 - r_2^2) Q + r_1 r_2 V  \right] \]
In terms of scattering angles, if we use polar coordinates oriented along $\hat{k}$ with polar angle $\phi$ which is the scattering direction away from the incident axis and the azimuth $\gamma$ running from $\hat{e}_1$ to $\hat{e}_2$ in the perpendicular plane we find,
\[ \deriv{\sigma}{\Omega} = \left( \frac{q^2}{4 \pi m c^2} \right)^2  \tfrac{1}{2} \left(1 + \left[ 1 + Q \cos{(2 \gamma)} + V \sin{(2 \gamma)} \right] \cos^2{\phi} \right) \]
Note that for purely circularly polarized light we have $Q = V = 0$ and thus,
\[ \deriv{\sigma}{\Omega} = \left( \frac{q^2}{4 \pi m c^2} \right)^2 \cdot \frac{1 + \cos^2{\phi}}{2} \]

\subsection{The Averaged Scattering Cross Sections}

To find the averaged effective cross section for scattering incident unpolarized radiation we average the power output due to linearly polarized radiation over all possible polarizations. This gives,
\[ \left< \deriv{P}{\Omega} \right> = \frac{q^4 E_0^2}{32 \pi^2 m^2 c^3} \left<  1 - (\hat{r} \cdot \hat{E}_0)^2 \right>  \]
Then,
\begin{align*}
\left<  1 - (\hat{r} \cdot \hat{E}_0)^2 \right> & = \frac{1}{2 \pi} \int_0^{2 \pi} \left[1 - (\hat{r} \cdot (\hat{x} \cos{\gamma} + \hat{y} \sin{\gamma}))^2 \right] \d{\gamma}
\\
& = 1 - \frac{1}{2 \pi} \int_0^{2\pi} [(\hat{r} \cdot \hat{x})^2 \cos^2{\gamma} + 2 (\hat{r} \cdot \hat{x})(\hat{r} \cdot \hat{y}) \cos{\gamma} \sin{\gamma} + (\hat{r} \cdot \hat{y})^2 \sin^2{\gamma} ] \d{\gamma}
\\
& = 1 - \frac{1}{2} [(\hat{r} \cdot \hat{x})^2 + (\hat{r} \cdot \hat{y})^2 ] 
\\
& = 1 - \frac{1}{2} [1 - \cos^2{\phi} ]
\\
& = \frac{1 + \cos^2{\phi}}{2}
\end{align*}
Then,
\[ \left< \deriv{P}{\Omega} \right> = \frac{q^4 E_0^2}{32 \pi^2 m^2 c^3} \cdot \frac{1 + \cos^2{\phi}}{2} \]
Then we define the differential scattering cross section to unpolarized decoherent light,
\[ \deriv{\sigma}{\Omega} = \frac{1}{\left< | S | \right>} \left< \deriv{P}{\Omega} \right> = \left( \frac{q^2}{4 \pi m c^2} \right)^2 \cdot \frac{1 + \cos^2{\phi}}{2} = r_0^2 \cdot \tfrac{1}{2}  (1 + \cos^2{\phi}) \]
Note that this result agrees with the result for circularly polarized light. 
\bigskip\\
Now we will compute the total Thompson cross section dependent on polarization. From our general formula, we see that,
\begin{align*}
\sigma & = \left( \frac{q^2}{4 \pi m c^2} \right)^2  \int_{S^2} \tfrac{1}{2} \left(1 + \left[ 1 + Q \cos{(2 \gamma)} + V \sin{(2 \gamma)} \right] \cos^2{\phi} \right) \d{\Omega}
\\
& = \left( \frac{q^2}{4 \pi m c^2} \right)^2  \int_0^\pi \int_0^{2 \pi} \tfrac{1}{2} \left(1 + \left[ 1 + Q \cos{(2 \gamma)} + V \sin{(2 \gamma)} \right] \cos^2{\phi} \right) \d{\gamma} \sin{\phi} \: \d{\phi}
\\
& = \left( \frac{q^2}{4 \pi m c^2} \right)^2 \pi \int_0^\pi (1 + \cos^2{\phi}) \sin{\phi} \: \d{\phi}
\\
& = \left( \frac{q^2}{4 \pi m c^2} \right)^2 \frac{8 \pi}{3}
\end{align*}
Therefore,
\[ \sigma = \frac{8 \pi r_0^2}{3} = \frac{q^4}{6 \pi m^2 c^4}   \]
which agrees with our formula for the total power radiated.

\subsection{Radiation From a Relativistic Particle}

\subsection{QED Calculation of Electron-Photon Scattering}

\section{Systems of Linear ODEs}

\newcommand{\struct}[1]{\mathcal{O}_{#1}}
\newcommand{\tr}[1]{\mathrm{Tr}\left( #1 \right)}
\newcommand{\M}{\mathcal{M}}

\begin{definition}
Let $\Omega \subset \C$ be a domain and let $\struct{\Omega}$ be the sheaf of holomorphic functions on $\Omega$. 
\end{definition}

\begin{definition}
A linear system of ODEs on $\Omega$ is given by $v' = Fv$ for a fixed matrix,
$F \in \End{\O(\Omega)^n}$.
\end{definition}

\begin{definition}
Let $v \in \O(\Omega)$ be a solution to $v' = F v$ then the Wronskian is the matrix,
\[ W(v) = [v^{(0)}, v^{(1)}, v^{(2)}, \dots, v^{(n)}] \in \End{\O(\Omega)^n} \]
\end{definition}

\begin{lemma}
If $X = [v_1, v_2, \dots, v_n]$ then,
\[ \deriv{}{z} \det{X} = \det{[v_1', \dots, v_n]} + \cdots + \det{[v_1, \dots, v_n']} \]
\end{lemma}

\begin{proof}
Obvious by the multilinearity of the derivative.
\end{proof}

\begin{lemma}
\[ \det{[F v_1, \dots, v_n]} + \cdots + \det{[v_1, \dots, F v_n]} = \tr{F} \det{[v_1, \dots, v_n]} \]
\end{lemma}

\begin{proof}
Consider the matrix,
\[ X(t) = (I + t F)[v_1, \dots, v_n] = [ (I + t F) v_1, \dots, (I + t F) v_n] \]
Then, consider,
\[ d = \deriv{}{t} \det{X(t)} \bigg|_{t = 0} \]
First, note that,
\[ \det{X} = \det{(I + t F)} \det{[v_1, \dots, v_n]} \]
and that,
\[ \deriv{}{t} \det{(I + t F)} \bigg|_{t = 0} = \tr{F} \]
Furthermore, by the previous lemma,
\[ D = \deriv{}{t} \det{[ (I + t F) v_1, \dots, (I + t F) v_n]} \bigg|_{t = 0} = det{[F v_1, \dots, v_n]} + \cdots + \det{[v_1, \dots, F v_n]} \]
proving the needed result. 
\end{proof}

\begin{corollary}
The Wronskian satisfies,
\[ \deriv{}{z} W = \tr{F} W \]
\end{corollary}

\begin{corollary}
Either $W$ vanishes identically or $W$ vanishes nowhere. 
\end{corollary}

\begin{theorem}
Let $\F(\Omega)$ be the $\M(\Omega)$-vectorspace of solutions to $v' = Fv$ then,
\[ \dim_{\C} \F(\Omega) \le n \]
\end{theorem}

\begin{proof}
By construction $\F(\Omega) \subset \M(\Omega)^n$ so there are at most $n$ $\M(\Omega)$-linearly independent solutions $v_1, \dots, v_r$. Clearly these are $\C$-linear we need to show that they form a $\C$-basis. For any solution $u \in \F(\Omega)$ we know that we can write,
\[ u = \lambda_1 v_1 + \cdots + \lambda_r v_r \]
for some $\lambda_i \in \M(\Omega)$. Then differentiating, we find,
\begin{align*}
u' & = \lambda_1' v_1 + \cdots + \lambda_r' v_r + \lambda_1 v_1' + \cdots + \lambda_r v_r'
\\
& = \lambda_1' v_1 + \cdots + \lambda_r' v_r + F u
\end{align*}
However, we know that $u' = F u$ and thus,
\[ \lambda_1' v_1 + \cdots + \lambda_r' v_r = 0 \]
However, since $v_1, \dots, v_r$ are $\M(\Omega)$-linearly independent which implies that each $\lambda_i' = 0$ identically so it must be constant on $\Omega$. Thus $\lambda_i \in \C$ so we have proven that $v_1, \dots, v_n$ span $\F(\Omega)$ as a $\C$-vectorspace. 
\end{proof}

\section{Harmonic Functions}

\newcommand{\Vol}[1]{\mathrm{Vol}\left( #1 \right)}

\begin{definition}
Let $\Omega \subset \R^n$ be a domain. A function $\phi : \Omega \to \R$ is \textit{harmonic} on $\Omega$ if it satisfies the Laplace equation, $\nabla^2 \phi = 0$.
\end{definition}

\begin{theorem}
Let $B_r(p) \subset \Omega$ be a ball and $\phi$ harmonic on $B_r(p)$ then,
\[ \phi(p) = \frac{1}{\Vol{\partial B_r(p)}} \int_{\partial B_r(p)} \phi(x) \: \d{A} = \frac{1}{\Vol{B_r(p)}} \int_{B_r(p)} \phi(x) \: \d{V} \]
\end{theorem}


\begin{theorem}[Liouville]
Let $\phi$ be harmonic on $\R^n$. If $\phi$ is bounded then it is constant. 
\end{theorem}

\begin{proof}
Take points $x, y \in \R^n$. Then we know that,
\begin{align*}
\phi(x) - \phi(y) & = \frac{1}{\Vol{B_1} r^n} \left[ \int_{B_r(x)} \phi(z) \: \d{V} - \int_{B_r(y)} \phi(z) \: \d{V} \right]
\\
& = \frac{1}{\Vol{B_1} r^n} \int_{\R^n}  (\chi_{B_r(x)} - \chi_{B_r(y)}) \phi  \: \d{V} 
\end{align*}
Therefore, uing $|\phi| \le M$,
\begin{align*}
|\phi(x) - \phi(y)| & \le \frac{1}{\Vol{B_1} r^n} \int_{\R^n} | \chi_{B_r(x)} - \chi_{B_r(y)}| \cdot | \phi | \: \d{V}
\\
& \le \frac{M}{\Vol{B_1} r^n} \int_{\R^n} | \chi_{B_r(x)} - \chi_{B_r(y)}| \: \d{V}
\\
& = \frac{M}{\Vol{B_1} r^n} \Vol{B_r(x) \Delta B_r(y)}
\end{align*}
Note that,
\[ \Vol{B_r(x) \Delta B_r(y)} = r^n \Vol{B_1(x/r) \Delta B_1(y/r)} \]
and thus,
\[ |\phi(x) - \phi(y)| \le \frac{\Vol{B_1(x/r) \Delta B_1(y/r)}}{\Vol{B_1)}} \xrightarrow{r \to 0} 0 \]
so $\phi(x) = \phi(y)$. 
\end{proof}

\begin{theorem}
Harmonic functions are analytic.
\end{theorem}

\begin{theorem}[Maximum Principle]
Nonconstant harmonic functions cannot have local extrema. 
\end{theorem}

\begin{proof}
Let $\phi : \Omega \to \R$ be harmonic and suppose that $\phi$ has a local extremum at $x \in \Omega$ i.e. there is some open $x \in U \subset \Omega$ such that
\[ \forall y \in U : |\phi(y)| \le |\phi(x)| \]
Then consider a small ball $B_\epsilon(x) \subset U$. Thus we have,
\[ \phi(x) = \frac{1}{\Vol{B_\epsilon}} \int_{B_\epsilon(x)} \phi(y) \: \d{V} \]
However, $|\phi(x)| \le |\phi(y)|$ for all $y \in B_\epsilon(x)$. Suppose that for some $y \in B_\epsilon(x)$ we had $|\phi(y)| < |\phi(x)|$ then by continuity,
\[ |\phi(x)| > \frac{1}{\Vol{B_\epsilon}} \int_{B_\epsilon(x)} | \phi(y) | \: \d{V} \ge \frac{1}{\Vol{B_\epsilon}} \left| \int_{B_\epsilon(x)}  \phi(y) \: \d{V} \right| = |\phi(x)| \]
implying that $\forall y \in B_\epsilon(x) : \phi(x) = \phi(y)$ so $\phi$ is constant on $B_\epsilon(x)$. By analycity, this implies that $\phi$ is constant on $\Omega$. 
\end{proof}

\begin{corollary}
Let $D \subset \Omega$ be compact. Then $f|_D$ achieves its extrema on $\partial D$. 
\end{corollary}

\begin{proof}
If $\phi$ is constant this is trivial so assume otherwise. Then $\phi$ cannot have local and thus cannot have global extrema on $D^\circ$. However, since $D$ is compact, $\phi$ achieves its extrema on $D$ so this must occur on $D \setminus D^\circ = \partial D$ (the last equality holding since $D$ is closed). 
\end{proof}

\begin{theorem}
Consider the Poisson equation $\nabla^2 \phi = \rho$ with boundary conditions fixed on $\partial D$ where $D \subset \R^n$ is compact. Such solutions are unique. 
\end{theorem}

\begin{proof}
Suppose $\phi_1$ and $\phi_2$ are two such solutions. Then,
\[ \nabla (\phi_1 - \phi_2) = \rho - \rho = 0 \]
so $h = \phi_1 - \phi_2$ is harmonic. Since $D$ is compact, $h$ must achieve its extrema on $\partial D$. However, $\phi_1 |_{\partial D} = \phi_2 |_{\partial D}$ by the boundary conditions so $h|_{\partial D} = 0$ impling that $h = 0$. 
\end{proof}

\section{The Multipole Expansion}

\newcommand{\ev}{\mathrm{ev}}

The multipole expansion relies on the fact the Taylor series,
\[ \frac{1}{\sqrt{1 - 2 x t + t^2}} = \sum_{n = 0}^\infty P_n(x) t^n \]
where $P_n$ is the $n^{\text{th}}$ Legendre polynomial. We apply this Taylor series to compute,
\[ \frac{1}{|\vec{R} - \vec{r}|} = \frac{1}{\sqrt{R^2 - 2 \vec{R} \cdot \vec{r} + r^2}} = \frac{1}{R} \cdot \frac{1}{\sqrt{1 - 2 \frac{r}{R} \cos{\alpha} + \left( \frac{r}{R} \right)^2}} = \frac{1}{R} \sum_{n = 0}^\infty \left( \frac{r}{R} \right)^n P_n(\cos{\alpha}) \]
Therefore, the Electrostatic potential for a localized collection of charges about the origin is,
\[ \phi(\vec{R}) = \int_D \frac{\rho(\vec{r})}{4 \pi |\vec{R} - \vec{r}|} \: \dn{3}{r} =  \frac{1}{4 \pi R} \sum_{n = 0}^\infty  \frac{1}{R^n} \left[ \int_D \rho(\vec{r}) \: r^n P_n(\cos{\alpha}) \: \dn{3}{r} \right]  \]
We identify this integral with $n^\text{th}$ moment of the distribution,
\[ \phi(\vec{R}) = \frac{1}{4 \pi R} \sum_{n = 0}^\infty \frac{Q_n}{R^n} \quad \quad \quad Q_n = \int_D \rho(\vec{r}) \: r^n P_n(\cos{\alpha}) \: \dn{3}{r}  \]
However, this expansion is rather inconvienient since the integrals depend on the observer location nontrivially. We can solve this problem by noticing that the moments are more naturally tensors. 
\bigskip\\
We can extend the Legendre defining equation to operations on vectors. Let $\varphi$ be some linear functional and $v$ some vector, then,
\[ \frac{1}{\sqrt{1 - 2 \varphi(v) t + t^2}} = \sum_{n = 0}^\infty P_n(\varphi(v)) t^n \]
Consider the algebra map $\R[x] \to T(V^*)$ via $x \mapsto \varphi$. Evaluation gives a commutative diagram,
\begin{center}
\begin{tikzcd}
\R[x] \arrow[dr, "x \mapsto \varphi(v)"'] \arrow[rr, "x \mapsto \varphi"] & & T(V^*) \arrow[dl, "\mathrm{ev}_v"]
\\
& \R
\end{tikzcd}
\end{center}
which implies that,
\[ P_n(\varphi(v)) = \ev_v(P_n(\varphi)) \]
where $P_n(\varphi)$ is the Legendre polynomial in the tensor algebra (i.e. the image of $P_n$ under the algebra map $x \mapsto \varphi$). Therefore, 
\[ \frac{1}{\sqrt{1 - 2 \varphi(v) t + t^2}} = \sum_{n = 0}^\infty \ev_v(P_n(\varphi)) t^n \] 
In our particular problem, we let $t = \frac{r}{R^2}$ and $v = \hat{R}$ and $\varphi = \inner{\hat{r}}{} = \check{r}$ which is the dual to $\hat{r}$ such that,
\[ \varphi(v) = \hat{R} \cdot \hat{r} \]
Therefore,
\begin{align*}
\frac{1}{|\vec{R} - \vec{r}|} & = \frac{1}{R} \cdot \frac{1}{\sqrt{1 - 2 \frac{\vec{R} \cdot \vec{r}}{R^2} + \left( \frac{r}{R} \right)^2}} = \frac{1}{R} \cdot \frac{1}{\sqrt{1 - 2 \varphi(v) t  + t^2}} = \frac{1}{R} \sum_{n = 0}^\infty \ev_v(P_n(\varphi)) t^n 
\\
& = \frac{1}{R} \sum_{n = 0}^\infty \left( \frac{r}{R} \right)^n \ev_{\hat{R}}P_n(\check{r})
\end{align*}
Plugging in and using linearity, we find,
\begin{align*}
\phi(\vec{R}) = \int_D \frac{\rho(\vec{r})}{4 \pi |\vec{R} - \vec{r}|} \: \dn{3}{r} =  \frac{1}{4 \pi R} \sum_{n = 0}^\infty  \frac{1}{R^n} \: \ev_{\hat{R}} \left[ \int_D \rho(\vec{r}) \: r^n P_n(\check{r}) \: \dn{3}{r} \right] 
\end{align*}
Therefore, we have a multipole expansion,
\[ \phi(\vec{R}) = \frac{1}{4 \pi R} \sum_{n = 0}^\infty \frac{\ev_{\hat{R}}(\hat{Q}_n)}{R^n} \quad \quad \hat{Q}_n = \int_D \rho(\vec{r}) \: r^n P_n(\check{r}) \: \dn{3}{r} \]
Likewise, we can solve magnetostatics problems for localized stready currents via,
\[ \vec{A}(\vec{R}) = \int_D \frac{\vec{J}(\vec{r})}{4 \pi c |\vec{R} - \vec{r}|} \: \dn{3}{r} =  \frac{1}{4 \pi c R} \sum_{n = 0}^\infty  \frac{1}{R^n} \: \ev_{\hat{R}} \left[ \int_D \vec{J}(\vec{r}) \: r^n P_n(\check{r}) \: \dn{3}{r} \right]  \]
and thus we arrive at a magnetic multipole expansion,
\[ \vec{A}(\vec{R}) = \frac{1}{4 \pi c R} \sum_{n = 0}^\infty \frac{\ev_{\hat{R}}(\hat{M}_n)}{R^n} \quad \quad \hat{M}_n = \int_D \vec{J}(\vec{r}) \: r^n P_n(\check{r}) \: \dn{3}{r} \]

\subsection{The Zeroth Multipole}

The zeroth moments are simply,
\[ \hat{Q}_0 = \int_D \rho(\vec{r}) \: \dn{3}{r} = Q \]
the total charge and,
\[ \hat{M}_0 = \int_D \vec{J}(\vec{r}) \: \dn{3}{r} = \vec{J}_{\text{tot}} \]
Note that, in order for magnetostatics to apply, the current and charge distributions must be static meaning that,
\[ \pderiv{\rho}{t} = - \nabla \cdot J = 0 \]
This implies that,
\[ \int \vec{J} \cdot \d{A} = 0 \]
over the boundary of our region. 

\begin{lemma}
We have,
\[ \int_D \vec{J}  \: \d{V} = \int_D \vec{r} \: \pderiv{\rho}{t} \: \d{V} + \int_{\partial D} \vec{r} \: (\vec{J} \cdot \d{A}) \]
\end{lemma}

\begin{proof}
From the continuity equation,
\[ \pderiv{\rho}{t} + \nabla \cdot J = 0 \]
we have,
\begin{align*}
\int_D \vec{r} \: \pderiv{\rho}{t} \: \d{V} & = - \int_D \vec{r} \: (\nabla \cdot J) \: \d{V} 
\end{align*}
Now,
\[ \partial_i (r_j J_i) = J_j + r_j (\partial_i J_i) \]
Therefore,
\[ \int_D \vec{r} \: \pderiv{\rho}{t} \: \d{V}  = \int_D J \; \d{V} - \int_{\partial D} \vec{r} \: (\vec{J} \cdot \d{A}) \]
\end{proof}

By the lemma, if we have $J$ vanish on the boundary and the charges everywhere inside are static then $J_{\text{tot}} = 0$. 

\subsection{The First Multipole}

Now the first moments are dual vectors,
\[ \hat{Q}_1 = \int_D \rho(\vec{r}) \: r \check{r} \: \dn{3}{r} \]
which is the dual of the vector,
\[ \vec{p} = \int_D \rho(\vec{r}) \vec{r} \: \dn{3}{r} \]
which is the dipole moment and then,
\[ \ev_{\hat{R}} (\hat{Q}_1) = \hat{R} \cdot \vec{p} \]
Likewise,
\[ \hat{M}_1 = \int_D \vec{J}(\vec{r}) \: r \check{r} \: \dn{3}{r} \] 
this acts via,
\[ \ev_{\hat{R}} (\hat{M}_1) = \int_D \vec{J}(\vec{r}) \: (\hat{R} \cdot \vec{r}) \: \dn{3}{r} \]
Define the magnetic moment,
\[ \vec{\mu} = \frac{1}{2} \int_D (\vec{r} \times \vec{J}(\vec{r})) \: \dn{3}{r} \]
Now consider,
\begin{align*}
\vec{\mu} \times \hat{R} & = \frac{1}{2} \int_D [ \vec{J} (\hat{R} \cdot \vec{r}) -  \vec{r} (\hat{R} \cdot \vec{J}) ] \: \dn{3}{r}
\end{align*}

\begin{lemma}
We have,
\[ \sum_{\ell = 1}^r  \int_D (r_{i_1} \cdots r_{i_{\ell-1}} \cdot r_{i_{\ell + 1}} \cdots r_{i_r}) \: \vec{J} \: \d{V} = \int_D (r_{i_1} \cdots r_{i_r}) \: \pderiv{\rho}{t} \: \d{V} + \int_{\partial D} [r_{i_1} \cdots r_{r_i}] (\vec{J} \cdot \d{A})  \]
\end{lemma}

\begin{proof}
From the continuity equation,
\[ \pderiv{\rho}{t} + \nabla \cdot J = 0 \]
we have,
\begin{align*}
\int_D (r_{i_1} \cdots r_{i_r}) \: \pderiv{\rho}{t} \: \d{V} & = - \int_D (r_{i_1} \cdots r_{i_r}) \: (\nabla \cdot J) \: \d{V} 
\end{align*}
Now,
\[ \partial_k ([r_{i_1} \cdots r_{i_r}] J_k) = \sum_{\ell = 1}^r (r_{i_1} \cdots r_{i_{\ell-1}} \cdot r_{i_{\ell + 1}} \cdots r_{i_r}) J_{i_\ell} + [r_{i_1} \cdots r_{i_r}] \partial_k J_k  \]
Therefore,
\begin{align*}
\int_D (r_{i_1} \cdots r_{i_r}) \: \pderiv{\rho}{t} \: \d{V} & = \sum_{\ell = 1}^r  \int_D (r_{i_1} \cdots r_{i_{\ell-1}} \cdot r_{i_{\ell + 1}} \cdots r_{i_r}) \: \vec{J} \: \d{V} - \int_{\partial D} [r_{i_1} \cdots r_{r_i}] (\vec{J} \cdot \d{A}) 
\end{align*}
\end{proof}
In particular,
\[ \int_D (r_i J_j + r_j J_i) \d{V} = \int_D (r_i r_j) \pderiv{\rho}{t} \: \d{V} + \int_{\partial D} [r_i r_j] (\vec{J} \cdot \d{A}) \]
For a bounded distrubtion of static currents we therefore have,
\[ \int_D (r_i J_j + r_j J_i) \d{V} = 0 \]
Which implies that,
\[ \int_D \vec{r} (\hat{R} \cdot \vec{J}) \: \d{V} = - \int_D \vec{J} (\hat{R} \cdot \vec{r}) \: \d{V} \]
which implies that,
\[ \vec{\mu} \times \hat{R} = \int_D \vec{J} (\hat{R} \cdot \vec{r}) \: \d{V} = \ev_{\vec{R}}(\hat{M}_1) \]

\subsection{The Second Multipole}
Consider,
\[ \hat{Q}_2 = \int_D \rho(\vec{r})\: r^2 \tfrac{1}{2} (3 \check{r} \otimes \check{r} - I) \: \d{V} \]
this dual to the tensor,
\[ \hat{Q}_2 = \frac{1}{2} \int_D  (3 \vec{r} \otimes \vec{r} - r^2 I) \rho(\vec{r}) \: \d{V} \]
In the magnetic case, we have similarly,
\[ \hat{M}_2 = \int_D \vec{J}(\vec{r})\: r^2 \tfrac{1}{2} (3 \check{r} \otimes \check{r} - I) \: \d{V} \]

\subsection{Force and Torque Equations} 



\subsection{The Dipole Fields}


First we consider the pro



\section{Electromagnetism in Mater}

\subsection{Dipole Densities}

We consider two vector fields $P$ and $M$ the densities of electric and magnetic dipole moments. Consider the potentials produces by these distributions. First,
\begin{align*}
\phi & = \int_D \frac{P \cdot \hat{r}}{4 \pi r^2} \: \d{V} = \int_D P \cdot \nabla \left( \frac{1}{4 \pi r} \right) \d{V} = \int_{\partial D} \frac{P \cdot \d{A}}{4 \pi r} - \int_D \frac{\nabla \cdot P}{4 \pi r} \d{V}
\end{align*}
so we find there is an effective charge density $\rho = - \nabla \cdot P$ and density of surface chrages $P \cdot \d{A}$. 
\bigskip\\
Furthermore, in the magnetic case,
\begin{align*}
\vec{A} & = \int_D \frac{\vec{M} \times \vec{r}}{4 \pi c r^2} \: \d{V} = \int_D \vec{M} \times \nabla \left( \frac{1}{4 \pi c r} \right) \: \d{V} = \int_{\partial D} \frac{\vec{M} \times \d{A}}{4 \pi c r} + \int_D \frac{\nabla \times \vec{M}}{4 \pi c r} \d{V} 
\end{align*}
Therefore we find an effective current density $J = \nabla \times \vec{M}$ and a density of surface current $\vec{M} \times \d{A}$. To prove the above identity, consider,
\begin{align*}
\int_D \epsilon_{ijk} M_j \partial_k \left( \frac{1}{4 \pi c r} \right) \: \d{V} & = \int_D \epsilon_{ijk} \partial_k \left( \frac{M_j}{4 \pi c r} \right) \: \d{V} - \int_D \left( \epsilon_{ijk} \partial_k M_j \right) \left( \frac{1}{4 \pi c r} \right) \: \d{V}
\\
&  = \int_D \epsilon_{ijk} \left( \frac{M_j}{4 \pi c r} \right) \: \d{A_k} + \int_D (\epsilon_{ijk} \partial_j M_k) \left( \frac{1}{4 \pi c r} \right) \: \d{V}
\end{align*} 

\newcommand{\free}{\text{f}}

Using the previous results, we decompose,
\[ \rho = \rho_{\text{f}} - \nabla \cdot P \quad \text{and} \quad J = J_{\text{f}} + \nabla \times M + \pderiv{P}{t} \]

\subsection{The Wave Equations}

Recall the wave equations, 
\begin{align*}
\nabla^2 E - \frac{1}{c^2} \npar{2}{E}{t} & = \nabla \rho  + \frac{1}{c^2} \pderiv{J}{t}
\\
\nabla^2 B - \frac{1}{c^2} \npar{2}{B}{t} & = - \frac{1}{c} (\nabla \times J) 
\end{align*}
Then, plugging in,
\begin{align*}
\nabla^2 E - \frac{1}{c^2} \npar{2}{E}{t} & = \nabla \rho_{\free} - \nabla(\nabla \cdot P) + \frac{1}{c^2} \pderiv{J_{\free}}{t} + \frac{1}{c^2} \nabla \times \pderiv{M}{t} + \frac{1}{c^2} \npar{2}{P}{t}
\\
\nabla^2 B - \frac{1}{c^2} \npar{2}{B}{t} & = - \frac{1}{c} (\nabla \times J_{\free}) - \frac{1}{c} [ \nabla (\nabla \cdot M) - \nabla^2 M ] - \frac{1}{c} \pderiv{}{t} (\nabla \times P)
\end{align*}
Now consider the case with no free charges or currents $\rho_{\free} = J_{\free} = 0$ and we furthermore suppose that the polarizations $P$ and $M$ have no divergence, this is often the case when the polarizations are induced by transverse waves. Then we find,
\begin{align*}
\nabla^2 E - \frac{1}{c^2} \npar{2}{}{t} (E + P) & =  \frac{1}{c^2} \pderiv{}{t} (\nabla \times M)
\\
\nabla^2 (B - c^{-1} M) - \frac{1}{c^2} \npar{2}{}{t} B & = - \frac{1}{c} \pderiv{}{t} (\nabla \times P)
\end{align*}


\subsubsection{Waves In Linear Media}

In a linear medium we assume there exist polarizability tensors $\alpha$ and $\beta$ such that,
\[ P = \alpha \cdot E \quad \quad M = \beta \cdot B \]
Then the wave equations become,
\begin{align*}
\nabla^2 E - (I + \alpha) \cdot \frac{1}{c^2} \npar{2}{}{t} E & = \frac{1}{c^2} \pderiv{}{t} (\nabla \times \beta B)
\\
(I - c^{-1} \beta) \cdot \nabla^2 B - \frac{1}{c^2} \npar{2}{}{t} B & = - \frac{1}{c} \pderiv{}{t} (\nabla \times \alpha E)
\end{align*}
We now consider the case that $\beta = 0$. Often $\beta$ is small so this is a resonable approximation. Then we need to solve the modified wave equations,
\begin{align*}
\nabla^2 E - (I + \alpha) \cdot \frac{1}{c^2} \npar{2}{}{t} E & = 0 
\end{align*}
Since $\alpha$ is symmetric, we can diagonalize it to give,
\[ \nabla^2 E_i - (1 + \alpha_i) \cdot \frac{1}{c^2} \npar{2}{}{t} E_i  = 0 \]
Therefore, the index of refraction along each eigendirection is,
\[ n_i^2 = 1 + \alpha_i \]
Now using,
\[ \nabla \times E = - \frac{1}{c} \pderiv{B}{t} \]
we can solve for the magnetic field. Since our equations are linear, we may write a general plane wave solution at a given frequency for the electric field as,
\[ \vec{E} = \vec{E}_1 \cos{(\vec{k}_1 \cdot \vec{r} - \omega t)} + \vec{E}_2 \cos{(\vec{k}_2 \cdot \vec{r} - \omega t)} + \vec{E}_3 \cos{(\vec{k}_3 \cdot \vec{r} - \omega t)} \]
where $k_i^2 c^2 = n_i^2 \omega^2$. Therefore, waves of different polarizations will travel at different velocities. Now,
\[ \nabla \times \vec{E} = - \sum_{i = 1}^3 \vec{k}_i \times \vec{E}_i \sin{(\vec{k}_i \cdot \vec{r} - \omega t)} \]
Therefore this equation will hold if we set,
\[ \vec{B} = \sum_{i = 1}^3 \frac{c \vec{k}_i}{\omega} \times \vec{E}_i \cos{(\vec{k}_i \cdot \vec{r} - \omega t)} \]
Note that now these normalized wave vectors do not all have the same length so the magnetic field will have different magnitude compared to $E$ for the different rays.
\bigskip\\
Finally, we better check the equation,
\[ \nabla \times B = \frac{1}{c} \pderiv{}{t} (P + E) = \frac{1}{c} (I + \alpha) \cdot \pderiv{E}{t} \]
The left-hand side is,
\begin{align*}
\nabla \times \vec{B} & = - \frac{c}{\omega} \sum_{i = 1}^3 \vec{k}_i \times (\vec{k}_i \times \vec{E}_i) \sin{(\vec{k}_i \cdot \vec{r} - \omega t)}
\\
& = - \frac{c}{\omega} \sum_{i = 1}^3 [\vec{k}_i (\vec{k}_i \cdot \vec{E}_i) - \vec{E}_i k_i^2]   \sin{(\vec{k}_i \cdot \vec{r} - \omega t)}
\end{align*}
The right-hand side is,
\begin{align*}
\frac{1}{c} (I + \alpha) \cdot \pderiv{E}{t} & = \frac{\omega}{c} \sum_{i = 1}^3 n_i^2  \vec{E}_i \sin{(\vec{k}_i \cdot \vec{r} - \omega t)} 
\\
& =  \frac{c}{\omega} \sum_{i = 1}^3 k_i^2 \vec{E}_i \sin{(\vec{k}_i \cdot \vec{r} - \omega t)} 
\end{align*}
Therefore, these equations are equal exactly when $\vec{E}_i$ and $\vec{k}_i$ are perpendicular. This is our constraint. Then we have solutions,
\begin{align*}
\vec{E} & = \sum_{i = 1}^3  \vec{E}_i \sin{(\vec{k}_i \cdot \vec{r} - \omega t)}
\\
\vec{B} & = \sum_{i = 1}^3 n_i (\hat{k}_i \times \vec{E}_i) \cos{(\vec{k}_i \cdot \vec{r} - \omega t)}
\end{align*}
Now we need boundary conditions. These boundary conditions are that $E_{\parallel}$ and $B$ are continuous across the boundary 

\subsection{Macroscopic Maxwell Equations}

Now consider Maxwell's equation,
\begin{align*}
\nabla \cdot E & = \rho_{\free} - \nabla \cdot P
\\
\nabla \cdot B & = 0
\\
\nabla \times E & = - \frac{1}{c} \pderiv{B}{t}
\\
\nabla \times B & = \frac{1}{c} \left( J_{\free} + \nabla \times M + \pderiv{P}{t} + \pderiv{E}{t} \right)
\end{align*}
Therefore, we define macroscopic fields,
\[ D = E + P \quad \quad \quad H = B - c^{-1} M \]
and the Maxwell equations become,
\begin{align*}
\nabla \cdot D & = \rho_{\free} 
\\
\nabla \cdot B & = 0
\\
\nabla \times E & = - \frac{1}{c} \pderiv{B}{t}
\\
\nabla \times H & = \frac{1}{c} \left( J_{\free} + \pderiv{D}{t} \right) 
\end{align*}

\subsection{Macroscopic Wave Equations}

Now consider,
\[ \nabla \times (\nabla \times H) = \frac{1}{c} \left( \nabla \times J_{\free} +  \pderiv{}{t} (\nabla \times D ) \right) \]
Furthermore,
\[ \nabla \times (\nabla \times E) = - \frac{1}{c} \pderiv{}{t} ( \nabla \times B) \]
For the special case the $M = 0$ then $H = B$ so we have,
\[ \nabla \times B = \frac{1}{c} \left( J_{\free} + \deriv{D}{t} \right) \]
Therefore,
\[ \nabla \times (\nabla \times E) + \frac{1}{c^2} \npar{2}{D}{t} = \frac{1}{c^2} \pderiv{}{t} J_{\free} \] 
Let us now consider the case with no free current $J_{\free} = 0$.
For a plane wave, 
\[ \vec{E} = \vec{E}_0 \cos{(\vec{k} \cdot \vec{r} - \omega t)} \]
then,
\[ c^2 \vec{k} \times (\vec{k} \times \vec{E}_0) + (I + \alpha) \omega^2 \vec{E}_0 = 0 \]
Furthermore, we can satisfy the equation,
\[ \nabla \times E = - \frac{1}{c} \pderiv{B}{t} \]
if we set,
\[ \vec{B} = \frac{c}{\omega} \: \vec{k} \times \vec{E}_0 \cos{(\vec{k} \cdot \vec{r} - \omega t)} \]
Now we consider the equation,
\[ \nabla \times B = \frac{1}{c} \pderiv{D}{t} \]
which gives,
\[  c^2 \vec{k} \times (\vec{k} \times \vec{E}_0) + \omega^2 (I + \alpha) \vec{E}_0 = 0 \]
recovering a previous equation. Furthermore, from,
\[ \nabla \cdot (\vec{E} + \vec{P}) = 0 \]
we find,
\[ \vec{k} \cdot (I + \alpha) \vec{E}_0 = 0 \]

\subsection{The Dielectric Sphere}

\subsection{Rayliegh Scattering}

\section{Frensel Equations}



\section{Continuity at a Point}

\begin{definition}
The map $f : X \to Y$ is continuous at $x \in X$ if for each open neighborhood $V$ of $f(x)$ there exists an open neighbrohood $U$ of $x$ s.t. $f(U) \subset V$.
\end{definition}

\begin{remark}
Equivalently, there exists an open neighborhood $U \subset f^{-1}(V)$. 
\end{remark}

\begin{proposition}
$f : X \to Y$ is continuous iff it is continuous at each point $x \in X$.
\end{proposition}

\begin{proof}
If $f$ is continuous then for any $f(x) \in V$ we have $x \in f^{-1}(V)$ is open and $f(f^{-1}(U)) \subset V$ so it is continuous at each point. 
\bigskip\\
Now, take an open set $V \subset Y$ and consider $f^{-1}(V)$. For any $x \in f^{-1}(V)$ we know that $V$ is an open neighbrohood of $f(x)$ so $x$ must have an open neighborhood $U_x \subset f^{-1}(V)$ this proves that $f^{-1}(V)$ is open since it is the union of open sets $U_x$. 
\end{proof}

\begin{proposition}
$f : X \to Y$ is continuous iff $\forall x \in X$ there exists a open neighborhood $U \subset X$ such that $f|_U : U \to f(U)$ is continuous. 
\end{proposition}

\begin{proof}
Clearly restriction of a continuous map is continuous since,
\[ f|_S^{-1}(f(S) \cap V) = \{ x \in S \mid f(x) \in V \} = S \cap f^{-1}(V) \] is open in $S$ because $f^{-1}(V)$ is open in $X$.
\bigskip\\
Now I claim that $f$ is continuous at $x$ when there exists an open neighbrohood $U$ such that $f|_U : U \to f(U)$ is continuous. Take any open neighborhood $V$ of $f(x)$ then $f(x) \in f(U) \cap V$ and it is open in $f(U)$ so we know that,
\[ f|_U^{-1}(f(U) \cap V) = \{ x \in U \mid f(x) \in V \} = U \cap f^{-1}(V) \]
is open in $U$ meaning that $U \cap f^{-1}(V)$ is open in $X$ and thus an open neighborhood of $x$ contained in $f^{-1}(V)$ impling that $f$ is continuous at $x$. If this property holds all $x$ then $f$ is continuous.
\end{proof}

\section{Local Diffeomorphisms}

\begin{remark}
It is clear from these definitions that continuity (smoothness) need not be assumed since $f|_U : U \to f(U)$ on a cover being continuous (smooth) implies that $f$ is since continuity (smoothness) is local.
\end{remark}


\begin{definition}
A continuous map $f : X \to Y$ is a \textit{local homeomorphism} if for each $x \in X$ there exists an open neighborhood $U \subset X$ such that $f(U) \subset Y$ is open and $f|_U : U \to f(U)$ is a homeomorphism.
\end{definition}

\begin{remark}
The condition, $\forall y \in \im{f}$ there exists an open (in $X$) neighbrohood $V \subset \im{f}$ such that $f |_{f^{-1}(V)} : f^{-1}(V) \to V$ is a homeomorphism is too strong. Any nontrivial convering map cannot satisfy this because the preimage will contain multiple copies of $V$. In fact, this implies that $f$ is a homeomorphism since it must be injective (if $f(x) = f(y)$ then $f|_{f^{-1}(V)}$ cannot be injective for a neighborhood of $f(x)$) see below.
\end{remark}

\begin{proposition}
The inclusion $\iota : S \to X$ is a local homeomorphism exactly when $S$ is open.
\end{proposition}

\begin{proof}
Clearly if $S$ is open the $\iota : S \to X$ is a local homeo. by $U = S$. Otherwise, choose a point $x \in (\partial S) \cap S$ (defined in $X$). Then any open $U$ containing $x$ must intersect $X \setminus S$ so every open set of $S$ containing $x$ is $S \cap U$ with $\iota(S \cap U) = S \cap U$ is not open since $x \in \partial(S \cap U)$ and $x \in S \cap U$. 
\end{proof}

\begin{proposition}
Local homeomorphisms are open.
\end{proposition}

\begin{proof}
Let $V \subset X$ be open and consider $y \in f(V)$. Then, choose any lift $x \in V$ and there exists an open neighbrohood $U$ of $x$ such that $y \in f(U) \subset f(V)$ with $f(U)$ open so $f(U)$ is open.  
\end{proof}

\begin{corollary}
A bijective local homeomorphism is a homeomorphism.
\end{corollary}

\begin{proposition}
A local homeomorphism of Hausdroff spaces $f : X \to Y$ with compact $X$ and connected $Y$ is a covering map.
\end{proposition}

\begin{proof}
Any continuous map $f : X \to Y$ is closed ($X$ is compact and $Y$ is Hausdorff) and $f$ is open since it is a local homeomorphism. However, $Y$ is connected so $f$ must be surjective since $f(X)$ is clopen. 
\bigskip\\
Since $f$ is a local homeomorphism $f^{-1}(y)$ is discrete and closed but since $X$ is compact then $f^{-1}(y) = \{ x_1, \dots x_n \}$ is finite. Now, by the Hausdorff property, choose nonintersecting open neighbrohoods $U_i$ of $x_i$. Shrinking if necessary, we may assume that $f|_{U_i} : U_i \to f(U_i)$ is a homeomorphism with $f(U_i) \subset Y$ open since this must be the case for some neighborhood of each $x_i$ and is compatbile with shrinking.  
\bigskip\\
Now, take $C = X \setminus (U_1 \cup \cdots \cup U_n) \supset X \setminus f^{-1}(y)$ and then $f(C)$ is closed so take,
\[ V = \bigcap_{i = 1}^n f(U_i) \setminus f(C) \]
an open neighborhood of $y$. Since,
\[ f^{-1}(V) = \bigcap_{i = 1}^n f^{-1}(f(U_i) \setminus f(C)) \subset \bigcap_{i = 1}^n f^{-1}(f(U_i)) \setminus C \subset U_1 \cup \cdots \cup U_n \]
Therefore,
\[ f^{-1}(V) = \bigcup_{i = 1}^n [U_i \cap f^{-1}(V)] \]
where $U_i \cap f^{-1}(V)$ is open and inside $U_i$ so it maps homeomorphically to the open set $f(U_i \cap f^{-1}(V)) = V$ since $V \subset f(U_i)$. Furthermore, these sets are disjoint by construction $U_i \cap U_j = \varnothing$ so $[U_i \cap f^{-1}(V)]$ and $[U_j \cap f^{-1}(V)]$ are disjoint. Therfore $f : X \to Y$ is a covering map.
\end{proof}

\begin{remark}
The comact requirement is necessary. Otherwise, the resriction of a covering map to an open set is still a local diffeomorphism but may no longer be evenly covered. For example, $t \mapsto e^{2 \pi i t}$ restricted to $(0, 1.5) \to S^1$ has every neighbrohood of $-1$ have a preimage containing one isomorphic copy of itself and one open interval mapping just above $-1$ so it is not evenly covered.
\end{remark}

\begin{definition}
Let $X, Y$ be smooth manifolds. A smooth map $f : X \to Y$ is a \textit{local diffeomorphism} if for each $x \in X$ there exists an open neighborhood $U$ of $x$ such that $f(U)$ is open and $f|_U : U \to f(U)$ is a diffeomorphism.
\end{definition}

\begin{remark}
Clearly any local diffeomorphism is a local homeomorphism. However, between smooth manifolds the converse is false since $f(x) = x^3$ as a map $\R \to \R$ is a homeomorphism (and thus a local homeomorphism) but fails to be a local diffeomorphism at $x = 0$. 
\end{remark}

\begin{theorem}[Inverse Function]
Let $f : X \to Y$ be a smooth map and $p \in X$ such that $\d{f} : T_p X \to T_{f(p)} Y$ is an isomorphism. Then there exists an open neighbrohood $U \subset X$ such that $f(U)$ is open and $f|_U : U \to f(U)$ is a diffeomorphism. 
\end{theorem}

\begin{corollary}
If $f : X \to Y$ has non-singular derivative everywhere then it is a local diffeomorphism.
\end{corollary}


\section{Induction and CoInduction}


\newcommand{\Gal}[1]{\mathrm{Gal}\left( #1 \right)}
\newcommand{\Nm}{\mathrm{Nm}}
\newcommand{\Ind}[3]{\mathrm{Ind}^{#1}_{#2} \left(#3\right)}
\newcommand{\coInd}[3]{\mathrm{coInd}^{#1}_{#2} \left(#3\right)}
\newcommand{\Res}[3]{\mathrm{Res}^{#1}_{#2} \left( #3 \right)}
\newcommand{\Mod}{\mathbf{Mod}}


\begin{definition}
Let $\phi : H \to G$ be a group homomorphism and $M$ a $G$-module i.e. a $\Z[G]$-module. Then we define, the induced and coinduced $\Z[G]$-modules as,
\begin{align*}
\Ind{G}{H}{M} & = \Hom{\Z[H]}{\Z[G]}{M}
\\
\coInd{G}{H}{M} & = M \otimes_{\Z[H]} \Z[G] 
\end{align*}
\end{definition}

\begin{theorem}[Frobenius Reciprocity]
The functor $\Res{G}{H}{-} : \Mod_{G} \to \Mod_{H}$, restriction via $\phi : H \to G$, is left-adjoint to $\Ind{G}{H}{-}$ and right-adjont to $\coInd{G}{H}{-}$. 
\end{theorem}

\begin{proof}
We have, (CLEVER PROOF)
\begin{align*}
\Hom{\Z[G]}{N}{\Ind{G}{H}{M}} & = \Hom{\Z[G]}{N}{\Hom{\Z[H]}{\Z[G]}{M}} = \Hom{\Z[H]}{\Res{G}{H}{N}}{M}
\end{align*}
Furthermore,
\begin{align*}
\Hom{\Z[G]}{\coInd{G}{H}{M}}{N} & = \Hom{\Z[G]}{M \otimes_{\Z[H]} \Z[G]}{N} = \Hom{\Z[H]}{M}{\Res{G}{H}{N}}
\end{align*}
\end{proof}

\begin{lemma}
Induction preserves injectives and coinduction preserves projectives.
\end{lemma}

\begin{proof}
These functors are adjoint to $\Res{G}{H}{-}$ which is clearly exact.
\end{proof}

\begin{lemma}
Induction and coinduction are exact.
\end{lemma}

\begin{proof}
Clearly, induction is left-exact and coinduction is right-exact. However, (CLEVER PROOF)
\end{proof}

\begin{lemma}[Shapiro]
For any $G$-module $M$,
\[ H^r(G, \Ind{G}{H}{M}) = H^r(H, M) \]
and
\[ H_r(G, \coInd{G}{H}{M}) = H_r(H, M) \]
\end{lemma}

\begin{proof}
Take an injective resolution $M \to I^\bullet$. Then we have an injective resolution $\Ind{G}{H}{M} \to \Ind{G}{H}{I^\bullet}$. Thus,
\begin{align*}
H^r(G, \Ind{G}{H}{M}) = H^r(\Hom{\Z[G]}{\Z}{\Ind{G}{H}{I^\bullet}}) = H^r(\Hom{\Z[H]}{\Z}{I^\bullet}) = H^r(H, M) 
\end{align*}
Similarly, take a projective resolution $P^\bullet \to M$. Then we have a projective resolution $\coInd{G}{H}{P^\bullet} \to \coInd{G}{H}{M}$. Thus,
\begin{align*}
H_r(G, \coInd{G}{H}{M}) & = H_r(\coInd{G}{H}{P_\bullet} \otimes_{\Z[G]} \Z) = H_r(P_\bullet \otimes_{\Z[G]} \Z[H] \otimes_{\Z[H]} \Z)
\\
& = H_r(P_\bullet \otimes_{\Z[H]} \Z) = H_r(H, M) 
\end{align*}
\end{proof}


\section{Group Cohomology}

\begin{lemma}
Let $G$ be cyclic with generator $\sigma$ and $M$ a $G$-module. Then,
\[ H^1(G, M) = \frac{\ker{\Nm_G}}{(\sigma - \id) M} \]
\end{lemma}

\begin{proof}
Consider the norm map $\Nm_G : M \to M$ via $m \mapsto \sum\limits_{g \in G} g \cdot m$. Given a crossed homomorphism $\varphi : G \to M$ its value is determined by $\varphi(\sigma)$
also if $\varphi$ is principal then $\varphi(\sigma) = \sigma m - m \in (\sigma - \id)M$. Finally, consider,
\[ \varphi(\sigma^k) = \sigma \cdot \varphi(\sigma^{k-1}) + \varphi(\sigma) \]
which implies that,
\[ \varphi(\sigma^n) = \sigma^{n-1} \cdot \varphi(\sigma) + \sigma^{n-2} \cdot \varphi(\sigma) + \cdots + \varphi(\sigma) \]
meaning that $m = \varphi(\sigma)$ satisfies,
\[ (\sigma^{n-1} + \sigma^{n-2} + \cdots + \id) \cdot m = 0 \]
where $n = |G|$ so $m \in \ker{\Nm_G}$ since $G$ is cyclic so these powers run over every element of the group. Thus we have an isomorphism,
\[ H^1(G, M) \xrightarrow{\sim} \frac{\ker{\Nm_G}}{(\sigma - \id)M} \]
\end{proof}

\begin{theorem}[Hilbert 90]
Let $L/K$ be a finite Galois extension with Galois group $G = \mathrm{Gal}(L/K)$ then,
\[ H^1(G, L^\times) = 0 \]
\end{theorem}

\begin{proof}
Let $\varphi : G \to L^\times$ be a crossed homomorphism i.e.,
\[ \varphi(\sigma \tau) = \sigma \cdot \varphi(\tau) \cdot \varphi(\sigma) \]
For some $a \in L^\times$ let,
\[ \tilde{a} = \sum_{\tau \in G} \varphi(\tau) \cdot (\tau \cdot a) \]
by independence of characters, we can ensure that $\tilde{a}$ is nonzero since otherwise we must have $\varphi(\tau) = 0$ for some $\tau$. 
Now consider,
\[ \sigma \cdot \tilde{a} = \sum_{\tau \in G} \sigma \varphi(\tau) \cdot (\sigma \tau \cdot a) = \sum_{\tau \in G} \varphi(\sigma)^{-1} \varphi(\sigma \tau) \cdot (\sigma \tau \cdot a) = \varphi(\sigma)^{-1} \sum_{\tau' \in G} \varphi(\tau') \cdot (\tau' \cdot a) = \varphi(\sigma)^{-1} a  \]
Therefore,
\[ \varphi(\sigma) = \frac{\sigma (\tilde{a}^{-1})}{\tilde{a}^{-1}} \]
so $\varphi$ is a principle homomorphism. 
\end{proof}

\begin{corollary}
If $L / K$ is finite cyclic with Galois group $G = \Gal{L/K}$ generated by $\sigma$ then every element with $\Nm_{L/K} (a) = 1$ is of the form $a = \frac{\sigma b}{b}$. 
\end{corollary}

\begin{proof}
First by the fact that $G$ is cyclic and then by Hilbert 90 we have,
\[ \frac{\ker{\Nm_{L/K}}}{(\sigma - \id)L^\times} = H^1(G, L^\times) = 0 \]
So $(\sigma - \id) L^\times = \ker{\Nm_{L/K}}$. Recall that $(\sigma - \id)(b) = \frac{\sigma(b)}{b}$ since $L^\times$ is multiplicative and furthermore,
\[ \Nm_{G}(a) = \prod_{g \in G} g \cdot a  = \Nm_{L/K}(a) \]
\end{proof}

\begin{lemma}[Existence of a Normal Basis]
Let $L/K$ be finite Galois. Then there exists $a \in L$ such that $\{ \sigma a \mid \sigma \in \Gal{L/K} \}$ is a basis of $L / K$. 
\end{lemma}

\begin{proof}
(FIND GOOD PROOF)
\end{proof}

\begin{proposition}
Let $L / K$ be finite Galois with Galois group $G = \Gal{L/K}$. Then for each $r > 0$ we have,
\[ H^r(G, L) = 0 \]
\end{proposition}

\begin{proof}
A normal basis gives an isomorphism $K[G] \to L$. However, 
\[ K[G] = \Hom{\Z}{\Z[G]}{K} = \Ind{G}{1}{K} \]
so By Shapiro's Lemma,
\[ H^r(G, L) = H^r(G, \Ind{G}{1}{K}) = H^r(1, K) = 0 \]
\end{proof}

\section{Orientation}

\begin{definition}
An orientation sheaf $o_X$ on an $n$-manifold $X$ is a locally constant sheaf with stalks at each $x \in X$ given by local homology,
\[ o_{X,x} = H_n(X, X \setminus \{ x \} ; \Z) \]
\end{definition}

\begin{proposition}
The antipodal map $a : S^n \to S^n$ is orientation preserving iff $n$ is odd.
\end{proposition}

\begin{proof}

\end{proof}

\begin{theorem}
Orientation preserving homeomorphisms $h : S^3 \to S^3$ are equivalent to ambient isotopy. 
\end{theorem}

\begin{proof}
The homotopy classes of homeomorphisms $S^3 \to S^3$ are exactly,
\[ \pi_0(\Hom{\mathbf{Top}_\bullet}{S^3}{S^3}^\times) = \pi_3(S^3)^\times \cong \Z^\times = \{ \pm 1 \} \]
the homotopy classes of invertible elements in the function space. The orientation preserving maps are thus the path-component of the identity $S^3 \to S^3$ since $\pi_3(S^3)^\times = \{\pm 1\}$ corresponds to orientation class of the maps because the reflection map which represents the class $-1$ inverts orientation. Therefore, orientation-preserving homeomorphisms $S^3 \to S^3$ all lie in the path-component of the identity and thus correspond to a path in function space i.e. an ambient isotopy. (Note. we must ensure that the function remains invertable throughout the deformation. We have shown that all ambient isotopy must lie in this path-component but not exactly that each element of the path-component can be linked through an invertable path. However, every map of degree $\pm 1$ is homotopic to a bijective one (which is automatically a homeomorphism since $S^3$ is compact hausdorff) so we may choose such a path using these representatives.  
\end{proof}

\section{Isometries}

\newcommand{\X}{\mathscr{X}}

\begin{definition}
Given a connection $\nabla$ on $M$, the torsion tensor $T_\nabla \in \Gamma(M, \Omega^{2}_M \otimes TM)$ is defined via,
\[ T^\nabla(X, Y) = \nabla_X Y - \nabla_Y X - [X, Y] \]
\end{definition}

\begin{remark}
We must check that $T_\nabla$ is in fact $\struct{M}$-linear. In fact,
\begin{align*}
T^\nabla(fX, Y) & = \nabla_{f X} Y - \nabla_Y (f X) - [f X, Y] 
\\
& = f \nabla_X Y - f \nabla_Y X - X \d{f}(Y) - f [X, Y] + X \d{f}(Y) 
\\
& f \left( \nabla_X Y - \nabla_Y X - [X, Y] \right) = f T^\nabla(X, Y)
\end{align*}
By antisymmetry, the result holds similarly in the second coordinate.
\end{remark}

\begin{definition}
Given a connection $\nabla$ on $M$, the curvature tensor,
\[ R^\nabla \in \Gamma(M, \Omega_M^2 \otimes \Omega_M^1 \otimes TM) \]
is defined via,
\[ R^\nabla(X, Y, Z) = \nabla_X \nabla_Y Z - \nabla_Y \nabla_X Z - \nabla_{[X, Y]} Z \]
\end{definition}

\begin{remark}
A connection can be viewed as a map $\nabla : TM \to \Omega_M^1 \otimes TM$ which extends to a map $\nabla_k : \Omega^k_M \otimes TM \to \Omega_M^{k+1} \otimes TM$ via,
\[ \nabla_k (\omega \otimes X) = \d{\omega} \otimes X + (-1)^k \omega \wedge \nabla X \]
Now consider,
\begin{align*}
(\nabla_1 \circ \nabla Z)(X, Y) & = 
\end{align*} 
\end{remark}

\begin{proposition}[Levi-Civita]
Let $(M, g)$ be a Riemannian manifold. Then there is a unique connection $\nabla$ on $M$ satisfing,
\begin{enumerate}
\item metric compatibility: $\nabla_X g = 0$ for any $X \in \X(M)$
\item torsion-free: $T^\nabla = 0$
\end{enumerate}
Furthermore, the Levi-Civita connection is natural, if $f : (M, g_M) \to (N, g_N)$ is an isometry then $\nabla_M = f^* \nabla_N$.
\end{proposition}

\begin{proof}
We have,
\begin{align*}
\nabla_X g(Y, Z) & = (\nabla_X g)(Y, Z) + g(\nabla_X Y, Z) + g(Y, \nabla_Y Z) = g(\nabla_X Y, Z) + g(Y, \nabla_Y Z)  
\end{align*}
by metric compatibility. Cyclically permuting,
\begin{align*}
\nabla_X g(Y, Z) & = g(\nabla_X Y, Z) + g(Y, \nabla_X Z) 
\\
\nabla_Y g(Z, X) & = g(\nabla_Y Z, X) + g(Z, \nabla_Y X) 
\\
\nabla_Z g(X, Y) & = g(\nabla_Z X, Y) + g(X, \nabla_Z Y) 
\end{align*}
Now subtract the second two equations,
\begin{align*}
X(g(Y, Z)) - Y(g(Z, X)) - Z(g(X, Y)) & =  g(\nabla_X Y, Z) - g(Z, \nabla_Y X) 
\\
& + g(Y, \nabla_X Z) - g(\nabla_Z X, Y) - g(X, \nabla_Z Y) - g(\nabla_Y Z, X)
\\
& = g([X, Y], Z) + g([X, Z], Y) - g(X, \nabla_Z Y + \nabla_Y Z)
\\
& =  g([X, Y], Z) + g([X, Z], Y) + g(X, [Z, Y]) - 2 g(X, \nabla_Z Y)
\end{align*}
since $\nabla$ is Torsion-free. Therefore, we may define,
\[ g(X, \nabla_Z Y) = \tfrac{1}{2} \left[ g([X, Y], Z) + g([X, Z], Y) + g(X, [Z, Y]) -   X(g(Y, Z)) + Y(g(Z, X)) + Z(g(X, Y)) \right] \]
which uniquely defines $\nabla$ since $g$ is non-degenerate. 
\bigskip\\
To prove naturality, it suffices to prove that $\tilde{\nabla} = f^* \nabla_N$ is metric compatible and torsion-free by the uniqueness we have just established. Consider,
\[ \tilde{\nabla}_X g_M = f^* \nabla_X (f^* g_N) = \nabla_{\d{f}(X)} g_N = 0 \]
so $\tilde{\nabla}$ is compatible with the metric $g_M = f^* g_N$. Now, I claim that,
\[ T^{f^* \nabla} = f^* T^\nabla = 0 \]
This holds because,
\begin{align*}
T^{\tilde{\nabla}}(X,Y) & = \tilde{\nabla}_X Y - \tilde{\nabla}_Y X - [X, Y]
\\
& = \d{f}^{-1}(\nabla_{\d{f}(X)} \d{f}(Y)) - \d{f}^{-1}(\nabla_{\d{f}(Y)} \d{f}(X)) - \d{f}^{-1}[\d{f}(X), \d{f}(Y)] 
\\
& = \d{f}^{-1} T^\nabla(\d{f}(X), \d{f}(Y))  
\end{align*}
\end{proof}

\begin{lemma}
Let $f : M \to N$ be an isometry of Riemannian manifolds. Then $f$ maps geodesics to geodesics and thus,
\[ f(\exp_p{v}) = \exp_{f(p)}(\d{f}(v)) \]
\end{lemma}

\begin{proof}
If $f$ is an isometry, then for the Levi-Civita connection we have,
\[ \nabla_{\d{f} X} \: \d{f} Y = \d{f} \left( \nabla_X Y \right) \]
Then,
\[ f(\exp{v}) = f (\gamma(1)) = (f \circ \gamma)(1) \]
Because $f$ is an isometry,
\[ \nabla_{\deriv{}{t}(f \gamma)} \deriv{}{t}(f\gamma) = \nabla_{\d{f} (\dot{\gamma}}) \: \d{f} (\dot{\gamma}) = \d{f} \left( \nabla_{\dot{\gamma}} \dot{\gamma} \right) = 0 \]
so $f \circ \gamma$ is a geodesic. Thus,
\[ f(\exp_p{v}) = \exp_{f(p)}{\d{f}(v)} \]
\end{proof}

\begin{theorem}
Let $(M, g)$ be a connected Riemannian manifold. Then any isometry $f : M \to M$ such that $f(p) = p$ and $\d{f}_p = \id$ for some $p \in M$ is globally the identity map. 
\end{theorem}

\begin{proof}
Consider the set,
\[ D = \{ x \in M \mid f(x) = x \text{ and } \d{f}_x = \id \} \]
We may view $\d{f}$ as a smooth section of $\Omega^1_M \otimes TM$. Then, there is a canonical section $\id$ of $\Omega^1_M \otimes TM$ via $\id(X) = X$ for any vector field. Now $D$ is the set on which $f(x) = x$ and $\d{f} - \id$ vanishes. Each are closed as follows and thus $D$ as the intersection is closed. First, $(f, \id) : M \to M \times M$ is continuous and the diagonal $\Delta \subset M \times M$ is closed by the Hausdorff property and thus so it its preimage $\{ x \in M \mid f(x) = x \}$. Furthermore, the vanishing of a section is always closed since wherever a section is nonzero it is invertable on some open neighborhood so its nonvanishing set is open.
\bigskip\\
Furthermore, $D$ is open. About a point $x \in D$ we can choose normal coordinates, i.e. $U = \exp{V}$ for $V \subset T_x M$. Then,
\[ f(\exp_p{v}) = \exp_p{\d{f}(v)} = \exp_p{v} \]
which implies that $f = \id$ and thus $\d{f} = \id$ on $U$ so $D$ is open.
Thus, since $p \in D$ we have $D = M$ and thus $f = \id_M$. 
\end{proof}

\begin{corollary}
Let $f,g M \to N$ be two isometries such that at some $p \in M$ we have $f(p) = g(p)$ and $\d{f}_p = \d{g}_p$ then $f = g$. 
\end{corollary}

\begin{theorem}
The isometries of $S^n$ are $\Orth{n+1}$. 
\end{theorem}

\begin{proof}
The group $\Orth{n+1}$ acts isometrically on $S^n \subset \R^{n+1}$. Furthermore it acts transitively on the frame bundle $F_{S^n}$ i.e. it acts transitively on pairs $(x, f)$ where $f$ is a frame of $T_x M$. Thus any isometry of $S^n$ must be an element of $\Orth{n+1}$. 
\end{proof}

\subsection{Manifolds of Quadratic Forms}

\begin{definition}
Let $f : M \to N$ be a smooth map. Then $x \in M$ is a \textit{regular point} if $\d{f}_x : T_x M \to T_x N$ is surjective. We say that $y \in N$ is a \textit{regular value} if each $x \in f^{-1}(y)$ is a regular point. If every point (equivalently value) is regular then $f : M \to N$ is a \textit{submersion}. 
\end{definition}

\begin{theorem}
Let $f : M \to N$ be smooth and $y \in N$ a regular value. Then $Y = f^{-1}(y)$ is an embedded submanifold of $M$ of codimension $\dim{N}$. Furthermore, for any $x \in Y$ the tangent space is $T_x Y = \ker{\d{f}_x} \subset T_x M$. 
\end{theorem}

\begin{example}
Let $Q : \R^N \to \R$ be a quadratic form on $\R^N$. Then $Q$ has a matrix representation as $Q(x) = x^\top M x$ where we may take $M$ to be a symmetric matrix $M^\top = M$. Then, we have $\d{Q}_x(v) = 2 x^\top M v$ which is full-rank 1 when $x^\top M \neq 0$ i.e. when $x \notin \ker{M}$ which clearly must occur when $Q(x) \neq 0$. Thus, the preimage theorem implies that for any $c \neq 0$,
\[ M^Q_c = Q^{-1}(c) = \{ x \in \R^N \mid Q(x) = c \} \]
is an embedded submanifold of codimension $1$. Furthermore, we have that the tangent space at $x \in M^Q_c$ is $\ker{\d{Q}_x}$ i.e,
\[ T_x M^Q_c = \{ v \in \R^N \mid x^\top M v = 0 \} \]
Since $x^\top M \neq 0$ this space is $N - 1$-dimensional. 
\bigskip\\
Now, the inclusion map $\iota : M_c^Q \embed \R^N$ gives a pullback $g = \iota^* B$ of differential forms where $B$ is the constant (0,2) tensor defined by the bilinear form,
\[ B(x,y) = \tfrac{1}{2} [ Q(x + y) - Q(x) - Q(y) ] \]
associated to $Q$. We wish to understand the (0, 2) tensor $g$. 
\bigskip\\
We see that,
\[ B(x, y) = \tfrac{1}{2} [ (x + y)^\top M (x + y) - x^\top M x - y^\top M y ] = \tfrac{1}{2} [x^\top M y + y^\top M x] = x^\top M y \]
since $M^\top = M$. Then, if $v,u \in T_x M^Q_c \subset T_x \R^N$ we see that, as elements of $\R^N$,
\[ g(v,u) = B(\d{\iota} (v), \d{\iota} (u)) = B(v, u) = v^\top M u \]
This is clearly a bilinear symmetric form. We want $g$ to be definite i.e.
\[ \{ v^\top M v \mid x^\top M x = c \text{ and } x^\top M v = 0 \text{ and } v \neq 0 \} \] 
to have constant sign. Note that $M^Q_c$ contains a line exactly when for some $x, y$ we have $Q(x + \lambda y) = c$ for all $\lambda$,
\[ Q(x + \lambda y) = Q(x) + \lambda^2 Q(y) + 2 \lambda B(x, y) = c \]
so taking the derivative at $\lambda = 0$ gives $B(x, y) = 0$ and then we must have $Q(y) = 0$. So $M^Q_c$ contains this line exactly when $B(x, y) = Q(y) = 0$ which is exactly the condition that there exist a tangent vector $y$ which is null iff $g$ is is indefinite.
\bigskip\\
Now we use Sylvester's theorem to change basis such that $M$ is diagonal of the form $(n_0, n_+, n_{-})$ so we may decompose $\R^N = \R^{n_0} \times \R^{n_+} \times \R^{n_-}$ with,
\[ x^\top M y = x^\top_+ y_+ - x^\top_- y_- \]
Without loss of generality, we can also set $c = 1$ by chaning $M$ to $M / c$. Now, we have,
\[ x \in M^Q \iff Q(x) = 1 \iff x_+^\top x_+ - x_-^\top x_- = -1 \]
Then,
\[ v \in T_x M^Q \iff B(v, x) = 0 \iff x^\top_+ v_+ = x^\top_- v_- \]
and,
\[ g(v,v) = Q(v) = v_+^\top v_+ - v_-^\top v_- \]
If $n_0 > 0$ then there is always a direction $y$ in which $B$ is degenerate so $B(x, y) = 0$ and $Q(y) = 0$ so there is a line in $M^Q$ and $g$ is nondefinite. 
\bigskip\\
Finally, I claim that $g$ is definite exactly when either $n_+ \le 1$ or $n_- = 0$. First, if $n_+ \ge 2$ and $n_{-} \ge 1$ then we have a subspace $\R^{2,1}$ in which,
\begin{align*}
x & = (1,0,0)
\\
Q(x) & = 1
\\
v & = (0, 1, 1)
\\
g(x, v) & = 0
\\
g(v, v) & = 0
\end{align*}
so we see that there are null vectors so $g$ is not definite, and, in fact, $M^Q$ contains the line $x + \lambda y$. Furthermore, there are both positive and negative norm vectors,
\begin{align*}
x & = (1,0,0)
\\
Q(x) & = 1
\\
v & = (0, 1, 0)
\\
u & = (0, 0, 1)
\\
g(x, v) & = 0
\\
g(x, u) & = 0
\\
g(v, v) & = 1
\\
g(u, u) & = -1
\end{align*}
Otherwise, the case $n_{-} = 0$ or $n_{+} = 0$ is trivial since $Q$ is already definite on $\R^N$. Thus, for the afirmative case, it suffices to consider the case $n_{+} = 1$. Then for $x \in M^Q$ we have $x_+^2 = 1 + |x_{-}|^2$. Now, if $v \in T_x M^Q$ then,
\[ x_{-}^\top v_{-} = x_{+} v_{+} \]
so,
\[ v_{+} = \frac{x_{-}^\top v_{-}}{\sqrt{1 + |x_{-}|^2}} \le |v_{-}| \]
Therefore,
\[ g(v, v) = v_+^2 - |v_{-}|^2 < 0 \]
so $g$ is definite. 
\bigskip\\
Suppose $g$ is a metric on $M^Q$. Then we consider isometries of $M^Q$. In particular there are the linear isometries of $Q$ given by $\Aut{Q} \subset \mathrm{GL}_{N}(\R)$. These preserve $B$ and $M^Q \subset \R^N$ and thus are isometries. Furthermore, linear isometries act transitively on $M^Q$. Finally, at any fixed point an isometry acts an a linear $Q$-preserving map on the tangent space $T_x M^Q$ and there always exists a linear isometry fixing $x$ and realizing this map on the perpenduclar space. Thus the isometries of $M^Q$ are exactly $\Aut{Q}$.
\bigskip\\
We have shown that this construction only leads to two classes of Riemannian manifolds $S^n$ corresponding to the form of type $n_0 = n_{-} = 0$, $n_{+} = n + 1$ and hyperbolic $n$-space corresponding to the form of type $n_0 = 0$, $n_{+} = 1$, $n_{-} = n$. Furthermore, we have shown that these have isometry groups $\Orth{n + 1}$ and $\Orth{1, n}$ respectively. 
\end{example}

\section{Coriolis Force on a Sphere}

Let $\vec{\Omega} = \omega \hat{z}$ with $\hat{z}$ pointing to the north pole of the sphere and $\hat{x}$ aligned towards the point $(\theta, \phi)$ in the equitorial plane. Then we have the tangent space of the sphere at $(\theta, \phi)$ is spanned by $\hat{y}$ and $\hat{z}' = \hat{z} \sin{\theta} - \hat{x} \cos{\theta}$. Then, $\vec{v} = v_1 \hat{y} + v_2 \hat{z}'$ and,
\begin{align*}
\vec{F}^C & = -2 m \vec{\Omega} \times \vec{v} = -2 m \omega [ \hat{z} \times v_2 \hat{y} + \hat{z} \times v_1 \hat{z}' ]
\\
& = 2 m \omega [v_1 \hat{x} + v_2 \hat{y} \cos{\theta}  ] 
\end{align*}
Then, 
\begin{align*}
F^C_1 & = \vec{F}^C \cdot \hat{y} = 2 m \omega v_2 \cos{\theta} 
\\
F^C_2 & = \vec{F}^C \cdot \hat{z}' = -2 m \omega v_1 \cos{\theta} 
\end{align*}
Therefore, in local coordinates $\vec{v} = (v_1, v_2)$ we have $F^C = - 2 m \vec{\omega}_\theta \times \vec{v}$ where $\vec{\omega}_\theta $ is the normal vector of length $\omega \cos{\theta}$.
\bigskip\\
We note that letting $P$ be the projection operator onto $T$. Then,
\[ T F^C = -2 m T(\Omega \times \vec{v}) = - 2 m T [\Omega]_\times T \vec{v} \]
and,
\[ T [\Omega]_\times T = [\omega_\theta]_\times \]

\section{Landau Levels}

\renewcommand{\a}{\hat{a}}
\newcommand{\adag}{\hat{a}^\dagger}
\newcommand{\bra}[1]{\left< #1 \right|}
\newcommand{\ket}[1]{\left| #1 \right>}

We consider an electron in a constant magnetic field $B$. We chose a gauge,
\[ \vec{A} = \tfrac{1}{2} \vec{B} \times \vec{r} \]
such that then,
\[ \nabla \times A =  \tfrac{1}{2} B (\nabla \cdot \vec{r}) - \tfrac{1}{2} (B \cdot \nabla) \vec{r} = B \]
Now the Hamiltonian for a nonrelativistic particle of mass $m$ and charge $q$ in the field $A$ is,
\[ \hat{H} = \frac{1}{2 m} (\hat{p} - q \hat{A})^2 \] 
Denote the unit vector in the direction of $\vec{B}$ as $\hat{n}$.
We can factor this Hamiltonian as follows. Define,
\begin{align*}
\hat{p}_{\hat{n}} & = \hat{p} \cdot \hat{n}
\\
\hat{p}_\perp & = \hat{p} - \hat{n} \hat{p}_B
\end{align*}
Now, we choose a basis $\hat{x}$, $\hat{y}$, $\hat{z}$ with $\hat{n} = \hat{z}$. Then,
\[ \hat{H} = \frac{1}{2m} \left( (\hat{p}_x - \tfrac{1}{2} q y B)^2 + (\hat{p}_y + \tfrac{1}{2} q x B)^2 + p_z^2 \right) \]
Now define the operators,
\[ \a_{\pm} = \frac{1}{\sqrt{2 \hbar q B}} \left[ (\hat{p}_x \mp \tfrac{1}{2} q y B) \mp i (\hat{p}_y \pm \tfrac{1}{2} q x B) \right] \]
Then,
\begin{align*}
\frac{\hbar q B}{m} \adag_{+} \a_{+} + \frac{1}{2m} \hat{p}_z^2 & = \frac{1}{2m} [(\hat{p}_x - \tfrac{1}{2} q y B)^2 + (\hat{p}_y + \tfrac{1}{2} q x B)^2] + \frac{1}{2m} \hat{p}_z^2 - \frac{i}{2m} [\hat{p}_x - \tfrac{1}{2} q y B, \hat{p}_y + \tfrac{1}{2} q x B]
\\
& = \hat{H} - \frac{i}{2m} \left( [- \tfrac{1}{2} q y B, \hat{p}_y] + [\hat{p}_x, \tfrac{1}{2} q x B] \right)  
\\
& = \hat{H} + \frac{i}{2m} [ \tfrac{i}{2} \hbar qB + \tfrac{i}{2} \hbar qB]
\\
& = \hat{H} - \frac{ \hbar qB}{2m}
\end{align*} 
Define,
\[ \omega = \frac{q B}{m}  \]
then we have,
\[ \hat{H} = \hbar \omega \left( \adag_{+} \a_{+} + \frac{1}{2} \right) + \frac{1}{2m} \hat{p}_z^2 \]
Now we need to check commutation relations,
\begin{align*} 
[\a_s, \a_{s'}] & = 0
\\
[\adag_s, \adag_s] & = 0
\\
[\a_s, \adag_{s'}] & = \delta_{s s'}
\\
[\a_s, \hat{p}_z] & = 0
\\
[\adag_s, \hat{p}_z] & = 0
\end{align*}
We only need to check the first three relations via,
\begin{align*}
[ \a_s^{t \dagger}, \a_{s'}^{t' \dagger} ] & = \frac{1}{2 \hbar q B} \left( [\hat{p}_x, s' \bar{t}' i s' \tfrac{1}{2} q x B] + [s \bar{t} i s \tfrac{1}{2} q x B, \hat{p}_x] + [\bar{s} \tfrac{1}{2} q y B, s' \bar{t}' i \hat{p}_y] + [s \bar{t} i \hat{p}_y, \bar{s}' \tfrac{1}{2} q y B]  \right)
\\
& = \tfrac{1}{4} \left( \bar{t}' - \bar{t} - \bar{s} s' \bar{t}' + \bar{t} \bar{s}' s \right) = \tfrac{1}{4} \left[ \bar{t}' (1 - \bar{s} s') + \bar{t} (\bar{s}'s - 1) \right] = \delta_{s, s'} \delta_{\bar{t}, t'} \bar{t}'
\end{align*}
Therefore, $[\a_{-}, \hat{H}] = 0$ and $[\adag_{-}, \hat{H}] = 0$ and $[\hat{p}_z, \hat{H}]  = 0$ so the first two operators act on a degenerate subspace and we may choose simultaneous eigenvalues of $\hat{p}_z$ and $\hat{H}$. 
\bigskip\\
Now we may compute,
\begin{align*}
\hat{p}_x \mp \tfrac{1}{2} q \hat{y} B & = \frac{\sqrt{2 \hbar q B}}{2} [\adag_{\pm} + \a_{\pm}]
\\
\hat{p}_y \pm \tfrac{1}{2} q \hat{x} B & = \pm \frac{\sqrt{2 \hbar q B}}{2 i}  [\adag_{\pm} - \a_{\pm}]
\end{align*}
Therefore,
\begin{align*}
\hat{p}_x & = \frac{\sqrt{2 \hbar q B}}{4} [ \adag_+ + \a_+ + \adag_- + \a_- ]
\\
\hat{p}_y & = \frac{\sqrt{2 \hbar q B}}{4 i} [ \adag_+ - \a_+ - \adag_- + \a_- ]
\\
\hat{x} & = \frac{\sqrt{2 \hbar q B}}{2 i q B} [ \adag_+ - \a_+ + \adag_- - \a_- ]
\\
\hat{y} & = - \frac{\sqrt{2 \hbar q B}}{2 q B} [ \adag_+ + \a_+ - \adag_- - \a_- ]
\end{align*}
Now the $\hat{z}$ component of angular momentum is,
\begin{align*}
\hat{L}_z & = \hat{x} \hat{p}_y - \hat{y} \hat{p}_x 
\\
& = - \frac{\hbar}{4} \left( [ \adag_+ - \a_+ + \adag_- - \a_- ] [ \adag_+ - \a_+ - \adag_- + \a_- ] - [ \adag_+ + \a_+ - \adag_- - \a_- ] [ \adag_+ + \a_+ + \adag_- + \a_- ] \right)
\\
& = \hbar \left( \adag_{+} \a_{+} - \adag_{-} \a_{-} \right)
\end{align*}
Now it is clear that,
\[ [\hat{L}_z, \hat{H}] = 0 \]
since $[ \adag_{-} \a_{-}, \adag_{+} \a_{+}] = 0$. Now we have commutation relations,
\begin{align*}
[\hat{H}, \adag_{+}] & = \hbar \omega \adag_{+}
\\
[\hat{H}, \a_{+}] & = -\hbar \omega \a_{+}
\\
[\hat{H}, \adag_{-}] & = 0
\\
[\hat{L}_z, \adag_{\pm}] & = \pm \hbar \adag_{\pm}
\\
[\hat{L}_z, \a_{\pm}] & = \mp \hbar \adag_{\pm}
\end{align*}
Now since,
\[ \bra{\psi} \adag_{\pm} \a_{\pm} \ket{\psi} = | \a_{\pm} \ket{\psi} |^2 \ge 0 \]
We have the property that $\hat{N}_{\pm} = \adag_{\pm} \a_{\pm}$ is a nonegative number operator with eigenvalues $n \in \N$ otherwise we could lower the eigenvalue via,
\[ [\hat{N}_{\pm}, \a_{\pm}] = - \a_{\pm} \]
to give,
\[ \hat{N}_{\pm} \a_{\pm} \ket{n} = \left( \a_{\pm} \hat{N}_{\pm} \ket{n} + [\hat{N}_{\pm}, \a_{\pm}] \right) \ket{n} = \a_{\pm} \left( \hat{N}_{\pm}  - \a_{\pm} \right) \ket{n} = (n - 1) \a_{\pm} \ket{n} \]
to give negative eigenvalues contradicting the positivity of the norm. Thus the spectrum must be integral such that it is anihilated at some point by $\a_{\pm}$ to not give negative eigenvalues which would correspond to negative norm states. Therefore we have states,
\[ \ket{n, m, k_z} = \frac{1}{\sqrt{n! \: m!}} (\adag_{+})^n (\adag_{-})^m e^{- i k_z \hat{z}} \ket{0} \]
where $\ket{0}$ is the state anihilated by $\a_{+}$ and $\a_{-}$ and $\hat{p}_z$. This state has eigenvalues,
\begin{align*}
\hat{H} \ket{n, m, k_z} & = \left[ \hbar \omega \left( n + \frac{1}{2} \right) + \frac{\hbar^2 k_y^2}{2m} \right] \ket{n, m, k_z}
\\
\hat{L}_z \ket{n, m, k_z} & = \hbar (n - m) \ket{n, m, k_z}
\\
\hat{p}_z \ket{n, m, k_z} & = \hbar k_z \ket{n, m, k_z}
\end{align*}
We can thus find the ground state wavefunction via,
\[ \bra{x,y,z} \a_{\pm} \ket{0} = 0 \]
implies that,
\[ \left[ \left( - i \hbar \pderiv{}{x} \mp \frac{1}{2} q y B \right) \mp i \left( - i \hbar \pderiv{}{y} \pm \frac{1}{2} q x B \right) \right] \psi_0(x, y, z) \]
Furthermore,
\[ \bra{x,y,z} \hat{p}_z \ket{0} = 0 \implies - i \hbar \pderiv{}{z} \psi_0(x,y,z) = 0 \]
so $\psi_0(x, y, z)$ is independent of $z$. Thus we find,
\[ \left[ - i \hbar \left( \pderiv{}{x} \mp i \pderiv{}{y} \right) - \frac{i}{2} q B ( x \mp i y ) \right] \psi_0(x, y, z) = 0 \]
Dividing out constants,
\[ \left[ \left( \pderiv{}{x} \mp i \pderiv{}{y} \right) + \frac{q B}{2 \hbar} ( x \mp i y ) \right] \psi_0(x, y, z) = 0 \]
Then adding and subtracting we find,
\begin{align*}
\left[  \pderiv{}{x} + \frac{q B}{2 \hbar} x \right] \psi_0(x, y, z) & = 0
\\
\left[ \pderiv{}{y} + \frac{q B}{2 \hbar} y \right] \psi_0(x, y, z) & = 0
\end{align*}
Therefore,
\[ \psi_0(x, y, z) = C_0 e^{- \frac{q B}{4 \hbar} (x^2 + y^2) } \]
Furthermore, up to constants, we have,
\[ \adag_{\pm} \psi = i \hbar \left[ - \left( \pderiv{}{x} \pm i \pderiv{}{y} \right) + \frac{q B}{2 \hbar} ( x \pm i y ) \right] \psi \]
Now we introduce the complex coordinate $w = x + i y$ and,
\[ \pderiv{}{w} = \pderiv{}{x} - i \pderiv{}{y} \quad \quad \quad \pderiv{}{\bar{w}} = \pderiv{}{x} + i \pderiv{}{y} \]
Therefore, up to constants,
\begin{align*}
\a_{+} \psi & \propto \left[ \pderiv{}{w} + \frac{q B}{2 \hbar} \bar{w} \right] \psi 
\\
\a_{-} \psi & \propto \left[ \pderiv{}{\bar{w}} + \frac{q B}{2 \hbar} w \right] \psi
\\
\adag_{+} \psi & \propto \left[ - \pderiv{}{\bar{w}} + \frac{q B}{2 \hbar} w \right] \psi 
\\
\adag_{-} \psi & \propto \left[ - \pderiv{}{w} + \frac{q B}{2 \hbar} \bar{w} \right] \psi 
\end{align*}
Therefore, up to constants,
\begin{align*}
\psi_{n,m, k_y}(x, y, z) & \propto \left[ - \pderiv{}{\bar{w}} + \frac{q B}{2 \hbar} w \right]^n \left[ - \pderiv{}{w} + \frac{q B}{2 \hbar} \bar{w} \right]^m e^{-\frac{q B}{4 \hbar} |w|^2} 
\\
& \propto \left[ - \pderiv{}{\bar{w}} + \frac{q B}{2 \hbar} w \right]^n \bar{w}^m e^{-\frac{q B}{4 \hbar} |w|^2} 
\end{align*}
Therefore, the $n = 0$ Landau level includes,
\[ \psi_n(w) \propto f(\bar{w}) \: e^{-\frac{q B}{4 \hbar} |w|^2} \]
for any holomorphic function $f$. Furthermore, the maximal angular momentum state for the Landau level $n$ has $m = 0$ since $L_z = \hbar (n - m)$ and has a wave function proportional to,
\[ \psi_{n,n}(w) \propto w^n e^{-\frac{q B}{4 \hbar} |w|^2}  \]
Therefore, the maximal angular momentum states together contain all wavefunctions of the form,
\[ \psi(w) \propto f(w) e^{-\frac{q B}{4 \hbar} |w|^2}  \]
for a holomorphic function $f$. 

\section{Connected Sets}

\begin{definition}
We say that a topological space $X$ is connected if it has no nontrivial clopen subsets. We say a subset $S \subset X$ is connected if $S$ endowed with the subspace topology is connected.
\end{definition}


\begin{lemma}
The closure of a connected set is connected.
\end{lemma}

\begin{proof}
Let $A \subset X$ be connected and consider clopen $D \subset \overline{A}$. Now $D \cap A$ is clopen in $A$ so either $D \cap A = A$ or $D \subset \overline{A} \setminus A$. In the first case, $A \subset D$ and inside $\overline{A}$, $A$ is dense and $D$ is closed so $D = \overline{A}$. In the second case, we know there is some open $U \subset X$ such that $U \cap \overline{A} = D \subset \overline{A} \setminus A$ which is a contradiction since every open set intersecting $\overline{A}$ intersects $A$. 
\end{proof}

\begin{lemma}
Let $f : X \to Y$ be continuous with $X$ connected. Then $f(X)$ is connected.
\end{lemma}

\begin{proof}
Suppose that $D \subset f(X)$ is clopen in $f(X)$ then $f^{-1}(D)$ is clopen so $f^{-1}(D)$ is trivial meaning that $D$ is trivial.
\end{proof}

\begin{definition}
We say that two sets $A, B \subset X$ are separated if $\overline{A} \cap B = A \cap \overline{B} = \varnothing$.
\end{definition}

\begin{proposition}
Disjoint open (or closed) subsets are separeted.
\end{proposition}

\begin{proof}
Let $A, B \subset X$ be disjoint open sets. WLOG suppose that $\exists x \in \overline{A} \cap B$ then since $B$ is open $B \cap A \neq \varnothing$.
The case for disjoint closed sets $A, B \subset X$ is trivial since $\overline{A} = A$ and $\overline{B} = B$.
\end{proof}

\begin{proposition}
The following are equivalent,
\begin{enumerate}
\item $X$ is disconnected
\item there exists a nontrivial disjoint open cover of $X$ i.e. nonempty disjoint open sets $A,B \subset X$ s.t. $X = A \cup B$
\item there exists a nontrivial separated cover of $X$ i.e. nonempty separated sets $A,B \subset X$ s.t. $X = A \cup B$
\end{enumerate}
\end{proposition}

\begin{proof}
If $X$ is disconnected then there exists a nontrivial clopen $D \subset X$. Then $D \cup (X \setminus D) = X$ is a nontrivial disjoint open cover of $X$. Any such cover is seperated by the previous lemma so it suffices to show that if $X$ has a nontrivial sparated cover then $X$ is disconnected.
\bigskip\\
Let $X = A \cup B$ with $\overline{A} \cap B = A \cap \overline{B} = \varnothing$.
\end{proof}

\begin{definition}
We say a topological space $X$ is normal if every pair of disjoint closed sets is separated by open sets. If $X$ is normal and Hausdorff then we say $X$ is $\mathrm{T}_4$. 
\end{definition}

\begin{proposition}
Metric spaces are $\mathrm{T}_4$. 
\end{proposition}

\begin{proof}
Given distinct points $x,y \in X$ let $\varepsilon = \tfrac{1}{2} d(x, y)$ then take $U = B_{\varepsilon}(x)$ and $V = B_{\varepsilon}(y)$ which are disjoint neighborhoods. 
\bigskip\\
Now let $A, B \subset X$ be closed. Consider the function,
\[ d(A, B) = \inf \{d(x,y) \mid x \in A , y \in B \} \]
This set is bounded below by zero so the inf always exists. Consider $d(A, y)$ and suppose that $d(A, y) = 0$ then for any $\varepsilon > 0$ there must exists $x \in A$ such that $d(x, y) < \varepsilon$ i.e. $x \in B_{\varepsilon}(y)$ so $y \in \overline{A}$. Thus we have shown that points nonlimit points may be separated from a set by an open neighborhood. Now let,
\[ U = \bigcup_{x \in A} B_{\tfrac{1}{2} d(x, B)}(x) \quad \quad \quad V = \bigcup_{y \in B} B_{\tfrac{1}{2} d(A, y)}(y) \] 
which are neighbrohoods of $A$ and $B$ respectivly. Furthermore, if $z \in U \cap V$ then, for some $x \in A$ we have $d(z, x) < \tfrac{1}{3} d(x, B)$ and for some $y \in B$ we have $d(z, y) < \tfrac{1}{3} d(A, y)$ then,
\[ \max \{ d(x, B), d(A, y) \} \le d(x, y) \le d(x, z) + d(z, y) < \tfrac{1}{2} d(x, B) + \tfrac{1}{2} d(A, y) \]
which is a contradiction so $U$ and $V$ are disjoint.
\end{proof}

\subsection{Connected Components}

\begin{lemma}
If $A \cap B \subset X$ are connected and $A \cap B \neq \varnothing$ then $A \cup B$ is conmmnected.
\end{lemma}

\begin{proof}
If $D \subset A \cup B$ is clopen then $D \cap A \subset A$ and $D \cap B \subset B$ are clopen so they are trivial. The only obstruction to concluding that $D$ is trivial is the possibility that $D \cap A = A$ and $D \cap B = \varnothing$. However, this cannot happen since $A \cap B \neq \varnothing$ 
\end{proof}

\begin{definition}
Let $X$ be a topological space. Then the connected componets of $X$ are the maximal elements of the poset of connected subsets under inclusion. Equivalently, the connected components of $X$ are the equivalence classes of the relation $x \sim y$ iff there exists a connected set containing $x$ and $y$.
\end{definition}

\begin{remark}
These definitions are equivalent as follows. If $Y$ is a maximal connected component then since $Y$ is connected if $x, y \in Y$ then $x \sim y$. Furthermore, if $x \in Y$ and $x \sim y$ then there exists a connected set $C$ containing $x,y$ then $C \cup Y$ is connected (since they intersect) so by maximality $C \subset Y$ so $y \in Y$. Thus $Y$ is an equivalence class. 
\bigskip\\
Conversely, if $Y$ is an equivalence class then clearly if $Y \subset C$ is connected then for any $x \in C$ and $y \in Y$ we have $x \sim y$ so $x \in Y$ and thus $Y = C$. Thus it suffices to show that $Y$ is connected. Suppose there is some clopen $D \subset Y$ then for any $x \in D$ and $y \in Y$ then any connected set $C$ containing $x, y$ has a clopen subspace $C \cap D$ which is nonempty so $C \subset D$ and thus since $y \sim x$ we must have $y \in D$ so $Y = D$. Therefore, $Y$ is connected.
\end{remark}

\begin{proposition}
The connected components of $X$ are closed and connected. Furthermore, if there are finitely many components then they are open.
\end{proposition}

\begin{proof}
Connectedness is obvious from their maximality in the poset of connected sets and so is closure since if $Y$ is connected then $\overline{Y}$ is also connected so by maximality $Y = \overline{Y}$. 
\bigskip\\
Now, if there are finitely many connected components then the complement of one is a finite union of closed sets (the other components) and thus closed so it is open.
\end{proof}

\newcommand{\Q}{\mathbb{Q}}

\begin{remark}
Finiteness is necessary to ensure that the connected components are open. Accordingly, the space $\Q$ (with the Euclidean topology) has connected connected components $\{ q \}$ for $q \in \Q$ which are open but not closed. 
\end{remark}


\begin{proposition}
Let $G$ be a topological group. Then $G_0$ the connected component of $e$ is a topological subgroup. 
\end{proposition}

\begin{proof}
The map $\ell_g : G \to G$ by left multiplication is continuous. Thus, if $g \in G_0$ then consider $\ell_{g}(G_0)$ which is connected and contains $g$ so it is contained in $G_0$. Furthermore, the inversion map $i : G \to G$ is continuous so $i(G_0)$ is connected and contains $e$ so $i(G_0) \subset G_0$. Therefore $G_0$ is a subgroup. 
\end{proof}

\begin{proposition}
Let $G$ be a topological group then there is an exact sequence of topological groups,
\begin{center}
\begin{tikzcd}
1 \arrow[r] & G_0 \arrow[r] & G \arrow[r] & \pi_0(G) \arrow[r] & 1
\end{tikzcd}
\end{center}
\end{proposition}

\begin{proof}
First, note that $\pi_0 : \mathbf{Top} \to \mathbf{Set}$ is a functor respecting products and thus preserves group objects. The map $G \to \pi_0(G)$ given by sending $g$ to $[g]$ the unique connected component containing it. This map is a continuous group homomorphism when $\pi_0(G)$ is given the quotient topology. 
Now $g \in \ker{(G \to \pi_0(G))}$ iff $[g] = [e]$ iff $g \in G_0 = [e]$ so the sequence is exact. In particular, $G_0 \triangleleft G$ is normal.
\end{proof}

\begin{lemma}
The connected components of any manifold are open. 
\end{lemma}

\begin{proof}
Let $C \subset M$ be a connected component. Then for any $x \in C$ there is a chart $(U, \varphi)$ containing $x$. Then $\varphi(U)$ is open in $\R^n$ which is locally connected so there exists an open connected set $V$ containing $\varphi(x)$ which implies that $\tilde{V} = \varphi^{-1}(V)$ is an open connected neighborhood of $x$ so $\varphi$ is a homeomorphism. Thus, by maximality, $x\in \tilde{V} \subset C$ so $C$ is open.
\end{proof}

\begin{proposition}
Every compact Lie group is a finite extenson of a connected group. 
\end{proposition}

\begin{proof}
Let $G$ be a Lie compact group. Then $G_0$ is open since $G$ is a manifold. Therefore, $\pi_0(G) = G / G_0$ is finite since the cosets form a disjoint open cover. Then the sequence,
\begin{center}
\begin{tikzcd}
1 \arrow[r] & G_0 \arrow[r] & G \arrow[r] & \pi_0(G) \arrow[r] & 1
\end{tikzcd}
\end{center}
makes $G$ a finite extension of $G_0$. 
\end{proof}

\begin{remark}
The requirement that $G$ be a manifold is necessarly. For example $\Z_p$ is a compact topological group but it is totally disconnected and points are not open and it is infinite. 
\end{remark}

\section{Oscillators}

\subsection{Fourier and Laplace Transforms}

\begin{definition}
For a function $f : [0,\infty) \to \C$ we define its Laplace transform,
\[ F(s) = \L\{ f \}(s) = \int_0^\infty f(t) e^{-st} \d{t} \] 
\end{definition}

\begin{definition}
For a function $f : \R \to \C$ we define its Fourier transform,
\[ \hat{f}(\omega) = \F\{ f \}(\omega) = \frac{1}{2 \pi} \int_{-\infty}^\infty f(t) e^{-i \omega t} \d{t} \] 
\end{definition}

\begin{theorem}
We may invert the Fourier transform as follows,
\[ f(t) = \int^{\infty}_{-\infty} \hat{f}(\omega) e^{i \omega t} \d{\omega} \]
\end{theorem}


\begin{theorem}[Parseval]
The energy defined by,
\[ E = \int_{-\infty}^\infty |f(t)|^2 \d{t} \]
may be computed as,
\[ E = 2\pi \int_{-\infty}^\infty |\hat{f}(\omega)|^2 \d{t} \]
\end{theorem}

\begin{proof}
Consider,
\begin{align*}
E & = \int_{-\infty}^\infty |f(t)|^2 \d{t} = \int_{-\infty}^\infty \left| \int^{\infty}_{-\infty} \hat{f}(\omega) e^{i \omega t} \d{\omega}\right|^2 \d{t}
\\
& = \int_{-\infty}^\infty \left( \int^{\infty}_{-\infty} \hat{f}(\omega) e^{i \omega t} \d{\omega} \right) \left( \int^{\infty}_{-\infty} \hat{f}(\omega')^* e^{-i \omega' t} \d{\omega'} \right) \d{t}
\\
& = \int_{-\infty}^\infty \int_{-\infty}^\infty  \hat{f}(\omega) \hat{f}(\omega') \left( \int_{-\infty}^\infty e^{i (\omega - \omega') t} \d{t} \right) \d{\omega} \d{\omega'}
\\
& = 2\pi \int_{-\infty}^\infty |\hat{f}(\omega)|^2 \: \d{\omega}
\end{align*}
\end{proof}

\begin{remark}
We think of $|f(t)|^2$ as the power or energy carried in the time domian and write,
\[ \deriv{E}{t} = |f(t)|^2 \]
Conversely, we think of $2 \pi |\hat{f}(\omega)|^2$ as the frequency space analogy of power i.e. spectral energy, energy distribution over the frequency spectrum,
\[ \deriv{E}{\omega} = 2 \pi |\hat{f}(\omega)|^2 \]
\end{remark}

\begin{remark}
If $f$ is real then so in this case the power spectrum is symmetric (up to conjugation about zero) so we may write,
\[ E = 4 \pi \int_0^\infty  | \hat{f}(\omega) |^2 \d{\omega} \]
and the new reduced power spectrum is,
\[ \deriv{E}{\omega} = 4 \pi | \hat{f}(\omega) |^2 \]
where we must recall that this is defined only for positive frequencies. 
\end{remark}

\begin{lemma}
$\F \{ f' \}(\omega) = (i \omega) \hat{f}(\omega)$
\end{lemma}

\begin{proof}
Consider,
\begin{align*}
\F \{ f' \}(\omega) & = \frac{1}{2 \pi} \int_{-\infty}^\infty f'(t) e^{-i \omega t} \d{t} = - \frac{1}{2 \pi} \int_{-\infty}^\infty f(t)  \deriv{}{t} e^{-i \omega t} \d{t}
\\
& = (i \omega) \frac{1}{2 \pi} \int_{-\infty}^\infty f(t) e^{-i \omega t} \d{t}
\\
& = (i \omega) \hat{f}(\omega)
\end{align*}
\end{proof}

\begin{proposition}
Define the convolution,
\[ (f * g)(t) = \int_{-\infty}^{\infty} f(t - t') g(t') \d{t'}  \]
Then,
\[ \F \{ f \cdot g \} = \hat{f} * \hat{g} \quad \quad \quad \F \{ f * g \} = 2 \pi \hat{f} \cdot \hat{g} \] 
\end{proposition}

\begin{proof}
Consier,
\begin{align*}
\F \{ f \cdot g \}(\omega) & = \frac{1}{2 \pi} \int_{-\infty}^\infty f(t) g(t) e^{-i \omega t} \d{t}
\end{align*}
However, we know that,
\[ g(t) = \int_{-\infty}^\infty \hat{g}(\omega') e^{i \omega' t} \d{\omega'} \]
Therefore,
\begin{align*}
\F \{ f \cdot g \}(\omega) & = \frac{1}{2 \pi} \int_{-\infty}^\infty f(t) \left[ \int_{-\infty}^\infty \hat{g}(\omega') e^{i \omega' t} \d{\omega'} \right] e^{-i \omega t} \d{t}
\\
& = \frac{1}{2 \pi} \int_{-\infty}^\infty \hat{g}(\omega') \left[ \int_{-\infty}^{\infty} f(t) e^{i (\omega' - \omega) t} \d{t} \right] \d{\omega'} 
\\
& =  \int_{-\infty}^\infty \hat{f}(\omega - \omega')  \hat{g}(\omega') \: \d{\omega'}
\\
& = (\hat{f} * \hat{g})(\omega)
\end{align*}
Likewise,
\begin{align*}
\F\{ f * g \}(\omega) & = \frac{1}{2 \pi} \int_{-\infty}^{\infty} \left[ \int_{-\infty}^{\infty} f(t - t') g(t') \: \d{t'} \right] e^{- i \omega t} \d{t}
\\
& = \frac{1}{2 \pi} \int_{-\infty}^{\infty} g(t') \left[ \int_{-\infty}^{\infty} f(t - t') e^{- i \omega t} \d{t} \right] \d{t'}
\\
& =  \int_{-\infty}^{\infty} g(t') \hat{f}(\omega) e^{-i \omega t'}
\\
& = 2 \pi \hat{f}(\omega) \hat{g}(\omega)
\end{align*}
\end{proof}

\begin{corollary}
\[ \F^{-1}\{ \F\{ f \} \cdot \F\{ g \} \} = \frac{1}{2\pi} f * g \]
\end{corollary}

\subsection{Linear Time Invariant Systems}

Consider a linear time-invariant system $L$ which is driven by some forcing term $f$ (which we may also use via impulses to put the system in some initial condition. We need to solve,
\[ L[\phi] = f \]
Now consider the following transforms. 
\[ \F \{L[\phi] \} = p_L(\omega) \hat{\phi} = \F \{ f \} = \hat{f} \]
where $p_L(\omega)$ is the polynomial in $\omega$ given by Fourier transforming the linear time-invariant operator $L$ which gives a polynomial in $\omega$ by the derivative property.
Then,
\[ \hat{\phi} = \frac{\hat{f}}{p_L(\omega)} \]
We call,
\[ w_L(\omega) = \frac{1}{p_L(\omega)} \]
the frequency response.
Finally,
\[ \phi = \F^{-1} \{ \hat{f} \cdot w_L \} = f * W_L \]
where,
\[ W_L = (2 \pi)^{-1} \F^{-1} \{ w_L \} \]
is the impulse response. 

\begin{remark}
Consider the system's response to an impulse, $f(t) = f_0 \delta(t)$. Then,
\[ \phi = f * W_L = f_0 W_L \] 
giving the response to an impulse. Furthermore, if $f(t) = f_0 e^{i \omega t}$ is a pure frequency then,
\[ \hat{f}(\omega') = f_0 \delta(\omega' - \omega) \]
and therefore,
\[ \phi = \F^{-1} \{ f_0 \delta(\omega' - \omega) \cdot w_L \} = \F^{-1} \{ f_0 w_L(\omega) \delta(\omega' - \omega) \} = f_0 w_L(\omega) \: e^{i \omega t} \: \d{\omega} \]
so $w_L$ is the frequency response of the system. 
\end{remark}

\begin{remark}
We can think of the solution,
\[ \phi(t) = (f * W_L)(t) = \int_{-\infty}^{\infty} f(t') W_L(t - t') \d{t'} \]
as summing up the responses to a train of impulses weighted by $f(t')$. We can see this explicitly by writing,
\[ f(t) = \int_{-\infty}^{\infty} f(t') \delta(t - t') \d{t'} \]
Then the system $L[\phi] = f$ is linear and responds to $\delta(t - t')$ via the impulse response $W_L(t - t')$ which implies that the solution should be,
\[ f(t) = \int_{-\infty}^{\infty} f(t') W_L(t - t') \d{t'} \]
\end{remark}

\begin{remark}
We can think of the solution,
\[ \phi(t) = \F^{-1} \{ \hat{f} * w_L \}(t) = \int_{-\infty}^{\infty} \hat{f}(\omega) w_L(\omega) e^{i \omega t} \]
as summing up the responses to each frequncy that makes up the function $f(t)$ weighted by its amplitude $\hat{f}(\omega)$. We can see this explicitly by writing,
\[ f(t) = \int_{-\infty}^{\infty} \hat{f}(\omega) e^{i \omega t} \: \d{t} \]
Then the system $L[\phi] = f$ is linear and responds to $e^{i \omega t}$ via the frequency response $w_L(\omega)$ which implies that the solution should be,
\[ \phi(t) = \int_{-\infty}^{\infty} \hat{f}(\omega) w_L(\omega) e^{i \omega t} \: \d{\omega} \]
\end{remark}

\subsection{The Damped Harmonic Oscillator}

Consider the system,
\[ m \ddot{x} + m \gamma \dot{x} + m \omega_0^2 x = F \]
we normalize it to remove the mass,
\[ \ddot{x} + \gamma \dot{x} + \omega_0^2 x = f \]
The charactristic polynomial is,
\[ p_L(\omega) = - \omega^2 + i  \gamma \omega +  \omega_0^2 \]
Therefore, the frequency response is,
\[ w_L(\omega) = \frac{1}{- \omega^2 + i \gamma \omega + \omega_0^2} \]
We can write this as,
\[ w_L(\omega) = \frac{e^{-i \delta}}{\sqrt{(\omega^2 - \omega_0^2)^2 + \gamma^2 \omega^2}} \quad \quad \tan{\delta} = \frac{\gamma \omega}{\omega_0^2 - \omega^2} \]
Then the impulse response is,
\begin{align*}
W_L(t) & = \frac{1}{2 \pi} \int_{-\infty}^{\infty} \frac{e^{i \omega t} \: \d{\omega} }{- \omega^2 + i \gamma \omega + \omega_0^2} 
\end{align*}
We can factor the denominator to find the natural frequencies,
\[ -\omega^2 + i \gamma \omega + \omega_0^2 = 0 \iff \omega = \frac{i \gamma}{2} \pm \sqrt{\omega_0^2 - \left( \frac{\gamma}{2} \right)^2 }  \]
Now let,
\[ \tilde{\omega} = \sqrt{\omega_0^2 - \left( \frac{\gamma}{2} \right)^2 } \]
so we find roots,
\[ \omega = \frac{i \gamma}{2} \pm \tilde{\omega} \]
and thus a partial fraction representation of the frequency response,
\[ w_L(\omega) = \frac{1}{2 \tilde{\omega}} \left[ \frac{1}{(\omega + \tilde{\omega}) - i \frac{\gamma}{2}} - \frac{1}{(\omega - \tilde{\omega}) - i \frac{\gamma}{2}} \right] \]
Then,
\begin{align*}
W_L(t) & = \frac{1}{2\pi} \int_{-\infty}^{\infty} \frac{1}{2 \tilde{\omega}}   \left[ \frac{1}{(\omega + \tilde{\omega}) - i \frac{\gamma}{2}} - \frac{1}{(\omega - \tilde{\omega}) - i \frac{\gamma}{2}} \right] e^{i \omega t} \: \d{\omega}
\\
& = \Theta(t) \: \frac{1}{2 i } [ e^{i(\tilde{\omega} + i \frac{\gamma}{2}) t} - e^{i(-\tilde{\omega} + i \frac{\gamma}{2}) t} ] =  \Theta(t) \: \tilde{\omega}^{-1} \: e^{- \frac{\gamma}{2} t} \sin{(\tilde{\omega} t)}
\end{align*}
Using the fact that,
\begin{align*}
\F \{ \Theta(t) \: e^{i \omega t} \}(\omega') & = \frac{1}{2 \pi} \int_{0}^{\infty}  e^{i (\omega - \omega') t} \: \d{t} = \frac{1}{2 \pi i} \cdot \frac{1}{( \omega' - \omega)} 
\end{align*}

\subsection{Resonance}

The frequency response is given by,
\[ w_L(\omega) = \frac{e^{-i \delta}}{\sqrt{(\omega^2 - \omega_0^2)^2 + \gamma^2 \omega^2}} \quad \quad \tan{\delta} = \frac{\gamma \omega}{\omega_0^2 - \omega^2} \]
Therefore,
\[ |w_L(\omega)| = \frac{1}{(\omega^2 - \omega_0^2)^2 + \gamma^2 \omega^2} \]
We may also write down the acceleration frequency response,
\[ \hat{a}(\omega) = \omega^2 w_L(\omega) \]
and thus,
\[ |\hat{a}(\omega)|^2 = \frac{\omega^4}{(\omega^2 - \omega_0^2)^2 + \gamma^2 \omega^2} \]
Now we consider various limits. In the $\omega \ll \omega_0$ limit we have,
\[ |w_L(\omega)| \approx \frac{1}{\omega_0^4} \quad \quad \quad |\hat{a}(\omega)| \approx \left( \frac{\omega}{\omega_0} \right)^4 \]
In the $\omega \gg \omega_0$ limit we have,
\[ |w_L(\omega) | \approx \frac{1}{\omega^4} \quad \quad \quad |\hat{a}(\omega)| = 1 \]
Finally, in the limit $\omega \approx \omega_0$ we can write $(\omega - \omega_0)^2 = (\omega + \omega_0) (\omega - \omega_0) \approx 2 \omega_0 (\omega - \omega_0)$. Furthermore, for a high-$Q$ oscillator, we can replace $\omega$ by $\omega_0$ elsewhere to get,
\[ |w_L(\omega)|^2 \approx \frac{1}{4 \omega_0^2 (\omega - \omega_0)^2 + \gamma^2 \omega_0^2} = \frac{\pi}{2 \gamma \omega_0^2} \cdot \frac{\gamma / (2 \pi)}{(\omega - \omega_0)^2 + \left( \gamma / 2 \right)^2} \]
where,
\[ \phi(\omega) = \frac{\gamma / (2 \pi)}{(\omega - \omega_0)^2 + \left( \gamma / 2 \right)^2} \]
is a normalized Lorentizan distribution with full width at half max $\gamma$. Furthermore, we have, near resonance,
\[ | \hat{a}(\omega) |^2 \approx \frac{\pi \omega_0^2}{2 \gamma} \phi(\omega) \] 


\subsection{Energy and Quality of Resonators}

\newcommand{\EV}[1]{\left< #1 \right>}

Consider the loss of energy stored in this oscillator. Let,
\[ W = \tfrac{1}{2} m \dot{x}^2 + \tfrac{1}{2} m \omega_0^2 x^2 \]
Then consider,
\[ \dot{x} (m \ddot{x} + m \gamma \dot{x} + m \omega_0^2 x^2 ) = \dot{x} F \]
Which implies that,
\[ \deriv{}{t} W = - \gamma m \dot{x}^2 + \dot{x} F \]
In steady state,
\[ \left< \deriv{W}{t} \right> = 0 \]
which implies that,
\[ \left< P \right> = \left< \dot{x} F \right> = \left< \gamma m \dot{x}^2 \right> \]
the power pumped into the system all ends up in the resistive term. 
We define the inverse quality of the oscillator as the time average of the fractional loss of energy per radian of the cycle (we may define this in general in action-angle coordinates),
\[ \frac{1}{Q} = -\left< \frac{1}{W} \deriv{W}{\phi} \right> = -\left< \frac{1}{\omega W} \deriv{W}{t} \right> \]
Therefore, on average, for transients,
\[ W = W_0 e^{- \omega t / Q} \]
so $Q / \omega$ is the lifetime of the oscilator.
Then in our case, if the oscillator is driven at a frequency $\omega$ then,
\[ \frac{1}{Q} = -\left< \frac{1}{\omega W} \deriv{W}{t} \right> = \frac{\gamma m \EV{\dot{x}}}{\EV{\tfrac{1}{2} m \dot{x}^2 + \tfrac{1}{2} m \omega_0^2 x^2}} = \frac{2 \gamma \omega}{\omega^2 + \omega_0^2} \]
At resonance, $\omega \approx \omega_0$ we have,
\[ Q = \frac{\omega}{\gamma} \]
so $\gamma^{-1}$ is the lifetime of the resonator.

\subsection{Atomic Transition Lines}

For an oscillating charge we know the emitted power is,
\[ \EV{P} = \frac{q^2 \EV{a}^2}{6 \pi c^3} \]
therefore we can compute the quality of the oscillator giving rise to atomic spectra. For a high-$Q$ oscillator freely oscillating at its natural frequency $\omega \approx \omega_0$,
\[ \EV{W} = \EV{\tfrac{1}{2} m \dot{x}^2 + \tfrac{1}{2} m \omega_0^2 x^2} = m \omega_0^2 \EV{x^2} \]
furthermore,
\[ \EV{a^2} = \omega_0^4 \EV{x^2} \]
Then,
\[ \frac{1}{Q} = \frac{P}{\omega W} = \frac{q^2 \omega_0}{6 \pi m c^3} = \frac{2r_0 \omega_0}{3 c} \]
Then we may find the line-width via,
\[ \frac{\Delta \omega}{\omega_0} = \frac{\gamma}{\omega_0} = \frac{1}{Q} = \frac{2r_0 \omega_0}{3 c} \]
We may also express $Q$ in terms of wavelength,
\[ \frac{1}{Q} = \frac{q^2}{3 \lambda_0 m c^2} = \frac{4 \pi r_0}{3 \lambda_0} \]
and thus,
\[ \gamma = \frac{\omega_0}{Q} = \frac{2 \pi c}{\lambda_0} \cdot \frac{1}{Q} = \frac{8 \pi^2 r_0 c}{3 \lambda_0^2} = \frac{2 \pi q^2}{3 mc \lambda_0^2} \]
Furthermore, 
\[ \Delta \lambda = \frac{2 \pi c}{\omega_0} \cdot \frac{\Delta \omega}{\omega_0} = \frac{2 \pi c}{\omega_0} \cdot \frac{2r_0 \omega_0}{3 c} = \frac{4 \pi r_0}{3} \]

\subsection{The Line Profile For Emission and Scattering}

We know that the radiated power is,
\[ P = \frac{q^2 a^2(t)}{6 \pi c^3} \]
where $a(t)$ is the acceleration of the impulse response with some initial magnitude.
Therefore, the energy spectrum of radiated power is,
\[ \deriv{W}{\omega} = \frac{q^2}{6 \pi c^3} 4 \pi |\hat{a}(\omega)|^2 = \frac{q^2 \pi \omega_0^2}{3 \gamma c^3} \cdot \frac{I^2}{(2 \pi)^2} \cdot \frac{\gamma / (2 \pi)}{(\omega - \omega_0)^2 + \left( \gamma / 2 \right)^2} \]
where $I$ is the initial impulse. 
Now the initial energy of the ocillator is,
\[ W = \tfrac{1}{2} m \dot{x}^2 = \tfrac{1}{2} m I^2 \]
Therefore,
\begin{align*}
\frac{1}{W} \deriv{W}{\omega} = \frac{2 q^2 \omega_0^2}{12 \pi m \gamma c^3} \cdot \frac{\gamma / (2 \pi)}{(\omega - \omega_0)^2 + \left( \gamma / 2 \right)^2}
\end{align*}
Now recall that,
\[ \gamma = \frac{2 r_0 \omega_0^2}{3 c} = \frac{2 q^2 \omega_0^2}{12 \pi m c^3} \]
Therefore,
\[ \frac{1}{W} \deriv{W}{\omega} = \frac{\gamma / (2 \pi)}{(\omega - \omega_0)^2 + \left( \gamma / 2 \right)^2} = \phi(\omega) \]
so the radiation is emitted in a Lorentizan distribution. 
\bigskip\\
Now we consider the oscillator divin by an electric field such that $F = qE$. Then, the frequency response acceleration amplitude is,
\[ A = \omega^2 w_L(\omega) \left( \frac{q E}{m} \right) \]
Then the average power radiated is,
\[ \EV{P} = \frac{q^2 |A|^2}{12 \pi c^3} = \frac{q^4 E^2}{12 \pi m^2 c^3} \cdot \frac{\omega^4}{(\omega^2 - \omega_0^2)^2 + \gamma^2 \omega^2} \]
Then, the time averaged Poynting vector is,
\[ \EV{S} = \tfrac{1}{2} c E^2 \]
so we find, the scattering cross section is,
\[ \sigma(\omega) = \frac{q^4}{6 \pi m^2 c^4} \cdot \frac{\omega^4}{(\omega^2 - \omega_0^2)^2 + \gamma^2} = \frac{8 \pi r_0^2}{3} \cdot \frac{\omega^4}{(\omega^2 - \omega_0^2)^2 + \gamma^2} \]
In the limit $\omega \gg \omega_0$ we find,
\[ \sigma(\omega) = \frac{8 \pi r_0^2}{3} \]
which is the Thomson scattering limit. For $\omega \ll \omega_0$ we have,
\[ \sigma(\omega) = \frac{8 \pi r_0^2}{3} \cdot \left( \frac{\omega}{\omega_0} \right)^4 \]
which is the Rayleigh scattering limit. Finally, near resonance $\omega \approx \omega_0$ we have,
\[ \sigma(\omega) = \frac{8 \pi r_0^2}{3} \cdot \frac{\pi \omega_0^2}{2 \gamma} \phi(\omega) \]
However, recall that, 
\[ \gamma = \frac{2 r_0 \omega_0^2}{3 c} \]
Therefore,
\[ \sigma(\omega) = (2 \pi^2 r_0 c) \: \phi(\omega) \]
Therefore, the line profile and scattering cross section are entirely determined by two quantities, $\omega_0$, the resonant frequency given by the energy splitting, and $\gamma^{-1}$, the lifetime. We have given a classical value for the lifetime of,
\[ \gamma_{\text{classical}} = \frac{2 r_0 \omega_0^2}{3 c} \]
which gives a linewidth in wavelength which is constant. This value may be computed directly in time-independent perturbation theory and we find a quantum correction,
\[ \frac{1}{f} = \frac{\gamma_{\text{quantum}}}{\gamma_{\text{classical}}} \]
We must fix the above computations with this correction factor. We have,
\[ \sigma(\omega) = \frac{8 \pi r_0^2}{3} \cdot \frac{\omega^4}{(\omega^2 - \omega_0^2)^2 + \gamma^2} \]
and therefore, near resonance,
\[ \sigma(\omega) = \frac{8 \pi r_0^2}{3} \cdot \frac{\pi \omega_0^2}{2 \gamma} \: \phi(\omega) = (2 \pi^2 r_0 c) \: \phi(\omega) \: f \]
It turns out that,
\[ f = 4 \pi \left( \frac{\hbar \omega_0}{E_{\text{Ryd}}} \right)  \cdot \left( \frac{r_t}{a_0} \right)^2 \]
where $r_t$ is the positional overlap of the transition. 

\section{Time-Dependent Perturbation Theory}

\section{Two State Systems}

\newcommand{\Tr}[1]{\mathrm{Tr}\left( #1 \right)}

We can write an arbitary 2 by 2 Hermitian operator in the form,
\[ \hat{H}  = E_0 I + \frac{\hbar}{2} (\vec{g} \cdot \vec{\sigma}) \]
Furthermore, the density matrix,
\[ \hat{\rho} = \sum_{\psi} p_\psi \ket{\psi} \bra{\psi} \]
is clearly Hermitian since,
\[ \inner{\alpha}{\hat{\rho} \beta} = \sum_{\psi} p_\psi \inner{\alpha}{\psi} \inner{\psi}{\beta} = \overline{\sum_{\psi} p_\psi \inner{\beta}{\psi} \inner{\psi}{\alpha}} = \overline{\inner{\beta}{\hat{\rho} \alpha}} = \inner{\hat{\rho} \alpha}{\beta} \]
Equivalently,
\[ \hat{\rho} \ket{\alpha} = \sum_\psi p_\psi \ket{\psi} \inner{\psi}{\alpha} \]
and thus,
\[ \inner{\hat{\rho} \alpha}{\beta} = \sum_{\psi} p_\psi \overline{\inner{\psi}{\alpha}} \inner{\psi}{\beta} = \sum_{\psi} p_\psi \inner{\alpha}{\psi} \inner{\psi}{\beta} = \inner{\alpha}{\hat{\rho} \beta} \]
Therefore, we can write,
\[ \hat{\rho} = \tfrac{1}{2} (a I + \vec{p} \cdot \vec{\sigma} ) \]
However, we know that $\Tr{\hat{\rho}} = 1$ and thus,
\[ \Tr{\hat{\rho}} = \tfrac{1}{2} \Tr{aI} + \tfrac{1}{2} \vec{p} \cdot \Tr{\vec{\sigma}} = a \]
so $a = 1$. Thus,
\[ \hat{\rho} = \tfrac{1}{2} (I + \vec{p} \cdot \vec{\sigma} ) \]
Now, finally, we have,
\[ i \hbar \pderiv{\hat{\rho}}{t} = \frac{\hbar}{2} [\hat{H}, \hat{\rho}] = [\vec{g} \cdot \vec{\sigma}, \tfrac{1}{2} \vec{p} \cdot \vec{\sigma}] \]
However,
\[ [\sigma_i, \sigma_j] = 2 i \epsilon_{ijk} \sigma_k \]
Therefore,
\[  [\hat{H}, \hat{\rho}] = \frac{i \hbar}{2} \epsilon_{ijk} g_i p_j \sigma_k =  \frac{i \hbar}{2} (\vec{g} \times \vec{p}) \cdot \vec{\sigma} \]
Therefore,
\[ i \hbar \pderiv{\hat{\rho}}{t} =  \frac{i \hbar}{2} (\vec{g} \times \vec{p}) \cdot \vec{\sigma}  \]
This implies that, 
\[ \pderiv{\vec{p}}{t} = \vec{g} \times \vec{p} \]


\section{Com Alg Stuff}

\newcommand{\Frac}[1]{\mathrm{Frac}\left( #1 \right)}

\begin{lemma}
Let $A \subset B$ be an integral extension of domains with $A$ integrally closed in $K = \Frac{A}$. Then in $F = \Frac{B}$ we have $B \cap K = A$. 
\end{lemma}

\begin{proof}
For $x \in B \cap K$ we have $x = \frac{a}{b}$ with $a, b \in A$ and $x \in B$. Thus, we know that $x$ satisfies some monic $f \in A[X]$. Since $x \in K$ then $x \in A$ since $A$ is integrally closed. 
\end{proof}

\begin{proposition}
Let $A$ be an integrally closed domain. Then $A[X_1, \dots, X_n]$ is integrally closed.
\end{proposition}

\begin{proof}
(DO THIS)
\end{proof}

\begin{lemma}
Let $R$ be a ring and consider the ring map,
\[ R[X_1, \dots, X_n] \to \Hom{\mathrm{Set}}{R^n}{R} \]
This map is injective if $R$ is an infinite domain. 
\end{lemma}

\begin{proof}
We need to show that if $f(x_1, \dots, x_n) = 0$ for an infinite subset of $(x_1, \dots, x_n) \in R^n$ then $f = 0$ in $R[X_1, \dots, X_n]$
\bigskip\\
First consider the case $n = 1$.
Consider $K = \Frac{R}$ then $K[X]$ is Euclidean. Thus, any nonconstant polynomial $f$ can have at most $\deg{f}$ roots in $K$ and thus also in $R \subset K$ which implies that if $f(r) = 0$ for an infinite set of $r$ then $f = 0$ since $\deg{f}$ is finite.
\bigskip\\
Now we proceed by induction. We assume the theorem for $n$ and consider,
\[ f \in R[X_1, \dots, X_{n+1}] = R[X_1, \dots, X_{n}][X] \]
The polynomial $Q \in R[X]$ via $Q(X) = f(x_1, \dots, x_n, X)$ for fixed $x_1, \dots, x_n$ is a polynomial in $X$. We know $Q(x) = f(x_1, \dots, x_n, x) = 0$ for any $x \in R$ so, by the case $n = 1$, we have $f(x_1, \dots, x_n) \in R[X]$ is the zero polynomial for each choice of $x_1, \dots, x_n$. Thus, in the ring $R' = R[X]$ which is an infinite domain we find that $f(x_1, \dots, x_n) = 0 \in R[X]$ for all $(x_1, \dots, x_n) \in R^n$. Therefore, by the inductive hypothesis for $n$ we have, $f = 0$ is the zero polynomial in $R[X][X_1, \dots, X_n]$ since $f(x_1, \dots, x_n)$ on the infinite set $R^n \subset R[X]^n$.   
\end{proof}

\begin{remark}
The infinite condition is needed since the polynomial $X + X^2$ is always zero on $\mathbb{F}_2$ which is certainally a domain. 
\end{remark}

\begin{theorem}
Let $F / K$ be an extension of infinite fields. And suppose that $A,B \in \GL{n}{K}$ are conjugate inside $\GL{n}{F}$. Then $A,B$ are conjugate in $\GL{n}{K}$.
\end{theorem}

\begin{proof}
There must exist a matrix $P \in \GL{n}{F}$ such that,
\[ PA = BP \]
Then let $p_{ij} \in F$ be the coefficients and consider the field $E = K(p_{ij})$ and choose a basis $\{ e_i \}$ of $E / K$ (this basis may be infinite). Now there must be a finite sum,
\[ P = \sum_{i = 1}^N e_i P_i \]
with $P_i \in \mathrm{M}_N(K)$ and furthermore since $e_i$ is a basis we have,
\[ P_i A = B P_i \]
for each $i$. Now consider the polynomial,
\[ f(x_1, \dots, x_n) = \det{\left( \sum_{i = 1}^N x_i P_i \right)} \]
with $f \in K[x_1, \dots, x_n]$. We know that $f(e_1, \dots, e_n) \in F$ is nonzero since $P$ is invertable and thus $f$ is not the zero polynomial. Therefore there must exist $a_1, \dots, a_n \in K$ such that $f(a_1, \dots, a_n) \neq 0$ because otherwise $f : K^n \to K$ would be the zero function which we have proven is not possible if $f$ is not he zero polynomial. Therefore, the matrix,
\[ P' = \sum_{i = 1}^N a_i P_i \]
is invertable and has coefficients in $K$ so $P' \in \GL{n}{K}$. Furthermore,
\[ \sum_{i = 1}^N x_i P_i A = \sum_{i = 1}^N x_i B P_i \]
which implies that,
\[ P' A = B P' \]
so $A$ and $B$ are conjugate in $\GL{n}{K}$.  
\end{proof}

\subsection{Symmetric Polynomials}

\newcommand{\galgroup}[1]{\mathrm{Gal}\left( #1 \right)}
\newcommand{\Disc}[1]{\mathrm{Disc}\left( #1 \right)}

\begin{remark}
Let $R$ be an integrally closed domain with fraction field $K = \Frac{R}$.
\end{remark}

\begin{definition}
In $K(Y_1, \cdots, Y_n)$, the fraction field of $R[Y_1, \cdots, Y_n]$, the elementary symmetric polynomials are, 
\[ u_i = \sum_{k_1 < k_1 < \dots < k_i} Y_{k_1} Y_{k_2} \cdots Y_{k_i} \]
We define the fields,
\[ K_0 = K(u_1, \dots, u_n) \subset K(Y_1, \dots, Y_n) = E_0 \]
\end{definition}

\begin{remark}
I claim that there is an abstract isomorphism, $K_0 \cong K(X_1, \dots, X_n)$. There is a map $K(X_1, \dots, X_n) \embed K(Y_1, \dots, Y_n)$ by sending $X_i \mapsto u_i$. We need to show this map is injective i.e. the elements are algebraically independent. 
\end{remark}

\begin{lemma}
Let $R$ be a domain then the map $\phi : R[X_1, \dots, X_n] \to R[Y_1, \dots, Y_n]$ via $\phi : X_i \mapsto u_i$ is injective.
\end{lemma}

\begin{proof}
We regard $R[X_1, \dots, X_n]$ as a function algebra over $K = \overline{\Frac{R}}$. Then consider the map $\tilde{\phi} : K^n \to K^n$ by $\tilde{\phi}(t_1, \dots, t_n) =  (s_1, \dots, s_n)$ where $s_i = u_i(t_1, \dots, t_n)$. Then I claim that $\phi = \tilde{\phi}^*$ because $\tilde{\phi}^*(X_i) = X_i \circ \tilde{\phi} = u_i$ as a function of $t_i$ since $X_i \circ \tilde{\phi}(t_1, \dots, t_n) = s_i = u_i(t, \dots, t_n)$. 
\bigskip\\
Furthermore, $\tilde{\phi} : K^n \to K^n$ is surjective because for any $(v_1, \dots, v_n) \in K^n$ the polynomial $f \in K[X_1, \dots, X_n]$ given by,
\[ X^n + v_1 X^{n-1} + \cdots + v_n \]
has must split in $K$ since the field is algebraically closed. Then,
\[  X^n + v_1 X^{n-1} + \cdots + v_n = (X + t_1) \cdots (X + t_n) \]
so by Vieta, $v_i = u_i(t_i)$ and thus $\tilde{\phi} : K^n \to K^n$ is surjective. This implies that $\phi = \tilde{\phi}^*$ is injective becuase if $\phi(f) = f \circ \tilde{\phi} = 0$ then, as a function $K^n \to K^n$ we must have $f = 0$ since $\tilde{\phi}$ is surjective. Therefore $f$ is the zero polynomial in $R[X_1, \dots, X_n]$ so $\phi$ is injective.
\end{proof}


\begin{proposition}
Let $f_0 \in K_0[X]$ be the polynomial,
\[ X^n - u_1 X^{n-1} + u_2 X^{n-2} + \cdots + (-1)^n u_n \]
Then $E_0$ is the splitting field of $f_0$ and $\galgroup{E_0/K_0} \cong S_n$.
\end{proposition}

\begin{proof}
By Vieta, $f_0(X) = (X - Y_1) \cdots (X - Y_n)$ so because $E_0 = K(Y_1, \cdots Y_n)$ we have that $E_0$ is the splitting field of $f_0$ over $K_0$. Therefore, $E_0 / K_0$ is a normal extension and also a seperable extension because $f_0$ is clearly a seperable polynomial by construction. Therefore, $E_0/K_0$ is Galois. Futhermore, consider $G =  S(\{Y_1, \cdots, Y_n\}) \cong S_n$. Any $\sigma \in G$ satisfies $\sigma(u_i) = u_i$ because they are unique with respect to reordering. We extend $\sigma : E_0 \to E_0$ by fixing it on $K$. Then $\sigma|_{K_0} = \id_{K_0}$ because $K_0 = K(u_1, \cdots u_n)$. Thus, $G \hookrightarrow \galgroup{E_0/K_0} \hookrightarrow S_n \cong G$. Therefore, $G \cong \galgroup{E_0/K_0}$. 
\end{proof}

\begin{corollary}
Any symmetric polynomial is generated by elementary symmetric polynomials.
\end{corollary}

\begin{proof}
Let $f \in R[Y_1, \dots, Y_n]$ be symmetric. For any automorphism $\sigma \in \galgroup{E_0/K_0}$, $\sigma(f) = f$ because the variables are symmetric under exchange. Therefore, $f$ is fixed by every Galois automorphism so $f \in E_0^{\galgroup{E_0/K_0}} = K_0 = K(u_1, \dots, u_n)$ by the Galois correspondence.
\bigskip\\
Now $A = R[u_1, \dots, u_n]$ is integrally closed and $B = R[Y_1, \dots, Y_n]$ is integral over $A$ since $f_0 \in A[X]$ is monic and each $Y_i \in B$ is a root. Therefore, by a previous lemma,
\[ B \cap K_0 = A = R[u_1, \dots, u_n] \]
and therefore $f \in R[u_1, \dots, u_n]$ so $f$ is generated by symmetric polynomials.
\end{proof}

\begin{corollary}
Let $K$ be a field and $f \in K[X]$ with splitting field $E$ such that $f(X) = a(X - \alpha_1) \cdots (X - \alpha_n)$ then any symmetric polynomial in the roots is given by a universal polynomial in the coefficients of $f$.  
\end{corollary}

\begin{definition}
$\Disc{f} = \Delta = \prod\limits_{i < j} (\alpha_i - \alpha_j)^2$ is a symmetric polynomial in the roots of $f$ and therefore expressible as a polynomial of the coefficients of $f$. 
\end{definition}

\begin{proposition}
$f \in K[X]$ is seperable if and only if $\Disc{f} \neq 0$
\end{proposition}

\begin{proof}
$\Disc{f} = \prod\limits_{i < j} (\alpha_i - \alpha_j)^2 = 0$ if and only if one of the factors is zero i.e. for $i < j$ we must have $\alpha_i - \alpha_j = 0$ so $\alpha_i = \alpha_j$. Thus, $f$ has multiple roots in its splitting field and is thus non-seperable if and only if $\Disc{f} = 0$. 
\end{proof}


\section{Ramification}

\newcommand{\stalk}[2]{\mathcal{O}_{#1, #2}}
\newcommand{\Spec}[1]{\mathrm{Spec}\left(#1\right)}
\newcommand{\Proj}[1]{\mathrm{Proj}\left(#1\right)}
\newcommand{\mSpec}[1]{\mathrm{mSpec}\left(#1\right)}
\newcommand{\q}{\mathfrak{q}}
\newcommand{\p}{\mathfrak{p}}

\newcommand{\Ann}[2]{\mathrm{Ann}_{#1}\left( #2 \right)}
\newcommand{\Supp}[2]{\mathrm{Supp}_{#1}\left( #2 \right)}

\begin{definition}
Given a map of schemes $f : X \to Y$ over $S$ we get an exact sequence,
\begin{center}
\begin{tikzcd}
f^* \Omega_{Y/S} \arrow[r] & \Omega_{X/S} \arrow[r] & \Omega_{X / Y} \arrow[r] & 0
\end{tikzcd}
\end{center}
We say that $f$ is ramified at $x \in X$ if $(\Omega_{X / Y})_x \neq 0$ which is equivalent to the map $f_x : (\Omega_{Y / S})_{f(x)} \to (\Omega_{X / S})_x$ not being surjective. Furthermore define,
\begin{enumerate}
\item The support of $\Omega_{X / Y}$ is called the \textit{ramification locus}
\item $f(\mathrm{Supp}_{\struct{X}}(\Omega_{X/Y}))$ is the \textit{branch locus}
\item if $\Omega_{X/Y} = 0$ then $f$ is \textit{formally unramified}
\item $f$ is \textit{unramified} if $f$ is formally unramified and locally of finite type
\item $f$ is \textit{G-unrmaified} if $f$ is formally unramified and locally of finite presentation 
\end{enumerate}
\end{definition}

\begin{lemma}
Let $f : X \to Y$ be locally of finite type. Then the following are equivalent,
\begin{enumerate}
\item the morphism $f : X \to Y$ is unramified at $x \in X$ 
\item the stalk map $f^\#_x : \stalk{Y}{f(x)} \to \stalk{X}{x}$
induces a finite seperable extension $\kappa(f(x)) / \kappa(x)$ and $f^\#_x(\m_{f(x)})\stalk{X}{x} = \m_x$
\end{enumerate} 
\end{lemma}

\begin{proof}
(DO THIS PROOF)
\end{proof}

(DEFINE RAMIFICATION INDEX)

\begin{remark}
A ring map $\phi : A \to B$ corresponds to morphism of affine schemes,
\[ \hat{\phi} : \Spec{B} \to \Spec{A} \]
which is ramified at $\q \subset B$ iff $(\Omega_{B / A})_{\q} \neq 0$ or equivalently if $\q \in \Supp{B}{\Omega_{B / A}}$. 
\bigskip\\
In particular if $\phi$ is finite then $\Omega_{B / A}$ is a finitely generated $B$-module so,
\[ \Supp{B}{\Omega_{B / A}} = V(\Ann{B}{\Omega_{B/A}}) \]
and thus $\q$ is ramified iff $\q \supset \Ann{B}{\Omega_{B/A}}$. This motivates the following definition. 
\end{remark}

\begin{definition}
Let $\phi : A \to B$ be finite. Then define the different $\delta_{B/A} = \Ann{B}{\Omega_{B/A}}$. 
\end{definition}

\begin{remark}
The important fact about the different is that it classifies ramification in the sense that $\phi$ is ramified at $\q$ (or we say $\q$ ramifies) iff $\delta_{B/A} \subset \q$. 
\end{remark}

\begin{corollary}
Let $\phi : A \to B$ be a finite map with $B$ a Dedekind domain. Then only finitely many points ramify.
\end{corollary}


\subsection{Ramification For Curves}

\begin{definition}
We say a scheme $X$ is \textit{normal} if each point $x \in X$ that $\stalk{X}{x}$ is normal i.e. an integrally closed local domain. 
\end{definition}

\begin{lemma}
Any normal local ring of dimension one is a DVR.
\end{lemma}

\begin{definition}
If $X$ is a normal curve then each $\stalk{X}{x}$ is a DVR so we may choose a uniformizer $\pi_x$. For a morphism of normal cuves $f : X \to Y$. Since $\m_x = (\pi_x)$ clearly the ramification index is the power $e$ such that $f^\#_{x}(\pi_{f(x)}) = u \pi_x^e$ for some $u \in \stalk{X}{x}^\times$. 
\end{definition}

\begin{proof}

\end{proof}

\subsection{Ramification for Dedekind Domains}

\begin{proof}
Since $B$ is Dedekind domain there is a finite unique factorization of $\delta_{B / A}$ into prime ideals. These are the only primes lying about $\delta_{B/A}$ and thus exactly the set of primes which ramify of which there are finitely many.  
\end{proof}

\begin{proposition}
Let $\phi : A \to B$ be a finite inclusion of Dedekind domains with finite residue fields. Then $\q$ ramifies iff the prime $\p = \phi^{-1}(\q)$ extends to the ideal $\p B$ with factorization,
\[ \phi(\p) B  = \prod_{i = 1}^{n} \q_i^{e_i} \]
with $\q_i$ distinct, $\q_0 = \q$, and $e_i > 1$. 
\end{proposition}

\begin{proof}
At a point $\p \subset A$ the residue field $\kappa(\p) = A / \p$ is a finite field which is perfect so $\kappa(\q) / \kappa(\hat{\phi}(\q))$ is automatically finite seperable. Thus $\q \subset B$ is unramified iff,
\[ \phi(\phi^{-1}(\q) A_\p) B_{\q} = \q B_{\q} \]
Since $B_\q$ is also Dedekind, by unique factorization of ideals this is equivalent to $e_0 = 1$ since localizing the above factorization gives,
\[ \phi(\p) B_\q = (\phi(\p) B)_\q = \prod_{i = 1}^{n} \q_i^{e_i} B_\q = \q_0^{e_0} B_\q = \q^{e_0} B_\q \]
\end{proof}

\begin{proposition}
DIFFERENT IN TERMS OF TRACE
\end{proposition}

\begin{lemma}
If $B = A[t]/(f(t))$ then,
\begin{align*}
\Omega_{B / A} & = (B \cdot \d{t}) /(f'(t) \cdot \d{t})
\\
\delta_{B / A} & = (f'(t)) \subset B
\end{align*}
\end{lemma}

\begin{proof}
$\Omega_{B / A}$ is generated by $\d{x}$ for $x \in B$. For any $g(t) \in A[t]/(f(t))$ then by the Leibniz relation, $\d{g(t)} = g'(t) \d{t}$. Thus, $\Omega_{B / A}$ is generated over $B$ by $\d{t}$. Furthermore, $f(t) = 0$ so $f'(t) \d{t} = 0$. This is the only relation. Furthermore,
\[ \delta_{B / A} = \Ann{B}{\Omega_{B/A}} = (f'(t)) \]
by the following lemma.
\end{proof}

\begin{lemma}
Let $A$ be a ring and $B$ an $A$-algebra with structure map $\phi : A \to B$ then $\Ann{A}{B} = \ker{\phi}$. 
\end{lemma}

\begin{proof}
An element $a \in \Ann{A}{B}$ iff $\phi(a)b = 0$ for all $b \in B$. In particular,
\[ a \in \Ann{A}{B} \iff \phi(a) \cdot 1_B = 0 \iff \phi(a) = 0 \iff a \in \ker{\phi} \]
\end{proof}
\newcommand{\ints}[1]{\mathcal{O}_{#1}}

\begin{corollary}
If $K / \Q$ is a number field with $\ints{K} = \Z[\alpha]$ and let $\alpha$ have minimal polynomial $f \in \Z[X]$. Then a prime $\p \subset \ints{K}$ ramifies iff $f'(\alpha) \in \p$. 
\end{corollary}

\begin{proof}
We have $\ints{K} = \Z[\alpha]/(f(\alpha))$ so $\delta_{\ints{K}/\Z} = (f'(\alpha)) \subset \Z[\alpha]/(f(\alpha))$. Then we know that $\p$ ramifies iff $\p \supset \delta_{\ints{K}/\Z}$. 
\end{proof}

\subsection{The Discriminant of an Extension}

\newcommand{\Norm}{\mathcal{N}}
\newcommand{\I}{\mathcal{I}}

\begin{definition}
Let $\phi : A \to B$ be a finite map of Dedekind domains with finite residue fields. Then we define the ideal norm as the homomorphism $\Norm_{B/A} : \I_{B} \to \I_{A}$ of the ideal groups which on the prime ideals which generate $\I_B$ acts via,
\[ \Norm_{B / A}(\q) = \p^{[B / \q : A / \p]} \]
where $\p = \phi^{-1}(\q)$. 
\end{definition}


\begin{definition}
Then we define the relative discriminant $\Delta_{B/A} = \Norm_{B/A}(\delta_{B/A}) \subset A$.
\end{definition}

\begin{proposition}
Primes $\p \subset A$ ramify iff $\p \supset \Delta_{B / A}$. 
\end{proposition}

\begin{proof}
We write,
\[ \p B = \prod_{i = 1}^n \q_i^{e_i} \]
$\p$ ramifies exactly when some $e_i > 1$ in which case we know $\q_i \supset \delta_{B/A}$ and thus,
\[ \p \supset \p^{[B / \q : A / \p]} \supset \Norm_{B / A}(\delta_{B/A}) = \Delta_{B/A} \]
Conversely, suppose that $\p$ does not ramify then we must have $e_i = 1$ for all $i$. Then $\q_i \not\supset \delta_{B/A}$ so by unique factorization, no primes dividing $\delta_{B/A}$ lie above $\p$ which implies that, $\Delta_{B/A} = \Norm_{B/A}(\delta_{B/A})$ does not contain $\p$ in its factorization. Thus, by the uniqueness of factorization,
\[ \p \not\supset \Delta_{B/A} \]
\end{proof}



\section{Jacobinson Radical}

\newcommand{\Jac}[1]{\mathrm{Jac}\left( #1 \right)}

\begin{remark}
Here a ring $R$ is unital but not commutative.
\end{remark}


\begin{definition}
The Jacobinson radical $\Jac{R}$ is the intersection of all maximal left-ideals.
\end{definition}

\begin{proposition}
Let $R$ be commutative. Then,
\[ \Jac{R} = \{ x \in R \mid 1 + R x \subset R^\times \} \]
\end{proposition}

\begin{proof}
If $x \in \Jac{R}$ then for each maximal ideal $\m$ we have $x \in \m$ so $1 + a x \notin \m$ else $1 \in \m$. Thus $1 + ax \in R^\times$. 
\bigskip\\
Suppose that $x \notin \Jac{R}$ so $x \notin \m$ for some $\m$. Thus $[x] \in R / \m$ is nonzero but $R / \m$ is a field so $[x]$ is invertable and thus $\exists y \in R$ such that $1 - yx \in \m$ so $1 - yx$ is not a unit. 
\end{proof}

\section{Hopf Fibration and Spin}

We have the Hopf fibration,
\begin{center}
\begin{tikzcd}
S^1 \arrow[r, hook] & S^3 \arrow[r, "\pi"] & S^2
\end{tikzcd}
\end{center}
which is quaternionic notation is,
\[ z =  x + i y \in S^1 \mapsto x + \bf{k} y \in S^3 \text{ and } q \in S^3 \mapsto q \bf{k} \bar{q} \in S^2 \subset \H \]
However, notice that,
\[ \CP^1 = (\C^2 \setminus \{ 0 \}) / \C^\times = (\C^2 \setminus \{ 0 \})/\R^\times /(\C^\times / \R^\times) \]
However, $(\C^2 \setminus \{ 0 \})/\R^\times \cong S^3$ and $\C^\times / \R^\times = S^1$ and $\CP^1 \cong S^2$ so this gives,
\[ \CP^1 = S^3 / U(1) \quad \text{topologically} \quad S^2 = S^3 / S^2 \]
and thus we have a fibration,
\begin{center}
\begin{tikzcd}
S^1 \arrow[r, hook] & S^3 \arrow[r, "\pi"] & S^2
\end{tikzcd}
\end{center}
comming from the fibration,
\begin{center}
\begin{tikzcd}
U(1) \arrow[r, hook] & (\C^2 \setminus \{ 0 \}) / \R^\times  \arrow[r, "\pi"] & \CP^1
\end{tikzcd}
\end{center}
which makes $S^3$ a principle $U(1)$-bundle over $\CP^1 \cong S^2$ and we include the fibre $U(1)$ as the $U(1)$-torsor $\pi^{-1}([1 : 0]) = (z, 0)$ over the north pole or point at infinity of $S^2 \cong \CP^1$. Thus,
\[ z \mapsto (z, 0) \quad \quad (z, w) \mapsto [z : w] \]
Now the map $\CP^1 \to S^2$ defined by stereographic projection,
\[ [z : w] \mapsto \left( \frac{2 \Re{z \bar{w}}}{|z|^2 + |w|^2}, \frac{2 \Im{z \bar{w}}}{|z|^2 + |w|^2}, \frac{|z|^2 - |w|^2}{|z|^2 + |w|^2} \right) \]
On the affine space $\A^1 \{ [ z / w : 1 ] \mid w \neq 0 \}$ inside $\CP^1$ this is eactly stereographic projection to the affine space inside $S^2$ by removing the north pole. 
If we take a representative in the image of $S^3 \to \CP^1$ such that $|z|^2 + |w|^2 = 1$ then we get,
\[ [z : w] \mapsto \left( 2 \Re{z \bar{w}}, 2 \Im{z \bar{w}},  |z|^2 - |w|^2 \right) \]
Then there is a commutative diagram,
\begin{center}
\begin{tikzcd}
U(1) \arrow[d] \arrow[r, hook] & (\C^2 \setminus \{ 0 \}) / \R^\times \arrow[d]  \arrow[r] & \CP^1 \arrow[d]
\\
S^1 \arrow[r, hook] & S^3 \arrow[r, "\pi"] & S^2
\end{tikzcd}
\end{center}
where the bottom map is the Hopf fibration. These isomorphism are,
\begin{align*}
U(1) \to S^1 \quad & \quad z = x + i y \mapsto x + \bf{k} y 
\\
S^3 \to S^3 \quad & \quad (x_1 + i y_1, x_2 + i y_2) \mapsto x_1 + \bf{i} y_2 + \bf{j} x_2 + \bf{k} y_1
\\
\CP^1 \to S^2 \quad & \quad [x_1 + i y_1 : x_2 + i y_2] \mapsto (2 x_1 x_2 + 2 y_1 y_2) \bf{i} + (2 y_1 x_2 - 2 y_2 x_1) \bf{j} +  (x_1^2 + y_1^2 - x_2^2 - y_2^2) \bf{k}
\end{align*}
Now, given a unit quaternion $q = w + x \bf{i}  + y \bf{j}  + z \bf{k}$ consider $\pi  : S^3 \to S^2$,
\begin{align*}
q \bf{k} \bar{q} & = (w \bf{k} - x \bf{j} + y \bf{i} - z) (w - x \bf{i} - y \bf{j} - z \bf{k})
\\
& = (2 w y + 2 x z) \bf{i} + (2 yz - 2 w x) \bf{j} + (w^2 + z^2 - x^2 - y^2) \bf{k}
\end{align*} 
Therefore taking the composition $S^3 \to S^3 \to S^2$ we get the map,
\[ (x_1 + i y_1, x_2 + i y_2) \mapsto (2 x_1 x_2 + 2 y_1 y_2) \bf{i} + (2 x_2 y_1 - 2 x_1 y_2) + (x_1^2 + y_1^2 - x_2^2 - y_2^2) \bf{k}  \]
which is exactly the map $S^3 \to \CP^1 \to S^2$. Furthermore $U(1) \to S^3 \to S^3$ is simply $z \mapsto (z, 0) \mapsto x + \bf{k} y$ and $U(1) \to S^1 \to S^3$ is $z \mapsto x + \bf{k} y$. Therefore, the diagram commutes so these fibrations are the same. In particular, in the complex representation $S^3$ is the space of normalized spin-$\tfrac{1}{2}$ states and $S^2 \cong \CP^1$ is the Bloch sphere of spin orientations so these are related by the Hopf fibration and the ray space of physical states is $S^3 / U(1) = S^2$ is exactly the space of spin orientations. 

\section{Generalized Hopf Fibration}

Given a real normed division algebra $A$ there is a fibration,
\begin{center}
\begin{tikzcd}
U(A) \arrow[r, hook] & S(A^2) \arrow[r, two heads] & \P^1(A) 
\end{tikzcd}
\end{center} 
where,
\begin{align*}
U(A) & = A^\times = \{ z \in A \mid |z|^2 = 1 \} \subset A^\times
\\
S(A^2) & = \{ (z,w) \in A^2 \mid |z|^2 + |w|^2 = 1 \} 
\\
\P^1(A) & = (A \times A \setminus \{0\}) / A^\times
\end{align*} 
There is a map $S(A^2) \to \P^1(A)$ via $(z, w) \mapsto [z : w]$ whose fibers are the $U(A)$-torsors $\{ (z u, w u) \mid u \in U(A) \subset A^\times \}$ since $(z u, w u) \mapsto [z u : w u] = [z : w]$ under the quotient by the right-action of $U(A)$ and multiplication by $u \in U(A)$ preserves the sphere since,
\[ |zu|^2 + |wu|^2 = (|z|^2 + |w|^2)|u|^2 = 1 \]

\section{Functorial Maps on Cohomology}

\newcommand{\J}{\mathcal{J}}
\newcommand{\Pic}[1]{\mathrm{Pic}\left( #1 \right)}

\begin{remark}
Here $f^*$ is the inverse image functor for abelian sheaves (not for modules). Here, we use the exactness of $f^*$ which only holds for modules if $f$ is flat. In general, on modules $f^*$ is right exact but only exact when $f$ is flat.
\end{remark}

\begin{theorem}
Let $f : X \to Y$ be a morphism of topological spaces (or sites) and $\F$ a sheaf on $Y$. Then there is a natural map,
\[ H^n(Y, \F) \to H^n(X, f^* \F) \]
\end{theorem}

\begin{proof}
There is a natural adjunction map $\F \to f_* f^* \F$. Now take an injective resolution $\I^\bullet$ of $\F$ and apply $f^*$ to give,
\begin{center}
\begin{tikzcd}
0 \arrow[r] & f^* \F \arrow[r] & f^* \I^\bullet
\end{tikzcd}
\end{center}
Since $f^*$ is exact, the above sequence is exact. Now we choose an injective resolution $\J^\bullet$ of $f^* \J$ and get a diagram,
\begin{center}
\begin{tikzcd}
0 \arrow[r] & f^* \F \arrow[d, equals] \arrow[r] & f^* \I^\bullet \arrow[d, dashed]
\\
0 \arrow[r] & f^* \F \arrow[r] & \J^\bullet
\end{tikzcd}
\end{center}
lifing the identity since $\J^\bullet$ is injective and the top row is exact. Thus, we have a sequence of complexes $\I^\bullet \to f_* f^* \I^\bullet \to f_* \J^\bullet$. Apply the global sections functor $\Gamma(Y, -)$ gives a sequence of complexes,
\begin{center}
\begin{tikzcd}
\Gamma(Y, \I^\bullet) \arrow[r] \arrow[d, equals] & \Gamma(Y, f_* f^* \I^\bullet) \arrow[r] \arrow[d, equals] & \Gamma(Y, f_* \J^\bullet) \arrow[d, equals]
\\
\Gamma(Y, I^\bullet) \arrow[r] & \Gamma(X, f^* \I^\bullet) \arrow[r] & \Gamma(X, \J^\bullet)
\end{tikzcd}
\end{center}
Taking the cohomology of these morphisms of complexes gives maps,
\begin{center}
\begin{tikzcd}
H^n(\Gamma(Y, I^\bullet)) \arrow[r] \arrow[d, equals] & H^n(\Gamma(X,  f^* \I^\bullet)) \arrow[r] \arrow[d, equals] & H^n(\Gamma(X, \J^\bullet)) \arrow[d, equals]
\\
H^n(Y, \F) \arrow[r] & H^n(\Gamma(X,  f^* \I^\bullet)) \arrow[r] & H^n(X, f^* \F)
\end{tikzcd}
\end{center}
\end{proof}

\begin{remark}
We may give an abstract nonsense proof to get that this map is natural and furthermore commutes with connecting homomorphisms. The natural adjunction map $\F \to f_* f^* \F$ gives a morphism $H^0(Y, -) \to H^0(X, f^* -)$ of left-exact functors where $H^0(X, f^* -)$ is left-exact since $f^*$ is exact. Furthermore, exactness of $f^*$ makes $H^*(X, f^* - )$ a $\delta$-functor. However, $H^*(Y, -)$ is a universal $\delta$-functor to the map $H^0(Y, -) \to H^0(X, f^* - )$ lifts to give a morphism of $\delta$-functors,  \begin{center}
\begin{tikzcd}
H^*(Y, -) \arrow[r] & H^*(X, f^* - )
\end{tikzcd}
\end{center} 
\end{remark}

\begin{proposition}
Let $f : X \to Y$ be a morphism of topological spaces (or sites) and $\F$ a sheaf on $X$. Then there is a natural map,
\[ H^n(Y, f_* \F) \to H^n(X, \F) \]
\end{proposition}

\begin{proof}
There is a natural adjunction map $f^* f_* \F \to \F$ so we use the natural map derived above $H^*(Y, -) \to H^*(X, f^* - )$ applied to $f_* \F$ giving,
\begin{center}
\begin{tikzcd}
H^n(Y, f_* \F) \arrow[r] & H^n(X, f^* f_* \F) \arrow[r] & H^n(X, \F)
\end{tikzcd}
\end{center}
\end{proof}

\begin{remark}
Because $f_*$ is not exact neither the above direct proof nor the abstract nonsense proof could work in this case. This is due to the fact that $H^*(Y, f_* -)$ is not a $\delta$-functor in general and so we cannot use facts about morphisms of $\delta$-functors. 
\end{remark}

\subsection{The Case for Modules}

\newcommand{\K}{\mathcal{K}}

\begin{remark}
Given a morphsim $f : X \to Y$ of locally ringed spaces, the above proof does not work for the functors $f_* : \Mod_{\struct{X}} \to \Mod_{\struct{Y}}$ and $f^* : \Mod_{\struct{Y}} \to \Mod_{\struct{X}}$ since the latter is not exact in general. We use a more general method. See Tag 01F7.
\end{remark}

\begin{proposition}
Let $f : X \to Y$ be a morphism of locally ringed spaces and $\F$ a sheaf on $X$. Then there is a natural map,
\[ H^n(Y, f_* \F) \to H^n(X, \F) \]
\end{proposition}

\begin{proof}
Take an injective resolution $\I^\bullet$ of $\F$ and consider the sequence,
\begin{center}
\begin{tikzcd}
0 \arrow[r] & f_* \F \arrow[r] & f_* \I^\bullet
\end{tikzcd}
\end{center}
Now we take injective resolutions of $f_* \F$ and the complex $\I^\bullet$ to get,
\begin{center}
\begin{tikzcd}
0 \arrow[r] & f_* \F \arrow[r] \arrow[d] & f_* \I^\bullet \arrow[d, "\alpha"] 
\\
& \J^\bullet \arrow[r, dashed, "\beta"] & \K^\bullet
\end{tikzcd}
\end{center}
with $\alpha$ a quasi-isomorphism.
Now $f_* \F \to \J^\bullet$ is a resolution and thus an exact sequence and $\K^\bullet$ is an injective complex over $f_* \F$ so there exists a lift $\beta : \J^\bullet \to \K^\bullet$. Therefore, applying the sections functor $\Gamma(Y, -)$, we get maps of complexes,
\begin{center}
\begin{tikzcd}
& \Gamma(Y, f_* \I^\bullet) \arrow[d, "\alpha_Y"] \arrow[r, equals] & \Gamma(X, \I^\bullet)
\\
\Gamma(Y, \J^\bullet) \arrow[r, "\beta"] & \Gamma(Y, \K^\bullet)
\end{tikzcd}
\end{center} 
I claim that $\Gamma(Y, -)$ takes $\alpha : f_* \I^\bullet \to \K^\bullet$ to a quasi-isomorphism $\alpha_Y$. This follows from the following Lemma given that $f_* \I^\bullet$ and $\K^\bullet$ are complexes of $\Gamma(Y,-)$-acyclic objects. The complex $f_* \I^\bullet$ is acyclic because it is flasque since $\I^\bullet$ is a complex of injective $\struct{X}$-modules which are flasque and $f_*$ preserves flasqueness. Furthermore, $\K^\bullet$ is a complex of injective $\struct{Y}$-modules which are thus $\Gamma(Y, -)$-acyclic. Therefore, $\alpha_Y$ is a quasi-isomorphism so taking cohomology gives,
\begin{center}
\begin{tikzcd}
& & H^n(\Gamma(Y, f_* \I^\bullet)) \arrow[d, "\alpha_Y"] \arrow[r, equals] & H^n(\Gamma(X, \I^\bullet)) \arrow[r, equals] & H^n(X, \F)
\\
H^n(Y, f_* \F) \arrow[r, equals] & H^n(\Gamma(Y, \J^\bullet)) \arrow[r, "\beta"] & H^n(\Gamma(Y, \K^\bullet))
\end{tikzcd}
\end{center} 
and on homology, $\alpha_Y : H^n(\Gamma(Y, f_* \I^\bullet)) \to H^n(\Gamma(Y, \J^\bullet))$ is an isomorphism since $\alpha_Y$ is a quasi-isomorphism. Therefore, composing $\alpha_Y^{-1} \circ \beta$ gives the canonical map,
\[ H^n(Y, f_* \F) \to H^n(X, \F)  \]
\end{proof}

\begin{lemma}
Let $F : \mathcal{A} \to \mathcal{B}$ be an additive functor between abelian categories. Let $\alpha : I^\bullet \to J^\bullet$ be a quasi-isomorphism of complexes of $F$-acyclic objects. Then $F(\alpha) : F(I^\bullet) \to F(J^\bullet)$ is a quasi-isomorphism. 
\end{lemma}

\begin{proof}
Conisder the mapping cone $C(\alpha)$ which fits into the long exact sequence such that $\alpha$ is a quasi-isomorphism iff $C(\alpha)$ is acyclic. Furthermore, additive functors preserve mapping cones (since they preserve direct sums and compositions) so $F(\alpha)$ is a quasi-isomorphism iff $F(C(\alpha))$ is acyclic. However, since $I^\bullet$ and $K^\bullet$ are complexes of $F$-acyclic objects then so is $C(\alpha)$ so $\alpha$ is an acyclic complex of $F$-acyclic objects and thus $F(C(\alpha))$ is acyclic since $F$ preserves exact sequences of $F$-acyclic objects. 
\end{proof}

\begin{proposition}
Let $f : X \to Y$ be a morphism of topological spaces (or sites) and $\F$ a sheaf on $X$. Then there is a natural map,
\[ H^n(Y, \F) \to H^n(X, f^* \F) \]
\end{proposition}

\begin{proof}
There is a natural adjunction map $\F \to f_* f^* \F$ so we use the natural map derived above $H^*(Y, f_* -) \to H^*(X, - )$ applied to $f^* \F$ giving,
\begin{center}
\begin{tikzcd}
H^n(Y, \F) \arrow[r] & H^n(X, f_* f^* \F) \arrow[r] & H^n(X, f^* \F)
\end{tikzcd}
\end{center}
\end{proof}


\subsection{Application to Divisors}

\begin{proposition}
Let $f : X \to Y$ be a morphism of locally ringed space then there is natural map,
\[ f^* : \Pic{Y} \to \Pic{X} \]
\end{proposition}

\begin{proof}
Given a line bundle $\L$ on $Y$ I claim that the $\struct{X}$-module $f^* \L$ is a line bundle. Take a trivializing neighborhood $V \subset Y$ of $\L$ and $U = f^{-1}(V)$ then,
\begin{center}
\begin{tikzcd}[row sep = large, column sep = large]
X \arrow[r, "f"] & Y 
\\
U \arrow[u, hook, "\iota_U"] \arrow[r, "f|_U"] & V \arrow[u, hook, "\iota_V"']
\end{tikzcd}
\end{center}
commutes. Then,
\[ f|_U^* \L|_V = f^* \iota_V^* \L = (f|_U \circ \iota_V)^* \L = (\iota_U \circ f)^* \L = \iota_U^* f^* \L = (f^* \L)|_U \]
However, $\L_V \cong \struct{Y}$ so $f|_U^* \L_V \cong \struct{X}|_U$ and thus,
\[ (f^* \L)|_U \cong \struct{X}|_U \]
so $f^* \L$ is locally free of rank $1$ since $U = f^{-1}(V)$ form a cover of $X$.
Furthermore $f^* (\L_1 \otimes_{\struct{Y}} \L_2) = f^* \L_1 \otimes_{\struct{X}} f^* \L_2$ so this is a homomorphism.
\bigskip\\
We can give another description of this map as follows. Consider the sheaf maps $f^\# : \struct{Y} \to f_* \struct{X}$. Then we have $f^\# : \struct{Y}^\times \to f_* \struct{X}^\times$. Now, taking $\F = \struct{X}^\times$ in the above we get maps,
\begin{center}
\begin{tikzcd}
\Pic{Y} \arrow[r, equals] & H^1(Y, \struct{Y}^\times) \arrow[r, "f^\#"] & H^1(Y, f_* \struct{X}^\times) \arrow[r] & H^1(X, \struct{X}^\times) \arrow[r, equals] & \Pic{X}
\end{tikzcd}
\end{center}
Equivalently, we have a map $f^\# : f^* \struct{Y} \to \struct{X}$ giving a map $f^\# \struct{Y}^\times \to \struct{X}^\times$ (here $f^*$ is in the category of abelian sheaves not sheaves of modules) giving $f^\# : f^* \struct{Y}^\times \to \struct{X}^\times$. Composing with the pullback on cohomology we get maps,
\begin{center}
\begin{tikzcd}
\Pic{Y} \arrow[r, equals] & H^1(Y, \struct{Y}^\times) \arrow[r] & H^1(X, f^* \struct{Y}^\times) \arrow[r, "f^\#"] & H^1(X, \struct{X}^\times) \arrow[r, equals] & \Pic{X}
\end{tikzcd}
\end{center}
\end{proof}

\subsection{The Grothendieck Spectral Sequence}

\( (\mathrm{Sch} / X)_{\mathrm{ye\acute{e}t}} \)

\section{Normalization of Schemes}

\begin{definition}
We say that a morphism of schemes $f : X \to Y$ is integral if for every map on affine opens $f : U \to V$ for $U = \Spec{B} \subset X$ and $V = \Spec{A} \subset Y$ the map $A \to B$ is integral. 
\end{definition}

\begin{definition}
Let $X$ be an integral noetherian scheme. We say that an affine surjective map $\nu : X^\nu \to X$ from a normal scheme $X^\nu$ is a normalization of $X$ if $\nu$  and satisfies the following universal property. Given any dominant $f : Y \to X$ with $Y$ an irreducible normal scheme then there exists a unique map $f^\nu : Y \to X^\nu$ making the diagram commute,
\begin{center}
\begin{tikzcd}
Y \arrow[r, "f^\nu", dashed] \arrow[dr, "f"'] & X^\nu \arrow[d, "\nu"]
\\
& X
\end{tikzcd}
\end{center}
\end{definition}

\begin{remark}
If a normalization exists then it is unique up to unique isomorphism since we may take any other normalization and get lifts of their normalization maps which are the unique inverse isomorphisms. 
\end{remark}

\begin{proposition}
Let $A$ be a domain and $X = \Spec{A}$ then let $\overline{A}$ be the integral closure. Then $\nu : \Spec{\overline{A}} \to \Spec{A}$ is the normalization. 
\end{proposition}

\begin{proof}
$\nu$ is trivally affine. Furthermore, by Cohen's theorem $\nu : \Spec{\overline{A}} \to \Spec{A}$ is surjective since $A \subset \overline{A}$ is an integral extension of domains. Now we need to check the universal property. Let $Y$ be an irreducible normal scheme and $f : Y \to \Spec{A}$ dominant. Then we have a ring map $A \to \Gamma(Y, \struct{Y})$ and it suffices to check that this ring map uniquely lifts to $\overline{A} \to \Gamma(Y, \struct{Y})$. However, $\Gamma(Y, \overline{A})$ is a normal ring and thus integrally closed in its ring of total fractions (Tag 034M). This implies that after localing $\Gamma(Y, \struct{Y})$ at the image of $A \setminus \{ 0 \}$ that any element integral over $A$ is sent to $\Gamma(Y, \struct{Y})$ in the ring of fractions meaning that there is a unique map,
\begin{center}
\begin{tikzcd}
\overline{A} \arrow[d] \arrow[r, dashed] & \Gamma(Y, \struct{Y})
\\
A \arrow[ru] \arrow[ru]
\end{tikzcd}
\end{center}
\end{proof}

\begin{theorem}
Let $X$ be an integral noetherian scheme. Then there exists a unique normalization $\nu : X^\nu \to X$ of $X$. 
\end{theorem}

\begin{proof}
Choose a finite affine cover $U_i = \Spec{A_i}$ of $X$ by noetherian domains. We may normalize each domain to $U_i^\nu = \Spec{\overline{A}_i}$ with morphisms $\nu_i : U_i^\nu \to U$. It suffices to prove that these morphisms glue to form a normal scheme $X^\nu$. (CHECK)
\end{proof}

\section{Talk Nov 1}

Let $X$ be a smooth projecitve over $\C$ and $\eta \in H^2(X, \Z)$ the chern class o fab $d = \dim{X}$ then it defines a map,
\[ \eta : H^{d - i}(X, \varphi) \xrightarrow{\sim} H^{d + i}(X, \varphi) \]
The first proof is due to Hodge (1941) realizing Betti cohomology as de Rham cohomology with harmonic forms. Then a long gap until 1992 when Simpson used nonabelian Hodge theory to prove f $V$ is as $\C$ local system which is semisimple then then it admits a harmonic metric alows him to formulate so HL holds for
\[ H^{d-i}(X, \vartheta) \xrightarrow{\sim} H^{d+i}(X, \vartheta) \]

\begin{example}
Let $\vartheta$ have rank one i.e. $\vartheta = L$ if $L$ has finite monodromy then HL for this problem is equivalent to HL over $\C$ by replacing $X$ by a finite etale galois cover $Y \to X$ which kills the monodromy. 
\bigskip\\
thus we ask how often the moduli space of such lines $M_B(X, n)$ is a abelian algebraic group which is an extension of a finite group by a torus,
\begin{center}
\begin{tikzcd}
1 \arrow[r] & \mathbb{G}_m^b \arrow[r] & M_B(X, 1) \arrow[r] & \text{torsion} \arrow[r] & 1
\end{tikzcd}
\end{center}
Then, topologically we send $M_B(1)(\C)$ to a $\R$-top and,
\[ \mathbb{G}_m^b \cong (S^1 \times \R_{\ge 0} )^{\theta} \]
the torsion points are not Hausdorff dense and niether are they Zariski dense. 
\end{example}

Deligne and Weil gives the theory of Weights and replaced harmonic theory with the theory of weights and thus can prove HL in the setting of arithmetic geometry:

\begin{theorem}
Let $X$ be smooth projective over $F$ (algebraically closed) with positive characteristic $p$ then $\eta \in H^2(X, \Z_\ell)$ gives an isomorphism
\[ \smile^i \eta : H^{d - i}(X, \varphi_\ell) \xrightarrow{\sim} H^{d + i}(X, \varphi_\ell) \]
on sheaf cohomology where $d = \dim{X}$. 
\end{theorem}

\section{Regular Functions}

\renewcommand{\A}{\mathbb{A}}
\newcommand{\val}{\mathrm{val}}

\begin{definition}
Let $(X, \struct{X})$ be a locally ringed space. Then we call global sections of the structure sheaf $\Gamma(X, \struct{X})$ regular functions.
\end{definition}

\begin{proposition}
Let $(X, \struct{X})$ be a locally ringed space over an affine scheme $\Spec{A}$. Then morphisms $X \to \A^1_A$ are equivalent to regular functions.
\end{proposition}

\begin{proof}
We know that,
\[ \Hom{A}{X}{\A^1_A} = \Hom{A}{X}{\Spec{A[x]}} = \Hom{A}{A[x]}{\Gamma(X, \struct{X})} \cong \Gamma(X, \struct{X}) \]
since any $A$-algebra morphism $A[x] \to R$ is determined uniquely by the image of $x \in R$. 
\end{proof}

\begin{proposition}
Let $(X, \struct{X})$ be a locally ringed space over a scheme $S$. Then morphisms $X \to \A^1_S$ are equivalent to regular functions.
\end{proposition}

\begin{proof}
By definition, $\A^1_S = S \times_\Z \A^1_\Z$ then,
\begin{align*}
\Hom{S}{X}{\A^1_S} & = \Hom{S}{X}{S \times_\Z \A^1_\Z} = \Hom{\Z}{X}{\A^1_\Z} = \Hom{\Z}{X}{\Spec{\Z[x]}} 
\\
& = \Hom{\Z}{\Z[x]}{\Gamma(X, \struct{X})} \cong \Gamma(X, \struct{X})
\end{align*}
since any $\Z$-algebra morphism $\Z[x] \to R$ is determined uniquely by the image of $x \in R$. 
\end{proof}

\begin{definition}
The map $\val_x : \Gamma(X, \struct{X}) \to \stalk{X}{x} \to \stalk{X}{x} / \m_x = \kappa(x)$ is the quotient map which computes the ``value'' of the section at the point $x$. 
\end{definition}


\begin{proposition}
Let $X$ be a scheme of finite type over an algebraically closed field and let $f : X \to \A^1_k$ be determined by a regular function $s \in \Gamma(X, \struct{X})$. Under the identification $\A^1_k = \Spec{k[x]} \cong k \cup \{ * \}$ this function on closed points is,
\[ f(x) = \val_x(s) \]
\end{proposition}

\begin{proof}
Let $g : k[x] \to \Gamma(X, \struct{X})$ be the ring map generated by $s \in \Gamma(X, \struct{X})$. We know that $f(x) = \p \subset \Spec{A[x]}$ iff $\p = g^{-1} \circ \res_x^{-1}(\m_x)$. Now every prime ideal in $\Spec{k[x]}$ is either zero or of the form $(x - \mu)$ for $\mu \in k$. Since $(x - \mu) = \p$ iff $x - \mu \in \p$ we have,
\begin{align*}
f(x) = (x - \mu) & \iff x - \mu \in f(x) \iff \res_x \circ g(x - \mu) \in \m_x
\\
&  \iff (s - \mu)|_x \in \m_x \iff \val_x(s) = \mu \text{ in } \kappa(x)
\end{align*}
Equivalently, note that $\p = \ker{(k[x] \to \kappa(x))}$ and thus,
\[ f(x) = (x - \mu) \iff x - \mu \in \ker{(k[x] \to \kappa(x))} \iff \val_x(s) = \mu \]
Recall that $\kappa(x)$ is an extension of $k$ which is algebraically closed so either $\kappa(x) = k$ or $\kappa(x)$ is a transcendental extension of $k$. In particular, since $X$ is finite type over $k$ a point $x \in X$ is closed iff $\kappa(x) / k$ is finite iff $\kappa(x) = k$. Therefore, at closed points $x \in X$, $\val_x(s) \in \kappa(x) = k$ must be some value $\mu \in k$ and thus $f(x) = \mu$.
\end{proof}

\begin{remark}
Suppose that $x \in X$ is not closed. Then $\kappa(x)$ is a transcendental extension of $k$. If $\val_x(s) \in k \subset \kappa(x)$ then $f(x) = \val_x(s)$. However, otherwise $s_x$ is transcendental over $k$ and thus $\p = \ker{(k[x] \to \kappa(x)} = 0$ because any polynomial $q \in k[x]$ is sent to $q(s_x)$ which cannot be zero since $s_x$ is transcendental over $k$. Thus, $\p = (0)$ so $f(x) = *$ is the generic point. 
\end{remark}

\begin{remark}
This proposition shows why a section $s \in \Gamma(X, \struct{X})$ is deserving of the title of ``function'' and $\val_x(s)$ deserves to be called its value at $x$. 
\end{remark}

\section{Jacobson Rings}

\newcommand{\nilrad}[1]{\mathrm{nilrad}\left(#1\right)}

\begin{definition}
A ring $A$ is \textit{weakly-Jacobson} if $\nilrad{A} = \Jac{A}$. 
\end{definition}

\begin{definition}
A topological space $X$ is \textit{weakly-Jacobson} if the closed points of $X$ are dense.
\end{definition}

\begin{proposition}
A ring $A$ is weakly-Jacobson iff $\Spec{A}$ is weakly-Jacobinson.
\end{proposition}

\begin{proof}
The closed points of $\Spec{A}$ are maximal ideals $\m$ which are dense iff there exists a maximal ideal in each nonempty principal open $\m \in D(f)$ where $f \notin \nilrad{A}$ since $D(f)$ is nonempty. Thus, $\Spec{A}$ is weakly-Jacobinson iff 
\[ f \notin \nilrad{A} \implies \exists \m \in \mSpec{A} : f \notin \m \]  
This is equivalent to $f \in \Jac{A} \implies f \in \nilrad{A}$ so $\Spec{A}$ is weakly-Jacobson iff $\Jac{A} \subset \nilrad{A}$ however $\Jac{A} \supset \nilrad{A}$ by definition so this is equivalent to $\nilrad{A} = \Jac{A}$.
\end{proof}

\begin{definition}
A ring $A$ is \textit{Jacobson} if for any ideal $I \subset A$,
\[ \sqrt{I} = \bigcap_{\m \supset I} \m \]
\end{definition}

\begin{proposition}
A ring is Jacobson iff every quotient is weakly Jacobinson.
\end{proposition}

\begin{proof}
For any ideal $I \subset A$ then consider $A / I$. We know $\nilrad{A / I} = \Jac{A / I}$ iff
\[ \sqrt{I} = \bigcap_{\m \supset I} \m \]
since $\Spec{A / I} = V(I)$ so the result follows.
\end{proof}

\begin{definition}
A topological space $X$ with closed points $X_0$ is Jacobson if for every closed subspace $Z \subset X$ we have $\overline{Z \cap X_0} = Z$ i.e. the closed points are dense in $Z$. 
\end{definition}

\begin{remark}
Clearly Jacobson rings and spaces are weakly Jacobson. 
\end{remark}

\begin{proposition}
A ring $A$ is Jacobson iff its spectrum $\Spec{A}$ is Jacobson.
\end{proposition}

\begin{proof}
Every closed subset $Z \subset \Spec{A}$ is of the form $Z = V(I) = \Spec{A / I}$ for some ideal $I \subset A$. Any closed point of $X$ is closed in $Z$ so if $Z \cap X_0$ is dense then $Z$ is weakly-Jacobson so $\Spec{A / I}$ is weakly-Jacobson for each ideal $I \subset A$ and thus $A$ is Jacobson. Conversely, if $A$ is Jacobson and $Z = V(I) \subset \Spec{A}$ is closed. Any nonempty open of $Z$ is of the form $U \cap Z \subset Z$ for an open $U \subset \Spec{A}$ which contains some principal affine open $D(f) \subset U$ such that $Z \cap D(f)$ is nonempty. Then, $f \notin \sqrt{I}$ but $A$ is Jacobson so,
\[ \sqrt{I} = \bigcap_{\m \supset I} \m \]
and thus $f \notin \m$ for some $\m \supset I$ so $\m \in D(f)$ and $\m \supset I$ i.e. $\m \in V(I) \cap D(f) \subset Z \cap U$ so closed points are dense in $Z$ so $X$ is Jacobson.
\end{proof}

\begin{theorem}
Finitely generated $k$-algebras are Jacobson.
\end{theorem}

\begin{proof}
Let $B$ be a finitely generated $k$-algebra. Then for any ideal $I \subset B$ we need to show that $\nilrad{B / I} = \Jac{B / I}$ which is equivalent to $\Jac{B / \sqrt{I}} = (0)$ since $\nilrad{B / \sqrt{I}} = (0)$. Since $B / \sqrt{I}$ is reduced and a finitely generated $k$-alegbra, it suffices to prove that if $A$ is a reduced finitely generated $k$-algebra then $\Jac{A} = 0$.
\bigskip\\
Let $f \in A$ be nonzero, we wish to show that $f \notin \Jac{A}$ i.e. there is a maximal ideal in $D(f)$. Since $A$ is reduced, there exists a maximal ideal $\m \in \mSpec{A_f}$. Let $\p \subset A$ be the preimage of $\m$ under $A \to A_f$. Then there are inclusions,
\[ k \subset A / \p \subset A_f / \m \]
Since $\m \subset A_f$ is maximal we have $A_f / \m$ is a field. Furthermore, $A_f = A[f^{-1}]$ is a finitely-generated $k$-algebra so $A_f / \m$ is a finitely generated $k$-algebra field and thus a finite field extension of $k$ by Hilbert's Nullstellensatz. Thus, since $\p$ is prime, $A / \p$ is a domain and $A / \p \subset A_f / \m$ so $A / \p$ is a finite dimensional domain and thus a field so $\p$ is maximal with $f \notin \p$ so $f \notin \Jac{A}$ and thus $\Jac{A} = (0)$. 
\end{proof}


\section{Versions of Hilbert's Nullstellensatz}

\begin{theorem}
Let $E$ be a finitely generated $k$-algebra and a field then $E / k$ is a finite extension of fields.
\end{theorem}

\begin{corollary}
Let $k$ be algebraically closed. Then the maximal ideals of $k[x_1, \dots, x_n]$ are $\m_\lambda = (x_1 - \lambda_1, \dots, x_n - \lambda_n)$ for $\lambda = (\lambda_1, \dots, \lambda_n) \in k^n$.
\end{corollary}

\begin{proof}
Let $A = k[x_1, \dots, x_n]$ and $\m \subset A$ be a maximal ideal. Then $A / \m$ is a finitely generated $k$-algebra and a field so $A / \m$ is a finite extension of $k$ but $k$ is algebraically closed so $A / \m = k$. The map $A / \m \to k$ must take $x_i \mapsto \lambda_i \in k$ and thus the kernel of this map is $\m = (x_1 - \lambda_1, \dots, x_n - \lambda_n)$. 
\end{proof}

\begin{theorem}
Finitely generated $k$-algebras are Jacobson.
\end{theorem}

\begin{definition}
Let $I \subset k[x_1, \dots, x_n]$ be an ideal then $V(I) \subset k^n$ is the common vanishing set,
\[ V(I) = \{ z \in k^n \mid \forall f \in I : f(z) = 0 \} \]
For a subset $Z \subset k^n$ define the ideal $I(Z) \subset k[x_1, \dots, x_n]$ of polynomials vanishing on $Z$,
\[ I(Z) = \{ f \in k[x_1, \dots, x_n] \mid \forall z \in Z : f(z) = 0 \} \]
\end{definition}

\begin{remark}
If $k$ is algebraically closed then $V(I) \subset k^n$ corresponds exactly to the closed points of $V(I) \subset \A^n_k = \Spec{k[x_1, \dots, x_n]}$. 
\end{remark}

\begin{proposition}
Let $Z \subset k^n$ be a subset. Then, in the Zariski topology,
\[ V(I(Z)) = \overline{Z} \]
\end{proposition}

\begin{proof}
The vanishing of functions is closed and the intersection of such sets is closed so $V(I)$ is always closed. Futhermore, it is clear that $V(I(Z)) \supset Z$ so $V(I(Z)) \supset \overline{Z}$. However, if $Y \supset Z$ is Zariski closed then $Y = V(J)$ for some ideal $J \subset k[x_1, \dots, x_n]$. However, $V(J) \supset Z$ so $J$ must vanish on $Z$ and thus $J \subset I(Z)$ so $V(J) \supset V(I(Z))$. Therefore, $V(I(Z)) = \overline{Z}$. 
\end{proof}

\begin{proposition}
Let $k$ be algebraically closed and $J \subset k[x_1,\dots, x_n]$ be an ideal. Then, $V(J) = \varnothing \iff J = (1)$. 
\end{proposition}

\begin{proof}
A point $\lambda \in V(J)$ is equivalent to $\m_\lambda \supset J$. If $J$ is proper then it is contained in some maximal ideal $\m$. When $k$ is algebraically closed every maximal ideal is of the form $\m_\lambda$ so $\m_\lambda \supset J$ and thus $\lambda \in V(J)$. Therefore, if $J \neq (1)$ then $V(J) \neq \varnothing$. If $J = (1)$ then clearly $V(J) = \varnothing$ since $1$ does not vanish anywhere.
\end{proof}

\begin{proposition}
Let $k$ be algebraically closed and $J \subset k[x_1,\dots, x_n]$ be an ideal. Then, $I(V(J)) = \sqrt{J}$. 
\end{proposition}

\begin{proof}
Since $k[x_1, \dots, x_n]$ is Jacobson we have,
\[ \sqrt{J} = \bigcap_{\m \supset I} \m \]
but since $k$ is algebraically closed every maximal ideal is of the form $\m_\lambda$ so,
\[ \sqrt{J} = \bigcap_{\m_\lambda \supset J} \m_\lambda = \bigcap_{\lambda \in V(J)} I(\lambda) = I(V(J)) \]
\end{proof}

\begin{remark}
These imply that $I(V(I(Z))) = I(Z)$ and $V(I(V(J))) = V(J)$.
\end{remark}

\begin{remark}
In the context of affine schemes, for a subspace $Z \subset \Spec{A}$, we define,
\[ I(Z) = \bigcap_{\p \in Z} \p \] 
 it is clear $V(I(Z)) = \overline{Z}$ and $I(V(J)) = \sqrt{J}$. This gives the corresponding bijection between Zariski closed subsets and radical ideals.
\end{remark}

\section{The Exponential Sequence of Sheaves}

\newcommand{\Piczero}[1]{\mathrm{Pic}^0\left( #1 \right)}

\begin{definition}
On a complex manifold $X$ there is an exact sequence of abelian sheaves on $X$,
\begin{center}
\begin{tikzcd}
0 \arrow[r] & \underline{\Z} \arrow[r, "2 \pi i"] & \struct{X} \arrow[r, "\exp"] & \struct{X}^\times \arrow[r] & 0
\end{tikzcd}
\end{center}
This is clearly exact at $\underline{Z}$ and $\struct{X}$ since the first map is obviously injective and $\ker{\exp} = 2 \pi \Z$ so if $\exp(f) = 1$ then $f$ has image in $2 \pi \Z$ and thus must be a constant function $2 \pi n$ on each connected component of its domain. Now, for any $f \in \struct{X}^\times(U)$ we can cover $U$ by opens $V_i$ on which $\Im{f}$ has argumet in a fixed bound (i.e. does not cross a choosen branch cut in $\C^\times$). Therefore, we can define a logarithm $\log : \Im{f|_{V_i}} \to \C$ so $f|_{V_i}$ is in the image of $\exp |_{V_i}$ and thus $\exp : \struct{X} \to \struct{X}^\times$ is surjective.
\end{definition}

\begin{proposition}
Applying sheaf cohomology, we get an exact sequence,
\begin{center}
\begin{tikzcd}
0 \arrow[r] & H^0(X, \underline{\Z}) \arrow[r, "2 \pi i"] & H^0(X, \struct{X}) \arrow[draw=none]{d}[name=Z, shape=coordinate]{} \arrow[r, "\exp"] & H^0(X, \struct{X}^\times) \arrow[dll,
rounded corners, crossing over,
to path={ -- ([xshift=2ex]\tikztostart.east)
|- (Z) [near end]\tikztonodes
-| ([xshift=-2ex]\tikztotarget.west)
-- (\tikztotarget)}]
\\ 
 & H^1(X, \underline{\Z}) \arrow[r, "2 \pi i"] & H^1(X, \struct{X}) \arrow[draw=none]{d}[name=Z, shape=coordinate]{} \arrow[r, "\exp"] & H^1(X, \struct{X}^\times)
\arrow[dll,
rounded corners, crossing over,
to path={ -- ([xshift=2ex]\tikztostart.east)
|- (Z) [near end]\tikztonodes
-| ([xshift=-2ex]\tikztotarget.west)
-- (\tikztotarget)}]
\\ 
 & H^2(X, \underline{\Z}) \arrow[r, "2 \pi i"] & H^2(X, \struct{X}) \arrow[r, "\exp"] & H^2(X, \struct{X}^\times) \arrow[r] & \cdots
\end{tikzcd}
\end{center}
Now we know that $H^n(X, \underline{\Z}) = H^n(X; \Z)$ and $H^1(X, \struct{X}^\times) = \Pic{X}$. Therefore, we get,
\begin{center}
\begin{tikzcd}
0 \arrow[r] & H^0(X ; \Z) \arrow[r, "2 \pi i"] & H^0(X, \struct{X}) \arrow[draw=none]{d}[name=Z, shape=coordinate]{} \arrow[r, "\exp"] & H^0(X, \struct{X}^\times) \arrow[dll,
rounded corners, crossing over,
to path={ -- ([xshift=2ex]\tikztostart.east)
|- (Z) [near end]\tikztonodes
-| ([xshift=-2ex]\tikztotarget.west)
-- (\tikztotarget)}]
\\ 
 & H^1(X ; \Z) \arrow[r, "2 \pi i"] & H^1(X, \struct{X}) \arrow[draw=none]{d}[name=Z, shape=coordinate]{} \arrow[r, "\exp"] & \Pic{X}
\arrow[dll,
rounded corners, crossing over,
to path={ -- ([xshift=2ex]\tikztostart.east)
|- (Z) [near end]\tikztonodes
-| ([xshift=-2ex]\tikztotarget.west)
-- (\tikztotarget)}]
\\ 
 & H^2(X ; \Z) \arrow[r, "2 \pi i"] & H^2(X, \struct{X}) \arrow[r, "\exp"] & H^2(X, \struct{X}^\times) \arrow[r] & \cdots
\end{tikzcd}
\end{center}
Let's now restrict ourselves to the case of compact connected Riemann surfaces in which case cohomology above dimension $2$ vanishes and furthermore $H^2(X, \struct{X}) = 0$ as for any vector bundle and degree higher than $1$. Furthermore, all global sections are constant $\Gamma(X, \struct{X}) = \C$ since $X$ is a compact complex manifold and is also connected so the first row gives the exact sequence,
\begin{center}
\begin{tikzcd}
0 \arrow[r] & \Z \arrow[r, "2 \pi i"] & \C  \arrow[r, "\exp"] & \C^\times \arrow[r] & 0
\end{tikzcd}
\end{center}
so the connecting map $H^0(X, \struct{X}^\times) \to H^1(X ; \Z)$ is the zero map. Futhermore, $H^2(X, \struct{X}) = 0$ and $H^2(X ; \Z) = \Z$ since complex manifolds are orientable (apply Poincare duality) so we get an exact sequence,
\begin{center}
\begin{tikzcd}
0 \arrow[r] & H^1(X ; \Z) \arrow[r, "2 \pi i"] & H^1(X, \struct{X}) \arrow[r, "\exp"] & \Pic{X} \arrow[r, "\deg"] & \Z \arrow[r] & 0
\end{tikzcd}
\end{center}
We define $\dim_\C H^1(X, \struct{X}) = g$ the arithmetic genus which by Serre duality is $\dim_\C H^0(X, \Omega^1_X)$. Firstly, we see in the case $g = 0$ that $\Pic{X} \cong \Z$. Therefore, defining,
\[ \Piczero{X} = \ker{(\Pic{X} \to \Z)} \]
we get a further exact sequence,
\begin{center}
\begin{tikzcd}
0 \arrow[r] & H^1(X ; \Z) \arrow[r, "2 \pi i"] & H^1(X, \struct{X}) \arrow[r, "\exp"] & \Piczero{X} \arrow[r] & 0
\end{tikzcd}
\end{center}
This is the Jacobian $\Jac{X} = \Piczero{X}$ as a quotient of the rank $g$ complex vectorspace $H^1(X, \struct{X}) = H^0(X, \Omega^1_X)$ (via Serre duality) by the rank $g$ free $\Z$-module $H^1(X ; \Z)$ defining a lattice inside the $\C$-vectorspace $H^1(X, \struct{X})$. 
\end{proposition}


\section{Colinear Points Form an Algebraic Subset}


\begin{proposition}
Let $k$ be a field, does the set of $m$ points in $k^{n}$ which lie in an $(m-2)$-hyperplane form a closed subvariety in $k^{mn}$?.
\bigskip\\
Yes!
\end{proposition}

\begin{remark}
$m$ points always lie in an $(m-1)$-hyperplane for $n + 1 \ge m$ which is why we choseo the $(m-2)$-hyperpane. For $m = 3$ this question corresponds to requiring the three points to be colinear.  
\end{remark}

\begin{proof}
Choose variables $x_{ij}$ with $(x_{i1}, \dots, x_{in})$ our vectors for $i \in \{ 1, \dots, m \}$. Then the property that these vectors lie in some $(m-2)$-hyperplane is that $\exists y_i \in k$ not all zero such that,
\[ \sum_{i = 1}^m y_i x_{ij} = 0 \] 
and
\[ \sum_{i = 1}^m y_i = 0 \]
Since the $y_i$ are not all zero and this relation is idependent of scaling, the $y_i$ ought to live in $\P^{m-1}_k$. Therfore, we should consider,
\begin{center}
\begin{tikzcd}
Z \arrow[r, hook] \arrow[d] & \P^{m - 1}_k \times_k \A^{mn}_k
\arrow[d, "\pi"]
\\
\pi(Z) \arrow[r, hook] & \A^{mn}_k
\end{tikzcd}
\end{center}
Where $Z$ is the closed subset of $\P^{m-1}_k \times_k \A^{mn}_k$ defined by,
\[ \sum_{i = 1}^m y_i \otimes x_{ij} = 0 \]
as a section of $\struct{\P}(1) \boxtimes \struct{\A}$ and using the K\"{u}nneth formula to find,
\[ H^0(\P^{m - 1}_k \times_k \A^{mn}_k, \struct{\P}(1) \boxtimes \struct{\A}) = H^0(\P^{m - 1}, \struct{\P}(1)) \otimes_k H^0(\A^{mn}_k, \struct{\A}) = k[y_i]_{(1)} \otimes_k k[x_{ij}]  \]
It suffices to prove that $\pi(Z)$ is closed and thus will be of the form $\Spec{k[x_{ij}]/I}$ for some ideal $I \subset k[x_{ij}]$ since $\A^{mn}_k$ is affine. However, $\P^{m-1}_k \to \Spec{k}$ is proper and thus its base change to $\A^{mn}_k$ is also proper. Therefore, $\P^{m-1}_k \times_k \A^{mn}_k \to \A^{mn}_k$ is proper and thus closed proving that $\pi(Z)$ is closed.
\bigskip\\
Let's give a more explict description of $Z$ and $\pi(Z)$. 
\end{proof}

\begin{remark}
For $k = \overline{k}$ we can calculate the radical ideal $I$ simply via.
\[ I = \bigcap_{\m_\lambda \supset I} \m_\lambda = \bigcap_{\lambda \in V(I)} \m_\lambda = \bigcap_{\lambda \in \pi(Z)} \m_{\lambda} \]
However, this is quite difficult to do explicitly. What we really want is a formula for the reduced induced scheme structue on $\pi(Z)$. 
\end{remark}

\begin{lemma}[Tag 01R8]
Let $f : X \to Y$ be quasi-compact and $Z \subset Y$ be the scheme theoretic image of $f$. Then,
\begin{enumerate}
\item the sheaf of ideals $\I = \ker{(\struct{Y} \to f_* \struct{X})}$ is quasi-coherent
\item the scheme theoretic image $Z$ is the closed subscheme of $Y$ corresponding to $\I$.
\end{enumerate}
\end{lemma}

\begin{lemma}[Tag 056B]
Let $f : X \to Y$ be a morphism with $X$ reduced. Then the scheme theoretic image of $f$ is the reduced induced subscheme structure on $\overline{f(X)} \subset Y$.
\end{lemma}

\begin{remark}
Therefore, in our case $\pi$ is proper and thus quasi-compact(by definition of finite-type) so $\pi(Z)$ which is closed when given the reduced induced subscheme structure is the scheme theoretic image of $\pi|_Z$. Therefore, to determine this scheme structure we need to compute, $\I = \ker{(\struct{\A^{nm}_k} \to \pi_* \struct{Z})}$.  
\end{remark}

\begin{lemma}
There is a natural map,
\[ \Gamma(X, \F) \otimes_{\struct{X}(X)} \Gamma(X, \G) \to \Gamma(X, \F \otimes_{\struct{X}} \G)  \] 
\end{lemma}

\begin{proof}
This follows from the existence of the sheafification map sending the presheaf tensor product to the sheaf tensor product.
\end{proof}

\section{On the Hodge Conjecture}

Can you find an associated abelian variety to any surface / curve and use Deligne's result to prove something about the algebraic cycles you started with?


\section{Abelian Varieties}

\begin{remark}
We motivate the fact that proper group varieties are abelian.
\end{remark}

\begin{theorem}
The only compact connected complex Lie groups are complex tori.
\end{theorem}

\begin{proof}
Let $G$ be an $n$-dimensional compact connected complex Lie group with Lie algebra $\g$. Consider the adjoint action $\Ad : G \to \Aut{\g}$ which is holomorphic and thus either constant or open. However, $G$ is compact to the image of $\Ad$ is compact and thus closed. Thus if the image of $\Ad$ is open then it must be the entire connected component of the identity which is not compact a contradiction showing that $\Ad$ must be constant. Thus $\Ad{(g)} = \id$ and thus $g \cdot \xi \cdot g^{-1} = \xi$ for all $g \in G$ and $\xi \in \g$. This implies that $\ad = \d{\Ad}$ is trivial but $\ad_{\xi}(\eta) = [\xi, \eta] = 0$ so the Lie algebra $\g$ is trivial. Thus, the universal covering group of $G$ is $\C^n$ (the unique simply conected Lie group with the trivial $n$-dimensional Lie algebra $\g$). Consider the covering map $\phi : \C^n \to G$ which is a local diffeomorphism since $\d{\phi} : \C^n \to \g$ is an isomorphism. Thus the kernel $\Lambda = \ker{\phi} \subset \C^n$ is a discrete subgroup and, since $G$ is compact, full rank so $\Lambda$ is a lattice. Therefore, $G \cong \C^n / \Lambda$ is a complex torus.
\end{proof}

\begin{remark}
Compactness is essential since $\mathrm{GL}_{n}(\C)$ is clearly a nonabelian  connected Lie group. 
\end{remark}


\section{Derived Nonsense}

\newcommand{\Ch}[1]{\mathbf{Ch}\left( #1 \right)}
\renewcommand{\A}{\mathcal{A}}

\begin{lemma}
Let $\A$ be an abelian category with enough injectives and $C^\bullet \in \Ch{\A}$ be a bounded below complex. Then there exists an injective complex $I^\bullet$ and a quasi-isomorphism $C^\bullet \to I^\bullet$. 
\end{lemma}

\begin{proof}

\end{proof}

\begin{remark}
For an object $A \in \A$ this existence theorem gives a quasi-isomorphism $A[0] \to I^\bullet$ which is just an injective resolution of $A$ since,
\begin{center}
\begin{tikzcd}
0 \arrow[r] & A \arrow[d] \arrow[r] & 0 \arrow[r] \arrow[d] & 0 \arrow[r] \arrow[d] & 0 \arrow[d] \arrow[r] & \cdots
\\
0 \arrow[r] & I^0 \arrow[r] & I^1 \arrow[r] & I^2 \arrow[r] & I^3 \arrow[r] & \cdots
\end{tikzcd}
\end{center}
must be a quasi-isomorphism which implies that $\im{A \to I^0} \cong \ker{I^0 \to I^1}$ and $H^i(I^\bullet) = 0$ for $i > 0$ so $0 \to A \to I^\bullet$ is exact.
\end{remark}



\renewcommand{\C}{\mathcal{C}}
\newcommand{\D}{\mathcal{D}}
\newcommand{\inthom}[3]{\underline{\mathrm{hom}}_{#1} \! \left( #2, #3 \right)}

\section{Cartesian and Closed Categories}

\subsection{Closed Categories}

\newcommand{\op}{\mathrm{op}}

\begin{definition}
We say a monoidal category $(\C, \otimes)$ is \textit{closed} if $- \otimes Y : \C \to \C$ has a right adjoint $\inthom{\C}{Y}{-} : \C \to \C$ forming a bifunctor, $\inthom{\C}{-}{-} : \C^\op \times \C \to \C$
\[ \Hom{\C}{X \otimes Y}{Z} = \Hom{\C}{X}{\inthom{\C}{Y}{Z}} \]
naturally in $X, Y, Z$.
\end{definition}

\begin{remark}
We call $\inthom{\C}{-}{-}$ the \textit{interal hom}. To justify this notation notice that if $I$ is the identity object of the monoid then,
\[ \Hom{\C}{I}{\inthom{\C}{X}{Y}}  = \Hom{\C}{I \otimes X}{Y} = \Hom{\C}{X}{Y}  \]
Furthermore, notice that,
\[ \Hom{\C}{X}{-} = \Hom{\C}{X \otimes I}{-} = \Hom{\C}{X}{\inthom{\C}{I}{-}} \]
and thus by Yoneda $\inthom{\C}{I}{-} \cong \id_{\C}$.
Therefore, $\inthom{\C}{-}{-}$ and $I$ gives a closed structure on the underlying category $\C$ (https://ncatlab.org/nlab/show/closed+category).
\end{remark}

\begin{proposition}
There is an internal natural adjunction,
\[ \inthom{\C}{X \otimes Y}{Z} = \inthom{\C}{X}{\inthom{\C}{Y}{Z}} \]
\end{proposition}

\begin{proof}
Consider the following,
\begin{align*}
\Hom{\C}{W}{\inthom{\C}{X \otimes Y}{Z}} & = \Hom{\C}{W \otimes (X \otimes Y)}{Z} = \Hom{\C}{(W \otimes X) \otimes Y}{Z}
\\
& = \Hom{\C}{W \otimes X}{\inthom{\C}{Y}{Z}} 
\\
& = \Hom{\C}{W}{\inthom{\C}{X}{\inthom{\C}{Y}{Z}}} 
\end{align*}
The result then follows from Yoneda.
\end{proof}

\begin{proposition}
Let $(\C, \otimes)$ be closed. Then $- \otimes Y  : \C \to \C$ preserves all colimts and $\inthom{\C}{Y}{-}$ preserves all limits.
\end{proposition}

\begin{proof}
Immediate from the adjunction $- \otimes Y \dashv \inthom{\C}{Y}{-}$.
\end{proof}

\begin{corollary}
We have $(X \coprod Y) \otimes Z = (X \otimes Z) \coprod (Y \otimes Z)$.
\end{corollary}

\begin{proposition}
Let $(\C, \otimes)$ be a symmetric monoidal category then $X \otimes -$ preserves colimits and $\inthom{\C}{-}{X}$ transforms colimits to limits.
\end{proposition}

\begin{proof}
That $X \otimes -$ preserves colimits follows from the fact that $- \otimes X \cong X \otimes -$ and $- \otimes X$ preserves colimts because it is left adjoint to $\inthom{\C}{X}{-}$. Furthermore,
\begin{align*}
\Hom{\C}{X}{\inthom{\C}{\colim{J}}{Y}} & = \Hom{\C}{X \otimes \colim{J}}{Y} = \Hom{\C}{\colim(X \otimes J)}{Y}
\\
& = \lim \Hom{\C}{X \otimes J}{Y} = \lim \Hom{\C}{X}{\inthom{\C}{J}{Y}}
\\
& = \Hom{\C}{X}{\lim \inthom{\C}{J}{Y}}
\end{align*}
Thus, by Yoneda, $\inthom{\C}{\colim J}{Y} = \lim \inthom{\C}{J}{Y}$.
\end{proof}

\begin{remark}
The unit and counit of the adjunction are,
\[ s : X \to \inthom{\C}{Y}{X \otimes Y} \quad \quad \ev : \inthom{\C}{Y}{Z} \times Y \to Z \] called slice and evaluation respectively.
\end{remark}

\subsection{Cartesian Categories}

\begin{definition}
A monoidal category is called \textit{cartesian} if the monoidal product is the categorical product. Thus any category with finite products is a cartesian monoial category (since the empty product is the terminal object which serves as the identity). 
\end{definition}

\begin{definition}
A category is \textit{cartesian closed} if the cartesian monoidal product is closed. In this case we write $Y^X := \inthom{\C}{X}{Y}$.
\end{definition}

\begin{proposition}
Let $\C$ be closed cartesian. Then $X \times - : \C \to \C$ preserves limits and colimits.
\end{proposition}

\begin{proof}
Immediate from the fact that $X \times -$ is a limit and a left adjoint to $(-)^X$. 
\end{proof}

\begin{proposition}
Let $\C$ be closed cartesian. Then the following formulae hold,
\begin{enumerate}
\item $(\lim J)^X = \lim J^X$
\item $(X \times Y)^Z = X^Z \times Y^Z$
\item $Y^{\colim J} = \lim Y^J$
\item $X^{(Y \coprod Z)} = X^Y \times X^Z$
\item $I^X = X$
\item $(X^Y)^Z = X^{Y \times Z}$
\end{enumerate}
\end{proposition}

\begin{proof}
These formulae have been proven previously for a general closed symmetric monoidal category.
\end{proof}

\begin{definition}
An \textit{exponential object} $Y^X$ is an object along with a map $\ev : Y^X \times X \to Y$ universal in the sense that for any $g : Z \times X \to Y$ there exists a unique $\lambda g : Z \to Y^X$ such that
\begin{center}
\begin{tikzcd}[row sep = huge]
Z \arrow[d, dashed, "\lambda g"'] & Z \times X \arrow[d, dashed, "\lambda g \times \id_X"'] \arrow[rd, "g"]
\\
Y^X & Y^X \times X \arrow[r, "\ev"'] & Y
\end{tikzcd}
\end{center}
commutes. A coexponential object is an exponential object in $\C^\op$.
\end{definition}


\begin{lemma}
Let $\C$ be cartesian closed. Then $Y^X = \inthom{\C}{X}{Y}$ is an exponential object with $\ev : Y^X \times X \to Y$ the counit.
\end{lemma}

\begin{proof}
Consider $g : Z \times X \to Y$ then given the adjunction,
\begin{center}
\begin{tikzcd}
\Hom{\C}{Y^X \times X}{Y} \arrow[r, "(\lambda g \times \id_X)^*"] \arrow[d, equals] & \Hom{\C}{Z \times X}{Y} \arrow[d, equals]
\\
\Hom{\C}{Y^X}{Y^X} \arrow[r, "(\lambda g)^*"] & \Hom{\C}{Z}{Y^X}
\end{tikzcd}
\end{center}
where $\lambda g$ is the image of $g$ in $\Hom{\C}{Z}{Y^X}$. Since $\ev : Y^X \times X \to Y$ corresponds to $\id : Y^X \to Y^X$ under the vertical map and $(\lambda g)^* \id_{Y^X} = \lambda g$ we see by commutativity that $(\lambda g \times \id_X)^* \ev = g$ i.e. $\ev \circ (\lambda g \times \id_X) = g$. Furthermore, if there were some other $h \in \Hom{\C}{Z}{Y^X}$ such that $\ev \circ (h \times \id_X) = g$ then by the corresponding diagram $h^* \id_{Y^X} = \lambda g$ so $h = \lambda g$.
\end{proof}

\subsection{Coexponential Objects}

\begin{definition}
A cocartesian coclosed category is a category such that $\C^\op$ is cartesian closed.
\end{definition}

\newcommand{\coev}{\mathrm{coev}}

\begin{remark}
Explicitly, a coexponential object $Y_X$ has a map $\coev : Y \to Y_X \coprod X$ universal in the sense that for any $g : Y \to Z \coprod X$ there exists a unique $\lambda g : Y_X \to Z$ such that,
\begin{center}
\begin{tikzcd}[row sep = huge]
Y_X \arrow[d, dashed, "\lambda g"'] & Y_X \coprod X \arrow[d, dashed, "\lambda g \coprod \id_X"'] & Y \arrow[l, "\coev"'] \arrow[ld, "g"] 
\\
Z & Z \coprod X 
\end{tikzcd}
\end{center}
\end{remark}

\begin{definition}
A 
\end{definition}

\section{Concrete Categoies}


\begin{definition}
A concrete category is a pair $(\C, U)$ where $U : \C \to \Set$ is a faithful functor called the forgetful functor to the underlying set. 
\end{definition}

\begin{lemma}
A morphism $f : X \to Y$ is monic iff $f_* : \Hom{\C}{-}{X} \to \Hom{\C}{-}{Y}$ is injective. Likewise, $f : X \to Y$ is epic iff $f^* : \Hom{\C}{Y}{-} \to \Hom{\C}{X}{-}$ is injective. 
\end{lemma}

\begin{proof}
Holds by definition.
\end{proof}

\begin{lemma}
Let $U : \C \to \D$ be a faithful functor and $f : X \to Y$ a $\C$-morphism. If $U(f)$ is monic then $f$ is monic and if $U(f)$ is epic then $f$ is epic.
\end{lemma}

\begin{proof}
Consider the diagram,
\begin{center}
\begin{tikzcd}
\Hom{\C}{-}{X} \arrow[d] \arrow[r, "f_*"] & \Hom{\C}{-}{Y} \arrow[d]
\\
\Hom{\D}{U(-)}{U(X)} \arrow[r, "U(f)_*"] & \Hom{\D}{U(-)}{U(Y)}
\end{tikzcd}
\end{center}
Since $U$ is faithful the downward arrows are injections. Thus, if $U(f)_*$ is injective then $f_*$ must also be injective. The exact same proof holds applying $f$ in the first factor to prove epicness.
\end{proof}

\begin{lemma}
A morphism $f : X \to Y$ in $\C$ is monic iff $\Delta : X \to X \times_Y X$ is an isomorphism. Dually, $f : X \to Y$ is epic iff $\Delta : X \coprod_Y X \to X$ is an isomorphism. 
\end{lemma}

\begin{proof}
DO THIS
\end{proof}

\begin{lemma}
Let $U : \C \to \D$ preserve fibre products. Then $U$ preserves monics. Dually, let $U : \C \to \D$ preserve fibred coproducts. Then $U$ preserves epimorphisms. 
\end{lemma}

\begin{proof}
DO THIS
\end{proof}

\begin{proposition}
Let $(\C, U)$ be a concrete category and $f : X \to Y$ a $\C$-morphism. Then the following hold,
\begin{enumerate}
\item if $U(f)$ is monic then $f$ is monic
\item if $U(f)$ is epic then $f$ is epic
\item if $U$ admits a left-adjoint then if $f$ is monic then $U(f)$ is monic
\item if $U$ admits a right-adjoint then if $f$ is epic then $U(f)$ is epic
\end{enumerate}
In particular, let $\C$ have small limits and $F$ be left-adjoint to $U$. Then $f$ is monic iff $U(f)$ is injective. Likewise, let $\C$ have small colimits and $W$ be right-adjoint to $U$. Then $f$ is epic iff $U(f)$ is surjective. 
\end{proposition}

\begin{example}
Consider the forgetful functor $U : \Top \to \Set$ making $(\Top, U)$ a concrete category which is complete and cocomplete. Furthermore, $U$ has a left adjoint $D$ giving a set the discrete topology and a right-adjoint $I$ giving a set the indiscrete topology. Thus, monics and epics in $\Top$ are exactly injections and surjections respectively on their underlying sets. 
\end{example}

\newcommand{\Haus}{\mathbf{Haus}}

\begin{example}
However, the category of Hausdorff spaces $\Haus$ has a forgetful functor $U : \Haus \to \Set$ making $(\Haus, U)$ a concrete category which is complete and cocomplete but $U$ does not have a right-adjoint since the indiscrete space is not generally Hausdorff. However, the discete topology is Hausdorff so $U$ admits a left-adjoint $D$. Therefore, monics in the category of Hausdorff spaces are exactly injective maps and all surjections are epic. However, $\Q \to \R$ is a epic but not surjective since continuous maps to Haudorff spaces are determined on any dense subset. 
\end{example}

\begin{remark}
An algebraic category is a complete and cocomplete concrete category $(\C, F, U)$ is a concrete category $(\C, U)$ with a free functor $F$ left-adjoint to $U$. Thus, in any algebraic category monics are exactly injections and all surjections are epic.
\bigskip\\
However, not all epimorphisms need be surjective. For example, in the category of rings $\Z \to \Q$ is epic but not surjective. 
\end{remark}

\section{Thurston's Geometrization}

\section{Products of Schemes (WWIP)}

\newcommand{\Ass}[2]{\mathrm{Ass}_{#1} \left( #2 \right)}

\begin{lemma}
The localization of a flat module is flat.
\end{lemma}

\begin{proof}
Suppose that $M$ is a flat $A$-module and $S \subset A$ a multiplicative set. Then the functor $M \otimes_A (-)$ is exact since $M$ is flat. Furthermore, $S^{-1} A \otimes_A (-) = S^{-1}(-)$ is exact. Therefore,
\[ S^{-1} M \otimes_A (-) = (S^{-1} A \otimes_A M) \otimes_A (-) = M \otimes_A (S^{-1} A \otimes_A (-)) = M \otimes_A S^{-1}(-) \]
is the composition of exact functors and thus exact. Therfore, $S^{-1} M$ is $A$-flat. 
\end{proof}

\begin{lemma}
We have $S^{-1} M \otimes_{S^{-1} A} (-) = M \otimes_A (-)$ as a functor on $S^{-1}A$-modules. 
\end{lemma}

\begin{proof}
We have,
\[ S^{-1} M \otimes_{S^{-1} A} N = (M \otimes_A S^{-1}A) \otimes_{S^{-1} A} N = M \otimes_A (S^{-1} A \otimes_{S^{-1} A} N) = M \otimes_A N \]
\end{proof}

\begin{lemma}
Let $M$ be a $S^{-1}A$-module. Then $M$ is $S^{-1} A$-flat iff $M$ is $A$-flat.
\end{lemma}

\begin{proof}
Suppose that $M$ is $S^{-1} A$-flat. Now, $S^{-1} A$ is $A$-flat so $M \otimes_{S^{-1} A} S^{-1} A = M$ is $A$-flat.
\bigskip\\
Now suppose that $M$ is $A$-flat. Now, $M = M \otimes_{A} S^{-1} A$ as an $S^{-1} A$-module. Then $M \otimes_{S^{-1} A} (-) = M \otimes_{A} (-)$ so $M$ is $S^{-1}A$-flat.
\end{proof}

\begin{lemma}
$M$ is a flat $A$-module iff $M_\p$ is a flat $A_\p$ module for each prime $\p \subset A$. 
\end{lemma}

\begin{proof}
If $M$ is $A$-flat then $M_\p = S_\p^{-1} M$ is $S^{-1}_\p A = A_\p$-flat. Now, suppose that $M_\p$ is $A_\p$-flat and consider an exact sequence,
\begin{center}
\begin{tikzcd}
0 \arrow[r] & N_1 \arrow[r] & N_2 \arrow[r] & N_3 \arrow[r] & 0
\end{tikzcd}
\end{center}
and apply the functor $(-) \otimes_A M$,
\begin{center}
\begin{tikzcd}
0 \arrow[r] & N_1 \otimes_A M \arrow[r] & N_2 \otimes_A M \arrow[r] & N_3 \otimes_A M \arrow[r] & 0
\end{tikzcd}
\end{center}
This sequence is exact if its localization at each prime is exact. However,
\begin{center}
\begin{tikzcd}
0 \arrow[r] & (N_1 \otimes_A M) \otimes_A  A_\p \arrow[r] \arrow[d, equals] & (N_2 \otimes_A M) \otimes A_\p \arrow[d, equals] \arrow[r] & (N_3 \otimes_A M) \otimes A_\p  \arrow[d, equals]\arrow[r] & 0
\\
0 \arrow[r] & N_1 \otimes_A (M \otimes_A  A_\p) \arrow[d, equals] \arrow[r] & N_2 \otimes_A (M  \otimes A_\p) \arrow[d, equals] \arrow[r] & N_3 \otimes_A (M \otimes A_\p) \arrow[d, equals] \arrow[r] & 0
\\
0 \arrow[r] & N_1 \otimes_A M_\p \arrow[r] & N_2 \otimes_A M_\p \arrow[r] & N_3 \otimes_A M_\p \arrow[r] & 0
\end{tikzcd}
\end{center}
Then $M_\p$ is flat as an $A_\p$-module iff $M_\p$ is $A$-flat so the above sequence is exact. 
\end{proof}


\begin{definition}
Let $f : X \to Y$ be a morphism of schemes and $\F$ a quasi-coherent $\struct{X}$-module. Then $\F$ is flat over $f : X \to Y$ if for each $x \in X$ the $\F_x$ is a flat $\stalk{Y}{f(x)}$-module. 
\bigskip\\
Furthermore, we say that $f$ is flat if $\stalk{X}{x}$ is a flat $\struct{Y}{f(x)}$-module for each $x \in X$ or equivalently if $\struct{X}$ is flat over $f : X \to Y$.
\end{definition}


\begin{lemma}
Let $M$ be an $A$-module. Then the map,
\[ M \to \prod_{\m \in \mSpec{A}} M_\m \]
is injective. Therefore, if $M \neq 0$ then $M_\m \neq 0$ for some maximal ideal $\m \in \mSpec{A}$. 
\end{lemma}

\begin{proof}
Fix $m \in M$. Then $m \mapsto 0$ inside $M_\m$ iff $\Ann{A}{m} \not\subset \m$. However, unless $1 \cdot m = 0$ i.e. for $m \neq 0$ the ideal $\Ann{A}{m}$ is contained in some maximal ideal $\m_0$ and thus $m$ is nonzero inside $M_{\m_0}$. 
\end{proof}

\begin{lemma}
The maximal ideals of the form $\Ann{A}{m}$ are prime and are therefore associated primes. 
\end{lemma}

\begin{proof}
Let $I = \Ann{A}{m}$ be maximal with respect to annihilators. Then if $xy \in \Ann{A}{m}$ we have $xym = 0$. If $ym = 0$ then $y \in \Ann{A}{m}$ otherwise $\Ann{A}{ym}$ is a proper ideal and $tm = 0 \implies tym = 0$ so $\Ann{A}{ym} \supset \Ann{A}{m}$. By maximality, $\Ann{A}{ym} = \Ann{A}{m}$ and $xym = 0$ so $x \in \Ann{A}{m}$. Therefore $\Ann{A}{m}$ is prime so it is an associated prime of $M$.
\end{proof}

\begin{corollary}
If $A$ is Noetherian than every ideal $I = \Ann{A}{m}$ for $m \in M$ is contained in an associated prime of $M$. In particular, when $M \neq 0$ the set of associated primes $\Ass{A}{M} \neq 0$ is nonempty.
\end{corollary}

\begin{lemma}
Let $A$ be Noetherian and $M$ an $A$-module. Then the map,
\[ M \to \prod_{\p \in \Ass{A}{M}} M_\p \]
is injective. 
\end{lemma}

\begin{proof}
Let $m \in M$ be nonzero. Then $\Ass{A}{m}$ is a proper ideal and thus $\Ass{A}{m} \subset \p$ lies in some maximal annihilator $\p$ (by the Noetherian property maximal elements exist in the poset of annhilator ideals) which is an associated prime. Thus, $m$ has nonzero image in $M_\p$.  
\end{proof}

\begin{lemma}
The map $\Spec{B} \to \Spec{A}$ is flat iff $A \to B$ is flat.
\end{lemma}

\begin{proof}
The map $\Spec{B} \to \Spec{A}$ is flat iff for each prime $\q \subset B$ and its image $\p \subset A$ the map $A_\p \to B_{\q}$ is flat. If $A \to B$ is flat then $A_\p \to B_\p \to B_\q$ if flat by localization properties.
 \bigskip\\
Now suppose that $A_\p \to B_\q$ is flat for all $\q \in \Spec{B}$ with image $\p \in \Spec{A}$. 
The functor, $T = \Tor{A}{i}{-}{B}$ has a $B$-module structure. If $T \neq 0$ then there must be some prime $\q \subset B$ such that $T_\q \neq 0$. However,
\[ T_\q = \Tor{A}{r}{-}{B}_\q = \Tor{A_\p}{r}{-}{B_\q} \]
which holds because,
\[ \Tor{A}{r}{M}{B}_\q = L_i [(-) \otimes_ A B] \otimes_B B_\q = L_i [ (-) \otimes_A B_\q ] \]
since $B_\q$ is $B$-flat, and,
\[ (-) \otimes_A B_\q = (-) \otimes_A B_\q = ((-) \otimes_{A_\p} A_\p) \otimes_A B_\q = (-) \otimes_{A_\p} (A_\p \otimes_A B_\q) = (-) \otimes_{A_\p} B_\q \]
and,
\[ B_\q = S^{-1}_\p B_\q = A_\p \otimes_A B_\q \]
Furthermore, $B_\q$ is $A_\p$-flat so,
\[ T_\q = \Tor{A}{r}{-}{B}_\q = \Tor{A_\p}{r}{-}{B_\q} = 0 \]
for all $\q \in \Spec{B}$ and thus $T = 0$ so $B$ is $A$-flat. 
\end{proof}

\begin{proposition}
Let $f : X \to Y$ be a morphism of schemes and $\F$ a quasi-coherent $\struct{X}$-module. Then the following are equivalent,
\begin{enumerate}
\item $\F$ is flat over $f : X \to Y$
\item for any affine opens $U \subset X$ and $V \subset Y$ with $f(U) \subset Y$ the map $\F(U)$ is a flat $\struct{Y}(V)$-module. 
\item (THERE IS AN AFFINE COVER ST ...)
\end{enumerate}
(HMMMMM, AFFINE?)
\end{proposition}

\begin{proposition}
Let $X, Y$ be schemes over $\Spec{A}$ and $\F$ be a quasi-coherent $\struct{X}$-module and $\G$ a quasi-coherent $\struct{Y}$-module. Then there is a natural map,
\[ H^0(X, \F) \otimes_A H^0(Y, \G) \to H^0(X \times_A Y, \pi^*_X \F \otimes_{\struct{X \times Y}} \pi^*_Y \G) \]
\end{proposition}

\begin{proof}
Let $P = X \times_A Y$. First, the functoriality of cohomology gives $A$-module maps,
\begin{align*}
H^0(X, \F) & \to H^0(P, \pi_X^{*} \F)
\\
H^0(Y, \G) & \to H^0(P, \pi_Y^{*} \G)
\end{align*}
Furthermore, the sheafification functor gives a natural map,
\[  \pi^*_X \F \otimes_{\struct{P}}^{\text{psh}} \pi^*_Y \G \to \pi^*_X \F \otimes_{\struct{P}} \pi^*_Y \G \]
and thus there is a natural map,
\[ H^0(P, \pi_X^* \F) \otimes_{\struct{P}(P)} H^0(P, \pi_Y^* \G) \to H^0(P, \pi^*_X \F \otimes_{\struct{X \times Y}} \pi^*_Y \G) \]
Therefore, we get a map,
\begin{align*}
H^0(X, \F) \otimes_A H^0(Y, \G) \to  H^0(P, \pi_X^* \F) \otimes_{\struct{P}(P)} H^0(P, \pi_Y^* \G) \to H^0(P, \pi^*_X \F \otimes_{\struct{X \times Y}} \pi^*_Y \G)
\end{align*}
\end{proof}

\begin{proposition}
If $X, Y$ are noetherian schemes seperated over $\Spec{A}$ and $\F$ and $\G$ are flat over $\Spec{A}$ then the map,
\[ H^0(X, \F) \otimes_A H^0(Y, \G) \xrightarrow{\sim} H^0(X \times_A Y, \pi^*_X \F \otimes_{\struct{X \times Y}} \pi^*_Y \G) \]
is an isomorphism. 
\end{proposition}

\begin{proof}
Choose a finite open affine cover $U_i$ of $X$ (since $X$ is noetherian). We first show that $\Gamma(U \times Y) = \Gamma(U) \otimes_A \Gamma(Y)$ for any affine open $U \subset X$. Now, to prove the claim, consider an affine open $U \subset X$ and choose a finite affine open cover $V_i \subset Y$ of $Y$. The sheaf property gives, 
\begin{center}
\begin{tikzcd}
0 \arrow[r] & \Gamma(Y) \arrow[r] & \bigoplus\limits_{i \in I} \Gamma(V_i) \arrow[r] & \bigoplus\limits_{i, j \in I} \Gamma(V_i \cap V_j)
\end{tikzcd}
\end{center}
Then, tensoring by the $A$-flat module $\Gamma(U)$ we get an exact sequence (which preserves the equalizer property since tensor products commute with biproducts), 
\begin{center}
\begin{tikzcd}
0 \arrow[r] & \Gamma(U) \otimes_A \Gamma(Y) \arrow[d, "\sim", dashed] \arrow[r] & \bigoplus\limits_{i \in I} \Gamma(U) \otimes_A \Gamma(V_i) \arrow[r] \arrow[d, "\sim"] & \bigoplus\limits_{i, j \in I} \Gamma(U) \otimes_A \Gamma(V_i \cap V_j) \arrow[d, "\sim"]
\\
0 \arrow[r] & \Gamma(U \times_A Y) \arrow[r] & \bigoplus\limits_{i \in I} \Gamma(U \times_A V_i) \arrow[r] & \bigoplus\limits_{i, j \in I} \Gamma(U \times_A V_i \cap V_j)
\end{tikzcd}
\end{center}
using the fact that $Y$ is separated so $V_i \cap V_j$ is affine and $\Gamma(U \times_A V) = \Gamma(U) \otimes_A \Gamma(V)$ since $\Spec{-}$ takes coproducts to products. Thus, by the uniqueness of the kernel, we get the desired $\Gamma(U) \otimes_A \Gamma(Y) = \Gamma(U \times_A Y)$
\bigskip\\
Likewise, the sheaf property gives that the following sequence is exact,
\begin{center}
\begin{tikzcd}
0 \arrow[r] & \Gamma(X) \arrow[r] & \bigoplus\limits_{i \in I} \Gamma(U_i) \arrow[r] & \bigoplus\limits_{i, j \in I} \Gamma(U_i \cap U_j)
\end{tikzcd}
\end{center}
Then applying the fact that $\Gamma(Y)$ is $A$-flat (plus that tensor products are cocontinuous and thus commute with biproducts although not with arbitrary products which is why the finiteness is needed) gives that,
\begin{center}
\begin{tikzcd}
0 \arrow[r] & \Gamma(X) \otimes_A \Gamma(Y) \arrow[r] & \bigoplus\limits_{i \in I} \Gamma(U_i) \otimes_A \Gamma(Y) \arrow[r] & \bigoplus\limits_{i, j \in I} \Gamma(U_i \cap U_j) \otimes_A \Gamma(Y)
\end{tikzcd}
\end{center}
is exact. However using that $X$ is seperated $U_i$ and $U_i \cap U_j$ are affine opens and thus, 
\begin{center}
\begin{tikzcd}
0 \arrow[r] & \Gamma(X) \otimes_A \Gamma(Y) \arrow[d, "\sim", dashed] \arrow[r] & \bigoplus\limits_{i \in I} \Gamma(U_i) \otimes_A \Gamma(Y) \arrow[r] \arrow[d, "\sim"] & \bigoplus\limits_{i, j \in I} \Gamma(U_i \cap U_j) \otimes_A \Gamma(Y) \arrow[d, "\sim"]
\\
0 \arrow[r] & \Gamma(X \times_A Y) \arrow[r] & \bigoplus\limits_{i \in I} \Gamma(U_i \times_A Y) \arrow[r] & \bigoplus\limits_{i, j \in I} \Gamma(U_i \cap U_j  \times_A Y)
\end{tikzcd}
\end{center}
via the uniqueness of kernels giving the equality $\Gamma(X) \otimes_A \Gamma(Y) = \Gamma(X \times_A Y)$. 
\end{proof}

(WAIT IS THIS ACTUALLY TRUE IF Y NOT AFFINE THEN Gamma(Y) not necessarily flat). 
(FUCK THIS IS FALSE!!!)

\begin{corollary}
Let $X, Y$ be noetherian schemes flat over $\Spec{A}$. Then there is an isomorphism,
\[ \Gamma(X, \struct{X}) \otimes_A \Gamma(Y, \struct{Y}) \xrightarrow{\sim} \Gamma(X \times_A Y, \struct{X \times_A Y}) \]
\end{corollary}

\begin{proof}
The map $f : X \to \Spec{A}$ is flat iff $\struct{X}$ is flat over $\Spec{A}$. Then apply the previous lemma using,
\[ \pi_X^* \struct{X} = \pi_Y^* \struct{Y} = \struct{X \times_A Y} \]
\end{proof}

\newcommand{\Ring}{\mathbf{Ring}}

\begin{remark}
The adjunction,
\[ \Hom{\mathbf{LRS}}{X}{\Spec{A}} = \Hom{\Ring^{\op}}{\Gamma(X, \struct{X})}{A} \]
shows that $\Spec{-} : \Ring^\op \to \mathbf{LRS}$ is continuous and $\Gamma(-) : \mathbf{LRS} \to \Ring^\op$ is cocontinuous. This implies that,
\[ \Spec{A \times_{\Ring^\op} B} = \Spec{A \otimes B} = \Spec{A} \times \Spec{B} \]
and
\[ \Gamma(X \sqcup Y) = \Gamma(X) \sqcup_{\Ring^\op} \Gamma(Y) = \Gamma(X) \times \Gamma(Y) \]
\end{remark}

\subsection{Generic Flatness (WIP)}

\begin{lemma}
Let $f : X \to Y$ be a finite type morphism of locally noetherian schemes. Then the set $\{ x \in X  \mid f \text{ is flat at } x \}$ is open.
\end{lemma}

\begin{proof}
Suppose $f$ is flat at $x \in X$ then it suffices to consider affine opens $x \in U = \Spec{B}$ and $V = \Spec{A}$ with $f(U) \subset V$ and $A \to B$ a finite map of noetherian rings. Let $x = \q \in \Spec{B}$ and $f(x) = \p \in \Spec{A}$. Then $A_\p \to B_\q$ is flat. We need to find an open $\q \in D(g) \subset U$ on which $f : D(g) \to V$ is flat.
\bigskip\\
Thus, we have reduced to the following algebra problem. Given a finite map of noetherian rings $A \to B$ and primes $\q \in \Spec{B}$ over $\p \in \Spec{A}$ s.t. $A_\p \to B_\q$ is flat, show that there exists some $g \in B$ s.t. $A \to B_g$ is flat. This is Tag 00RC.
\end{proof}

\begin{proposition}
Let $f : X \to Y$ be a dominant finite type map of integral noetherian schemes. There exists a dense open $U \subset X$ such that $f|_U : U \to Y$ is flat. 
\end{proposition}

\begin{proof}
Let $\xi \in X$ and $\eta \in Y$ be the generic points. Since $f$ is dominat $f(\xi) = \eta$ so consider the map $\stalk{Y}{\eta} \to \stalk{X}{\xi}$ which gives $K(Y) \embed K(X)$. Since $K(Y)$ is a field this map is flat so we may apply the previous lemma to get a flat neighborhood of the generic point of $X$ which is dense since $X$ is irreducible. 
\end{proof}

\begin{theorem}[Tag 052B]
Let $f : X \to Y$ be a finite type morphism with $Y$ reduced. Then there exists a dense open subset $U \subset Y$ such that $f : X_U \to U$ is flat and of finite presentation. 
\end{theorem}

\section{Kahler Differentials (WIP)}

\begin{proposition}
Let $B, A'$ be $A$-algebras and $B' = B \otimes_A A'$ then,
\[ \Omega_{B' / A'} = \Omega_{B / A} \otimes_B B' \]
\end{proposition}

\newcommand{\Der}[3]{\mathrm{Der}_{#1} \left(#2, #3\right)}

\begin{proof}
Be definition, for any $B'$-module $M$,
\[ \Hom{B'}{\Omega_{B'/A'}}{M} = \Der{A'}{B'}{M} \]
\end{proof}

\begin{proposition}
Let $B$ be an $A$-algebra and $S \subset B$ a multiplicative system then,
\[ \Omega_{S^{-1} B / A} = S^{-1} \Omega_{B/A} \]
\end{proposition}

\begin{proposition}
Let $A \to B \to C$ be rings. Then there is an exact sequence,
\begin{center}
\begin{tikzcd}
\Omega_{B/A} \otimes_B C \arrow[r] & \Omega_{C/A} \arrow[r] & \Omega_{C / B} \arrow[r] & 0
\end{tikzcd}
\end{center}
\end{proposition}

\begin{proposition}
Let $B$ be an $A$-algebra and $I \subset B$ an ideal and $C = B / I$. Then there is an exact sequence,
\begin{center}
\begin{tikzcd}
I / I^2 \arrow[r, "\delta"] & \Omega_{B/A} \otimes_B C \arrow[r] & 
\Omega_{C/A} \arrow[r] & 0 
\end{tikzcd}
\end{center}
\end{proposition}

\begin{proof}

\end{proof}

\section{Finite Locally Free Modules (WIP)}

\begin{definition}
Let $(X, \struct{X})$ be a ringed space and $\F$ a sheaf of $\struct{X}$-modules. Then $\F$ is finite locally free if there exists an open cover of $X$ by opens $U$ s.t. $\F|_U \cong (\struct{X}|_U)^{\oplus n}$. 
\end{definition}

\begin{proposition}
If $\F$ is a finite locally free $\struct{X}$-module then $\F_x$ is a finite free $\stalk{X}{x}$-module.
\end{proposition}

\begin{proposition}

\end{proposition}

\section{Line Bundles (WIP)}


\section{Compactifications}

\begin{definition}
Let $X$ be a topological space. Then the one-point compactification $\hat{X}$ is the set $X \cup \{ \infty_X \}$ with a topology whose closed sets are,
\begin{enumerate}
\item $C \cup \{\infty_X\}$ where $C \subset X$ is closed
\item $D$ where $D \subset X$ is closed and compact
\end{enumerate}
\end{definition}

\begin{proposition}
For any $X$, $\hat{X}$ is compact.
\end{proposition}

\begin{proof}
Let $\mathfrak{U}$ be an open covering of $\hat{X}$. Then there must exist $U \in \mathfrak{U}$ s.t. $\infty_X \in U$ thus $U^C = D$ where $D \subset X$ is compact. Then $\mathfrak{U} \cap D$ is an open cover of $D$ which is compact and thus has a finite supcover. Possibly adding $U$ this given a finite subcover of $\hat{X}$. 
\end{proof}

\begin{proposition}
The canonical map $c : X \to \hat{X}$ is a continuous injection and is an open embedding.
\end{proposition}

\begin{proof}
We have $c^{-1}(C \cup \{ \infty_X \}) = C$ and $c^{-1}(D) = D$ are closed by definition and $c : X \to \hat{X}$ is injective. For any open set $U \subset X$ then $c(U) = U \subset \hat{X}$ is the complement of $(X \setminus U) \cup \{ \infty_X \}$ which is closed in $\hat{X}$ so $U \subset \hat{X}$ is open.  
\end{proof}

\begin{definition}
A continuous map $f : X \to Y$ is quasi-proper if for any compact closed $C \subset Y$ we have $f^{-1}(C) \subset X$ is compact (and closed by continuity).
\end{definition} 

\begin{remark}
When the target is Hausdorff proper and quasi-proper are identical since all compact subsets are automatically closed. 
\end{remark}

\begin{proposition}
The map $f : X \to Y$ is proper iff $\hat{f} : \hat{X} \to \hat{Y}$ is continuous.
\end{proposition}

\begin{proof}
The closed sets of $\hat{Y}$ are $C \cup \{ \infty_Y \}$ where $C \subset Y$ is closed and $D \subset Y$ where $D$ is compact. Then $\hat{f}^{-1}(C \cup \{ \infty_Y \}) = f^{-1}(C) \cup \{ \infty_X \}$ which is closed in $X$ automatically by the continuity of $f$. Furthermore, $\hat{f}^{-1}(D) = f^{-1}(D)$ is a subset of $X \subset \hat{X}$ which is closed in $\hat{X}$ iff it is compact. Thus $\hat{f}$ is continuous iff $f$ is proper. 
\end{proof}

\begin{proposition}
$\hat{X}$ is Hausdorff iff $X$ is Hausdorff and locally compact.
\end{proposition}

\begin{proof}
If $\hat{X}$ is Hausdorff then under the embedding $X \embed \hat{X}$ we see $X$ is Hausdorff. Furthermore, to seperate $x \in X$ from $\infty_X$ there must exist an open neighborhood $x \in U$ and a compact $D \subset X$ such that $x \in U \subset D$ in order that $U \cap (\hat{X} \setminus D) = \varnothing$ and $\hat{X} \setminus D$ is an open neighbrohood of $\infty_X$ when $D$ is compact. Thus we see that $X$ is locally compact. Conversely, shows that locally compact implies $\hat{X}$ is Hausdorff. 
\end{proof}

\begin{proposition}
Let $f : X \to Y$ be proper and $Y$ be Hausdorff and locally compact. Then $f$ is closed. 
\end{proposition}

\begin{proof}
Since $f : X \to Y$ is proper (equivalently quasi-proper since $Y$ is Hausdorff) then $\hat{f} : \hat{X} \to \hat{Y}$ is continuous. However, $\hat{X}$ is compact and $\hat{Y}$ is Hausdorff (since $Y$ is Hausdorff and locally compact) so $\hat{f}$ is closed. Thus, for any closed $C \subset X$ then $C \cup \{ \infty_X \}$ is closed in $\hat{X}$ so $\hat{f}(C \cup \{\infty_X \}) = f(C) \cup \{ \infty_Y \}$ is closed in $\hat{Y}$ and thus $f(C) \subset Y$ is cloesd.
\end{proof}

\begin{proposition}
Let $f : X \to Y$ be a nonconstant proper holomorphic map of complex manifolds with $Y$ connected. Then $f$ is surjective. 
\end{proposition}

\begin{proof}
Since $f : X \to Y$ is holomorphic and nonconstant $f(X) \subset Y$ is open. Furthermore, since $f : X \to Y$ is proper (and any manifold is Hausdorff and locally compact) then $f(X) \subset Y$ is closed. Thus, since $Y$ is connected, $f(X) = Y$. 
\end{proof}

\section{The Spin Statistics Theorem (WIP)}

The K\"{a}hlen-Leman spectral resolution,
\[ \bra{\Omega} \hat{\phi}_i(x) \: \hat{\phi}_j(y) \ket{\Omega} = \]

(REPS)

We have $U_\Lambda \hat{\phi}_i(x) U^\dagger_\Lambda = S(\Lambda)_{ij} \hat{\phi}_j(\Lambda^{-1} x)$.
\begin{enumerate}
\item[$s = 0$] we have $S = \id$
\item[$s = \tfrac{1}{2}$] (CLIFFORD) we have $S(\Lambda) = e^{s^{\mu \nu} \omega_{\mu \nu}}$ where,
\[ s^{\mu \nu} = (CHECK DO THIS) \] 
For the case of boosts,
\[ S(p)_{ij} = e^{\tfrac{1}{2} \vec{\chi}_p \cdot \gamma^0 \gamma^i} = \sqrt{\frac{\gamma^0 \gamma_\mu p^\mu}{m}} \]
We know that $\gamma^0 S^\dagger \gamma^0 = S^{-1}$. 
Then,
\[ S S^\dagger \gamma^0 = S \gamma^0 S^{-1} = \Lambda^{0}_\mu \gamma^\mu = \frac{\bar{p}_\mu \gamma^\mu}{m} \]
Furthermore,
\[ S \gamma^0 S^\dagger = S S^{-1} \gamma^0 = \gamma^0 \]
\end{enumerate}

(CLIFFORD ALGEBRA)
For the case of spin 


\begin{remark}
We have $S(-p) S(-p)^\dagger$. However, note that $S(-p) = R S(p) R^{-1}$ where $R$ is  a rotation by $\pi$ matrix about a fixed axis. Then,
\[ S(-p) S(-p)^\dagger = R S(p) R^{-1} (R^{-1})^\dagger S(p)^\dagger R^\dagger \]
The rotation group inside $\mathrm{SO}(1,3)$ is compact so we may choose our representation so it restricts to a unitary representation on $\mathrm{SO}(3) \subset \mathrm{SO}(1,3)$. Thus, $R^\dagger = R^{-1}$ so we have,
\[ S(-p) S(-p)^\dagger = R S(p) S(p)^\dagger R^{-1} \]
\end{remark}
Thus we have shown that,
\[ \bra{\Omega} \hat{\phi}(x) \: \hat{\phi}(y) \ket{\Omega} = \bra{\Omega} R \hat{\phi}(y) \: R \hat{\phi}(x)  \ket{\Omega} \]

\newpage

\section{Representation Theory: An Annoying Tale of Physics Notation}

You will often see the following witten down in a physics text,
\[ Y^\ell_m(R \vec{x}) = \sum_{m'} V(R)_{m m'} Y^{\ell}_{m'}(\vec{x}) \]
for some representation $V$ of $\SO{3}$ i.e. $V(R_1 R_2) = V(R_1) V(R_2)$. However, the way we Mathematicians act on function spaces to make them into actual (left) representations is $(R \cdot f)(x) = f(R^{-1} x)$. What the physicist wrote down of the left looks like a right representation but on the left it looks like a left representation. How can this make sense??
\bigskip\\
An even more egrigious example is the trasformation properrties of a qunatum field,
\[ U^\dagger(\Lambda) \phi_i(x) U(\Lambda) = S_{ij}(\Lambda) \phi_{j}(\Lambda^{-1} x) \]
for a unitary $G$-representation $U$ and a (usually not unitary) $G$-representaion $S$. Again $U(\Lambda_1 \Lambda_2) = U(\Lambda_1) U(\Lambda_2)$ and $S(\Lambda_1 \Lambda_2) = S(\Lambda_1) S(\Lambda_2)$. 
Now the right hand side loos like a good honest representation (with functions acted on correctly this time) but the left hand side is the epitome of a right representation. What??
\bigskip\\
For the spherical harmonics, note that the definition is at least consistent since,
\begin{align*}
Y^\ell_m(R_1 R_2 \vec{x}) & = \sum_{m'} V(R_1)_{m m'} Y^\ell_{m'}(R_2 \vec{x}) = \sum_{m' m''} V(R_1)_{m m'} V(R_2)_{m' m''} Y^\ell_{m''}(\vec{x}) 
\\
& = \sum_{m''} V(R_1 R_2)_{m m''} Y^\ell_{m''}(\vec{x})
\\
& = Y^\ell_m((R_1 R_2) \vec{x})
\end{align*}
The issue is that physicsts only write down the action on the basis and how the representation \textit{transforms the basis}. Mathematicians usually don't think this way, instead prefering to take the basis to be invariant (some geometrical aspect of the space perhaps) and the action permuting points by acting on their coordinates. It turns out that both left hand sides are indeed right representations when thinking about their action on the entire space in which case we will find that the right hand side is also a right representating in this context. However, both sides can be interpreted as left actions \textit{on the basis}. 
\bigskip\\
An arbitary function is expressed as,
\[ f(\vec{x}) = \sum_{\ell = 0}^\infty \sum_{-\ell \le m \le \ell} C^m_\ell Y^\ell_m(\vec{x}) \]
This function is represented by the coefficents $C^m_\ell$. Now we act on the left in the standard fashion,
\begin{align*}
(R \cdot f)(\vec{x}) & = f(R^{-1} \vec{x}) =  \sum_{\ell = 0}^\infty \sum_{-\ell \le m \le \ell} C^m_\ell Y^\ell_m(R^{-1} \vec{x})
\\
& = \sum_{\ell = 0}^\infty \sum_{-\ell \le m \le \ell} C^m_\ell \sum_{m'} V(R^{-1})_{m m'} Y^{\ell}_{m'}(\vec{x})
\\
& = \sum_{\ell = 0}^\infty \sum_{m, m'} C^m_{\ell} V(R^{-1})_{m m'} Y^{\ell}_{m'}(\vec{x})
\end{align*}
Therefore, the new coefficients are $\tilde{C}^{m'}_\ell = C^m_\ell V(R^{-1})_{m m'}$ so in vector notation,
\[ \tilde{C}_\ell = V(R^{-1})^\top C_\ell \] which is clearly a left action on the coordinates even though the inverse appears to make this action a right action on the $Y^\ell_m$. 
\bigskip\\
Now we take on the case of quantum fields. Again, first note there is consistency of the definition since,
\begin{align*}
U^\dagger(\Lambda_1 \Lambda_2) \phi_i(x) U(\Lambda_1 \Lambda_2) & = U^\dagger(\Lambda_2) U^\dagger(\Lambda_1) \phi_i(x) U(\Lambda_1) U(\Lambda_2) 
\\
& = U^\dagger(\Lambda_2) S_{ij}(\Lambda_1) \phi_j(\Lambda_1^{-1} x) U(\Lambda_2)
\\
& = S_{ij}(\Lambda_1) S_{jk}(\Lambda_2) \phi_k(\Lambda_2^{-1} \Lambda_1^{-1} x) 
\\
& = S_{ik}(\Lambda_1 \Lambda_2) \phi_k((\Lambda_1 \Lambda_2)^{-1} x)
\\
& = U^\dagger(\Lambda_1 \Lambda_2) \phi_i(x) U(\Lambda_1 \Lambda_2)
\end{align*}
Now, an arbitrary operator in the span of this basis of tensor operators is acted on via,
\begin{align*}
U(\Lambda) \psi^i(x) \phi_i(x) U^\dagger(\Lambda) & = \psi^i(x) S_{ij}(\Lambda^{-1}) \phi_j(\Lambda x)
\end{align*}
For $x = 0$ we clearly see that the operator $\psi^i(0) \phi_i(0)$ has its coefficients transformed as $\psi \mapsto S(\Lambda^{-1})^\top \psi$ as before which is a left action. Now if we consider these as operator functions, then the correct transformation is,
\begin{align*}
\psi^i(x) \phi_i(x) \mapsto U(\Lambda) \psi^i(\Lambda^{-1} x) \phi_i(\Lambda^{-1} x) U^\dagger(\Lambda) & = \psi^i(\Lambda^{-1} x) S_{ij}(\Lambda^{-1}) \phi_j(x) 
\end{align*}
which again simply shifts the coordinates $\psi(x) \mapsto S(\Lambda^{-1})^\top \psi(\Lambda^{-1} x)$ and is clearly a left action on both the left and the right hand sides. 

\section{Moduli Spaces (WIP)}

\begin{definition}

\end{definition}

\renewcommand{\S}{\mathcal{S}}

\begin{definition}
Let $T : \C \to \S$ be a functor and $F : A \to B$ a morphism in $\S$ and $Y \in \C$ with $T(Y) = B$. Then a pullback $F^* Y$ is a morphism $F^* Y \to Y$ with $F^* Y$ over $A$ satisfying the following univeral property,
\begin{center}
\begin{tikzcd}
X \arrow[rr, bend left] \arrow[d, dotted, "T"]  \arrow[r, dashed] 
& F^* Y \arrow[r] \arrow[d, dotted, "T"] & Y \arrow[d, dotted, "T"]
\\
C \arrow[r] & A \arrow[r, "F"] & B
\end{tikzcd}
\end{center}
\end{definition}

\begin{definition}
A fibred category $(\C, T : \C \to \S)$ is a category $\C$ and a functor $T : \C \to \S$ where $S$ is a cite such that all pullbacks along $T$ exist and that for each $X,Y \in \C$ above $B \in \S$ and a morphism $F : A \to B$ in $\S$ the presheaf $F \mapsto \Hom{\C}{T^* X}{T^* Y}$ in the category of objects over $B$ is a sheaf. 
\end{definition}

\begin{example}
The category of vector bundles is a category fibred over smooth manifolds equiped with the open immersion topology (WHAT TOPOLOGY). 
\end{example}

\begin{example}
The category of abelian sheaves is fibred over the category of schemes given the \'{e}tale topology. 
\end{example}

\section{Abelian Varieties Have a Unique Group Law (WIP)} 

\begin{proposition}
The geometric group law and the analytic group law coincide.
\end{proposition}

\begin{proof}
Let $\Lambda \subset \C$ be a lattice, $E$ the associated elliptic curve over $\C$ and $\Phi_{\wp} : \C / \Lambda \to E$ the map induced by the Wierstrass $\wp$-function. For $P \in E$ let $T_P : E \to E$ be the map $Q \mapsto P + Q$. Then define, $\tau_P = \Phi_{\wp}^{-1} \circ T_P \circ \Phi_{\wp} : \C / \Lambda \to \C / \Lambda$. The map $\tau_P$ is holomorphic because $\Phi_{\wp}$ is biholomorphic and $T_P$ is given by rational functions. Let $\pi : \C \to \C / \Lambda$ be the projection map and take $g = \tau_P \circ \pi$ which is doubly periodic. Then $g' : \C \to \C$ is a well-defined holomorphic function since, although its image is only defined up to addition by $\omega \in \Lambda$, its derivative is invariant under addition by a constant. Thus, $g'$ is holomorphic and doubly periodic so $g'$ is constant. Thus $g$ is a linear function so $\tau_P = c_P z + d_P$ where $c_P$ and $d_P$ are constants determined by $P$. Firstly, 
\[ \tau_P(0) = d_P =  \Phi_{\wp}^{-1} \circ T_P \circ \Phi_{\wp}(0) = \Phi_{\wp}^{-1}(T_P(O)) = \Phi_{\wp}^{-1}(P + O) = \Phi_{\wp}^{-1}(P) \]
Secondly, since $T_A$ is an automorphism of $E$ and $\Phi_{\wp}$ is a bijection, $\tau_P$ is a map of the fundamental domain $D$ onto itself bijectivly which must preserve area so $|c_P| = 1$. If $c_p \neq 1$ then $c_P z + d_P = z$ has a solution, namely $z = d_P (1 - c_P)^{-1}$ so $\tau_P$ has a fixed point. However, if $\tau_P(z) = z$ then 
\[ T_P \circ \Phi_{\wp}(z) = \Phi_{\wp} \circ \tau_P(z) = \Phi_{\wp}(z) \]
so $\Phi_{\wp}(z)$ is a fixed point of $T_P$ i.e. $P + \Phi_{\wp}(z) = \Phi_{\wp}(z)$ which cannot happen unless $P = O$ since $(E, +)$ is a group. However, in the case $P = O$ we have $T_O = \id_E$ so $\tau(z) = z$. Thus, either way, $c_P = 1$ so $\tau_P(z) = z + \Phi_{\wp}^{-1}(P)$. Therefore, the geometric group law action $T_P$ is equivalent to a translation $\tau_P(z) = z + \Phi_{\wp}^{-1}(P)$ on the complex torus. In particular, we defined the analytic group law by,
\[ P +_A Q = \Phi_{\wp}(\Phi_{\wp}^{-1}(P) + \Phi_{\wp}^{-1}(Q)) = \Phi_{\wp} \circ \tau_P \circ \Phi_{\wp}^{-1}(Q) = T_P(Q) = P +_G Q \]
which equals the geometric group law.
\end{proof}

\begin{remark}
Since we assumed almost nothing about the geometric group law in this proof, we actually proved a far more remarkable fact. We proved that there is a \textit{unique} group law on $E$ whose identity is the distinguished point $O$ and which is regular with respect to $\wp$ in the sense that $\Phi_{\wp} \circ T_P \circ \Phi_{\wp}^{-1} : \C / \Lambda \to \C / \Lambda$ is holomorphic. This is true of the geometric group law because it is given by rational functions. This extremely powerful uniqueness shows that there cannot be any other group law on $E$ given by rational functions or even by holomorphic functions in the above sense. Requiring that $T_P$ be a regular map is the defining property of an \textit{algebraic group} or, here in the special case of projective algebraic varieties, of an \textit{abelian variety}. We have shown that the geometry of our elliptic curve determines completely and rigidly the algebraic stucture on it. It is exactly this rigidness which makes the group law on an elliptic curve such a natural and indespensible tool for studying the geometry which uniquely determines it. 
\end{remark}

\begin{theorem}
Let $A$ be an abelian variety over $k$ and $f, g : A \to A$ be nonconstant maps. If for some $x \in A(\overline{k})$ we have $f(x) = g(x)$ then $f = g$.
\end{theorem}

\begin{proof}
(LOOK AT MILNES PROOF)
\end{proof}

\begin{corollary}
Abelian varieties have a unique regular group law given a fixed choice of identity.
\end{corollary}

\begin{proof}
For $p \in A$ consider $T_p : A \to A$ via $T_p(x) = p + x$. For any other group law, consider $T'_p : A \to A$. For the identity $e \in A$ we have $T_p(e) = p + e = 1$ and, by assumption, $T'_p(e) = p$. Thus $T_p = T_p'$. 
\end{proof}

\section{Fine Sheaves}

\begin{definition}
A sheaf $\F$ on $X$ is fine if for every open cover $\mathfrak{U}$ (DO THIS)
\end{definition}

\begin{definition}
A sheaf $\F$ on $X$ is soft if for each closed $\iota : C \embed X$ the map $H^0(X, \F) \to H^0(C, \iota^* \F)$ is surjective. 
\end{definition}

\section{Lie Algebra Cohomology}

\begin{definition}
Let $\g$ be a Lie algebra over $k$. Then a $\g$-module $M$ is an abelian group $M$ and a morphism of Lie algebras $\g \to \gl{M}$. 
\end{definition}

\begin{remark}
By the universal property of the universal enveloping algebra we get,
\begin{center}
\begin{tikzcd}
\g \arrow[r] \arrow[d] & \gl{M} 
\\
U \g \arrow[ru, dashed]
\end{tikzcd}
\end{center}
and thus we get a $k$-algebra map $U \g \to \gl{M}$ i.e. makes $M$ a $U \g$-module. Thus, the category of $\g$-modules is canonically equivalent to the category of $U \g$-modules. 
\end{remark}

\begin{definition}
Let $\g$ be a Lie algebra. Consider the functor $(-)^\g : \mathbf{Mod}_\g \to \mathbf{Mod}_k$ sending $M \mapsto M^\g$ to its invariants under the $\g$-action (or equivalently the $U \g$-action. Then the Lie algebra cohomology $H^n(\g, -)$ is the $n^{\text{th}}$-right-derived functor of $(-)^\g$.  
\end{definition}

\begin{remark}
Considering $M$ as a $U\g$-module we have $M^\g = M^{U \g}$ (since $U \g$ is generated by $\g$ and has a compatible action). Therefore,
\[ M^{\g} = M^{U \g} = \Hom{U \g}{k}{M} \]
and thus the right-derived functors are,
\[ H^n(\g, M) = \Ext{n}{U \g}{k}{M} \]
similar to the cohomology of groups.
\end{remark}


\begin{definition}
Let $\g$ be a Lie algebra over $k$. Then the Chevalley–Eilenberg complex complex is given by,
\[ C_M^n = \Hom{k}{\Lambda^n \g}{M} \]
With differential defined by the Lie bracket $[\cdot,\cdot] : \Lambda^2 \g \to \g$ of the algebra $\g$. Explicitly, let $f : \Lambda^n \g \to M$ be a $n$-cochain then define the $(n+1)$-cochain $\d{f}$ as follows,
\begin{align*}
\d{f}(x_1, \dots, x_{n+1}) & = \sum_{i = 1}^{n+1} (-1)^{i + 1} x_i \cdot f(x_1, \dots, \hat{x}_i, \dots, x_{n+1}) 
\\
& + \sum_{i < j} (-1)^{i + j} f([x_i, x_j], x_1, \dots, \hat{x}_i, \dots, \hat{x}_j, \dots, x_{n+1})
\end{align*}
\end{definition}

\begin{theorem}
The cohomology of the Chevalley–Eilenberg complex computes the Lie algebra cohomology. Explicitly,
\[ H^n(\g, M) = \Ext{n}{U \g}{k}{M} = H^n(\Hom{U\g}{U\g \otimes_k \Lambda^\bullet \g}{M}) = H^n(\Hom{k}{\Lambda^\bullet \g}{M}) \]
\end{theorem}

\begin{proof}
It suffices to show that the Chevalley–Eilenberg chain complex,
\[ U \g \otimes_k \Lambda^\bullet \g \to k \]
is a projective resolution of $k$ in the category of $U \g$-modules which has the given differential,
\begin{align*}
\d{(u \otimes x_1 \wedge \dots \wedge x_{n+1})} & = \sum_{i = 1}^{n+1} (-1)^{i+1} u x_i \otimes x_1 \wedge \cdots \wedge \hat{x}_i \wedge \cdots \wedge x_{n+1} 
\\
& + \sum_{i < j} (-1)^{i + j} u \otimes [x_i, x_j] \wedge \dots \wedge \hat{x}_i \wedge \dots \wedge \hat{x}_j \wedge \dots x_{n+1}
\end{align*} 
Exactness is clear by computation. Furthermore, since $\Lambda^n_k \g$ is a free $k$-module then $U \g \otimes_k \Lambda^n_k \g$ is a free $U \g$-module and thus projective. 
\end{proof}

\begin{remark}
We also need to check that the the Chevalley–Eilenberg chain complex induces the the Chevalley–Eilenberg cohain complex defined above. Note the under the isomorphism $\Hom{U \g}{U \g \otimes_k N}{M} = \Hom{k}{N}{M}$ we send $f : U \g \otimes_k N \to M$ to $\tilde{f} : N \to M$ via $\tilde{f}(n) = f(1 \otimes n)$. And thus, the induced differential corresponds to,
\begin{align*}
\d{\tilde{f}}(x_1, \dots, x_{n+1}) & = \widetilde{f \circ \d{(x_1, \dots, x_{n+1})}} = f \circ \d{(1 \otimes x_1 \wedge \dots \wedge x_{n+1})} 
\\
& = \sum_{i = 1}^{n+1} (-1)^{i+1} f(x_i \otimes x_1 \wedge \cdots \wedge \hat{x}_i \wedge \cdots \wedge x_{n+1})
\\
& + \sum_{i < j} (-1)^{i + j} f(1 \otimes [x_i, x_j] \wedge \dots \wedge \hat{x}_i \wedge \dots \wedge \hat{x}_j \wedge \dots x_{n+1})
\\
& = \sum_{i = 1}^{n+1} (-1)^{i+1} x_i \cdot f(1 \otimes x_1 \wedge \cdots \wedge \hat{x}_i \wedge \cdots \wedge x_{n+1})
\\
& + \sum_{i < j} (-1)^{i + j} \tilde{f}([x_i, x_j] \wedge \dots \wedge \hat{x}_i \wedge \dots \wedge \hat{x}_j \wedge \dots x_{n+1})
\\
& = \sum_{i = 1}^{n+1} (-1)^{i+1} x_i \cdot \tilde{f}(x_1 \wedge \cdots \wedge \hat{x}_i \wedge \cdots \wedge x_{n+1})
\\
& + \sum_{i < j} (-1)^{i + j} \tilde{f}([x_i, x_j] \wedge \dots \wedge \hat{x}_i \wedge \dots \wedge \hat{x}_j \wedge \dots x_{n+1})
\end{align*}
which is the differential we defined earlier. 
\end{remark}

\newcommand{\Inn}{\mathrm{Inn}}

\begin{proposition}
The first two Lie algebra cohomology groups have explict descriptions. We have, 
\[ H^1(\g, M) = \Der{k}{\g}{M} / \Inn(\g, M) \]
the space of derivations $d : \g \to M$ satisfying $d([x, y]) = x d(y) - y d(x)$ modulo inner derivations $d(x) = x \cdot m$ for some $m \in M$. Furthermore, $H^2(\g, M)$ classifies isomorphism classes of Lie algebra extensions of $\g$ by $M$,
\begin{center}
\begin{tikzcd}
1 \arrow[r] & M \arrow[r] & \h \arrow[r] & \g \arrow[r] & 1
\end{tikzcd}
\end{center}
\end{proposition}

\begin{proof}
Consider $f \in \ker{(C^1_M \to C^2_M)}$ this is $f : \g \to M$ such that $\d{f} = 0$ i.e.,
\[ \d{f}(x, y) = x \cdot f(y) - y \cdot f(x) - f([x, y]) = 0 \]
and thus $f([x,y]) = x \cdot f(y) - y \cdot f(x)$. Then $H^1(\g, M) = \ker{(C^1_M \to C^2_M)} / \im{(C^0_M \to C^1_M)}$ where $C^0_M = \Hom{k}{k}{M} = M$ and for any point $f_a : k \to M$ with image $f_a : 1 \mapsto a$ we have,
\[ \d{f_a}(x) = x \cdot f_a(1) = x \cdot a \]
so the image is functions of this form giving the required computation of $H^1(\g, M)$. The computation for $H^2(\g, M)$ is similar defining extensions via a section satsifying the conition of a $2$-cochain. 
\end{proof}

\begin{lemma}[Whitehead]
Let $\g$ be a semisimple Lie algebra and $M$ a finitely-generated $\g$-module. Then,
\[ H^1(\g, M) = H^2(\g, M) = 0 \]
\end{lemma}


\begin{proof}
(DO THIS)
\end{proof}



\subsection{The Relationship with deRham Cohomology}


\begin{theorem}
Let $G$ be a compact connected Lie group with Lie algebra $\g$. Then,
\[ H^n_{\text{dR}}(G) = H^n(\g, \R) \]
\end{theorem}

\begin{proof}
Consider the de Rham complex on $G$,
\begin{center}
\begin{tikzcd}
0 \arrow[r] & \Omega^0(G) \arrow[r] &  \Omega^1(G) \arrow[r]  & \Omega^2(G) \arrow[r] & \Omega^3(G) \arrow[r] & \cdots 
\end{tikzcd}
\end{center}
which is equivalent to the complex,
\begin{center}
\begin{tikzcd}
0 \arrow[r] & \Omega^0(G) \arrow[r] & \Lambda^\bullet \Omega^1(G)
\end{tikzcd}
\end{center}
Consider taking the $G$-invariants of this complex of forms to give a new complex,
\begin{center}
\begin{tikzcd}
0 \arrow[r] & \R \arrow[r] & \Lambda^\bullet \Omega^1(G)^G
\end{tikzcd}
\end{center}
Furthermore, the left-invariant $1$-forms $\Omega^1(G)^G$ are dual to the left-invaiant vector fields $\g$ i.e. $\Omega^1(G)^G = \g^* = \Hom{\R}{\g}{\R}$. Therefore, the invariants of the de Rham complex gives exactly the Chevalley–Eilenberg cochain complex for $\R$, $\Hom{\R}{\Lambda^\bullet \g}{\R}$. 
Therefore, it suffices to show that the cohomology of  the $G$-invariant de Rham complex coincides with usual de Rham cohomology since this $G$-invariant cohomology is exactly computing the cohomology of the above Chevalley–Eilenberg complex and thus the Lie algebra cohomology $H^n(\g, \R)$.  
\bigskip\\
Consider the subcomplex $\iota : \Omega_L^\bullet(G) \embed \Omega^\bullet(G)$ of left-invariant forms (what we calld $\Omega^\bullet(G)^G$ earlier). Since $G$ is compact, there is an averaging map which forms a retract $r : \Omega^\bullet(G) \to \Omega_L^\bullet(G)$ defined via,
\[ \omega \mapsto \frac{1}{\mathrm{Vol}(G)} \int_{g \in G} L^*_g \: \omega \]
Clearly, $r \circ \iota = \id$ so it suffices to check that $\iota \circ r$ is the identity on cohomology. In fact, there is a chain homotopy $\iota \circ r \to \id$ via (DO THIS)
\end{proof}

\begin{theorem}
Let $G$ be a Lie group. Then $\pi_1(G)$ is abelian, $\pi_2(G) = 0$, and $\pi_3(G)$ is torsion-free.
\end{theorem}

\begin{proof}

\end{proof}

\begin{corollary}
Let $G$ be a simply-connected Lie group. Then $H^2_{\text{dR}}(G) = 0$.
\end{corollary}

\begin{proof}
Since $G$ is simply-connected, via Whitehead's theorem,
\[ \pi_2(G) \to H_2(G) \to H^2(G)^\vee \]
is an isomorphism. And thus $H^2(G) = 0$.
\end{proof}

\begin{corollary}
If $\g$ is a compact Lie algebra then,
\[ H^1(\g, \R) = H^2(\g, \R) = 0 \]
\end{corollary}

\begin{proof}
Let $G$ be a compact simply-connected Lie group with Lie algebra $\g$. Then we know,
\[ H^n(\g, \R) = H^n_{\mathrm{dR}}(G) \]
Since $G$ is simply-connected we have,
\[ H^1_{\mathrm{dR}}(G) = H^2_{\mathrm{dR}}(G) = 0 \]
proving the theorem. 
\end{proof}


\section{Projective Representations}

\begin{lemma}
Given an exact sequence (which here means $N \embed G$ is a normal Lie subgroup equal to the kernel of $G \to H$ and $G \to H$ induces $G / N \cong H$),
\begin{center}
\begin{tikzcd}
1 \arrow[r] & N \arrow[r] & G \arrow[r] & H \arrow[r] & 1
\end{tikzcd}
\end{center}
of Lie groups, we get an exact sequence of their Lie algebras,
\begin{center}
\begin{tikzcd}
1 \arrow[r] & \mathfrak{n} \arrow[r] & \g \arrow[r] & \h \arrow[r] & 1
\end{tikzcd}
\end{center}
\end{lemma}

\begin{proof}
Consider the functors,
\[ \mathrm{Lie} : \mathbf{LieAlg} \to \mathbf{LieGrp}\quad \text{and} \quad T_e : \mathbf{LieGrp} \to \mathbf{LigAlg} \]
Then Lie's theorems give an adjunction,
\[ \Hom{\mathbf{LieGrp}}{\Lie{\g}}{H} = \Hom{\mathbf{LieAlg}}{\g}{T_e H} \]
so the functor $T_e$ is automatically right-exact. Therefore, it suffices to show that $T_e$ preserves the injection. This is immediate from the definition of $N \embed G$ as a Lie subgroup which includes injectivity of the differential $\mathfrak{n} \to \g$. However, it is also the case that for any morphism $G \to H$,
\[ T_e \ker{(G \to H)} = \ker{(\g \to \h)} \] 
We use the naturality of the exponential,
\begin{center}
\begin{tikzcd}
\ker{f} \arrow[r] & G \arrow[r, "f"] & H
\\
\mathfrak{k} \arrow[r] \arrow[u, "\exp"] & \g \arrow[r, "f_*"] \arrow[u, "\exp"] & \h \arrow[u, "\exp"']
\end{tikzcd}
\end{center}
and the fact that it is a local diffeomorphism. For $\xi \in \g$ with $f_*(\xi) = 0$ then $f(\exp{\xi}) = \exp{f_*(\xi)} = \exp{(0)} = 1$ so $\exp{\xi} \in \ker{f}$ and thus $\xi \in \mathfrak{k}$. Conversely, if $\xi \in \mathfrak{k}$ then since $f : G \to H$ is constant on $\ker{f} \subset G$ then $f_*(\xi) = 0$.  
\end{proof}

\begin{definition}
Let $G$ be a Lie group. A projective representation is a smooth group map $G \to \Aut{\P(V)}$. 
\end{definition}

\begin{remark}
The for finite dimensional vectorspaces $V$ the group $\Aut{\P(V)}$ can be idenified with the Lie group $\PGL{V}$ of invertible matrices up to scalling. 
\end{remark}

\begin{remark}
Often the fundamental question in the study of projective representations will be when they can be lifted to honest representations. Often this will require passage to the universal covering Lie group. 
\end{remark}

\begin{theorem}
Let $G$ be a connected Lie group with $H^2(\g, \R) = 0$. Then any projective representation $G \to \Aut{\P(V)}$ lifts to a representation $\tilde{G} \to \Aut{V}$ of the universal covering Lie group. 
\end{theorem}

\begin{proof}
We consider the base change i.e. pullback,
\begin{center}
\begin{tikzcd}
G \times_{\rho} \GL{V} \arrow[d] \arrow[r] & \GL{V} \arrow[d, "\pi"'] 
\\
G \arrow[r, "\rho"] & \PGL{V}
\end{tikzcd}
\end{center}
Consider the kernel of $G \times_{\rho} \GL{V} \to G$ this is all $(1, A) \in G \times_\rho \GL{V}$ which must thus satisfy, $\pi(A) = I$. Therefore, $A \in \R^\times I$ so we can identify, 
\[ \R^\times = \ker{(G \times_{\rho} \GL{V} \to G)} \]
Therefore, setting $H = G \times_\rho \GL{V}$ we get an extension of Lie groups,
\begin{center}
\begin{tikzcd}
1 \arrow[d]
\\
\R^\times \arrow[d]
\\
H \arrow[d] \arrow[r] & \GL{V} \arrow[d, "\pi"]
\\
G \arrow[d] \arrow[r, "\rho"] & \PGL{V}
\\
1
\end{tikzcd}
\end{center} 
Taking the Lie algebras of this extension gives an exact sequence,
\begin{center}
\begin{tikzcd}
1 \arrow[r] & \R \arrow[r] & \h \arrow[r] & \g \arrow[r] & 1
\end{tikzcd}
\end{center}
and thus $\h$ is an extension of $\g$ by $\R$. However $H^2(\g, \R)$ classifies such extensions and we have assumed this group is trivial. Therefore, this extension must be trivial so there must exist a section,
\begin{center}
\begin{tikzcd}
1 \arrow[r] & \R \arrow[r] & \h \arrow[r] & \g \arrow[l, bend right, "s"'] \arrow[r] & 1
\end{tikzcd}
\end{center}
This induces a map $s : \tilde{G} \to H$, where $\tilde{G}$ is the universal covering group of $G$, which gives $\tilde{G} \to H \to G$ is the quotient map $\tilde{G} \to G$ since this map induces the identy $\g \to \g$ on Lie algebras. This gives a diagram,
\begin{center}
\begin{tikzcd}
& 1 \arrow[d]
\\
& \R^\times \arrow[d]
\\
\tilde{G} \arrow[dr, "\pi"'] \arrow[r, "s"] & H \arrow[d] \arrow[r] & \GL{V} \arrow[d, "\pi"]
\\
& G \arrow[d] \arrow[r, "\rho"] & \PGL{V}
\\
& 1
\end{tikzcd}
\end{center}
This gives a standard representation $\tilde{G} \to \GL{V}$ compatible with the projective representation $G \to \PGL{V}$ in the sense that the following diagram commutes,
\begin{center}
\begin{tikzcd}
\tilde{G} \arrow[r, "\tilde{\rho}"] \arrow[d, "\pi"'] & \GL{V} \arrow[d, "\pi"]
\\
G \arrow[r, "\rho"] & \PGL{V}
\end{tikzcd}
\end{center}
\end{proof}

\begin{remark}
By Whitehead's Lemma, the lifting of projective representations then holds whenever $\g$ is semisimple. Furthermore, whenever $\g$ has a compact universal cover then $H^2(\g, \R) = H^2_{\mathrm{dR}}(G) = 0$ and thus the the lifting property for projective representations also holds. 
\end{remark}


\section{Complexified Lie Groups and Representations}

\renewcommand{\C}{\mathbb{C}}

\begin{remark}
In this section, a representation will refer to a representation on a complex vectorspace $V$. 
\end{remark}

\begin{definition}
Let $\g$ be a real Lie algebra then its complexification $\g_\C = \g \otimes_\R \C$ satisfies the folowing universal property. Given a complex Lie algera $\h$ any $\R$-linear Lie algebra map $\g \to \h$ factros through a unique $\C$-linear Lie algebra map $\g_\C \to \h$ as follows,
\begin{center}
\begin{tikzcd}
\g \arrow[r] \arrow[d] & \h
\\
\g_\C \arrow[ru, dashed]
\end{tikzcd}
\end{center}
\end{definition}

\begin{definition}
Let $\g$ be a complex Lie algebra. Then a real form of $\g$ is a real Lie algebra $\mathfrak{k}$ such that $\g = \mathfrak{k}_\C$.
\end{definition}

\begin{theorem}
Let $\g$ be a finite dimensional semi-simple complex Lie algebra. Then $\g$ admits a real form.
\end{theorem}

\begin{proof}
(DO THIS)
\end{proof}

\begin{proposition}
There is a one-to-one correspondence between real-linear representations of $\g$ and complex-linear representation of $\g_\C$.
\end{proposition}

\begin{proof}
Let $V$ be a complex vectorspace. Via the universal property, there is a correspondence between real linear Lie algebra maps $\g \to \gl{V}$ and complex-linear Lie algebra maps $\g_\C \to \gl{V}$. 
\end{proof}

\begin{definition}
Let $G$ be a real Lie group. Then a complexification of $G$ is a complex Lie group $G_\C$ satisfying the following universal property. Given any complex Lie group $H$, any real Lie group map $G \to H$ factors uniquely through a holomorphic Lie group map $G_\C \to H$ as follows,
\begin{center}
\begin{tikzcd}
G \arrow[r] \arrow[d] & H
\\
G_\C \arrow[ru, dashed]
\end{tikzcd}
\end{center}
\end{definition}

\begin{proposition}
Let $\g$ be a real Lie algebra and $G$ its unique simply connected Lie group. Then $G_\C$ is the unique  simply connected complex Lie group associated to the complex Lie algebra $\g_\C$. 
\end{proposition}

\begin{proof}
This is clear from Lie's theorems giving the correspondence betweeen morphisms $\g \to \h$ and $G \to H$ when $G$ is simply connected. Furthermore, complex-linear morphisms $\g_\C \to \h$ correspond to holomorphic group maps $G_\C \to H$. (EXPAND ON THIS)
\end{proof}

\begin{proposition}
There is a one-to-one correspondence between  representations of $G$ and holomorphic representation of $G_\C$.
\end{proposition}

\begin{proof}
Let $V$ be a complex vectorspace. Via the universal property, there is a correspondence between real Lie group maps $G \to \GL{V}$ and holomorphic Lie group maps $G_\C \to \GL{V}$. 
\end{proof}

\begin{lemma}
The finite-dimensional irreducible representations of $G \times H$ are exactly tensor products $V \otimes_\C W$ of finite-dimensional irreducible representation of $G$ and $H$ respectivly.
\end{lemma}

\begin{lemma}
Let $\g$ be a Lie algebra and $G$ is corresponding simply connected Lie group. There is a one-to-one correspondence between representation of $\g$ and representations of $G$.
\end{lemma}

\begin{proof}
Since $G$ is simply connected there is a correspondence between Lie group maps $G \to \GL{V}$ and Lie algebra maps $\g \to \gl{V}$. 
\end{proof}

\begin{example}
Computing the projective representation theory of the Lorentz group.
\end{example}

\renewcommand{\k}{\mathfrak{k}}
\renewcommand{\sl}{\mathfrak{sl}}
\newcommand{\su}{\mathfrak{su}}

\begin{proof}
Because the Lorentz group $\mathrm{SO}^+(1,3)$ is connected and simple its projective representations may be lifted to standard representations of the universal covering group $G = \SL{2, \C}$. Furthermore, the Lie algebra $\g = \mathfrak{so}(1,3) = \sl(2, \C)$ is thus naturally a complex Lie algebra with a real form $\k = \su(2)$. This classifies the complex-linear representations of $\g$ via the representations of $\su(2)$. However, we are interested in all representations of $\sl(2, \C)$ since we are not interested in its complex structure. 
\bigskip\\
First, I should check that $\su(2)$ is actually a real form for $\sl(2, \C)$. This follows directly from the fact that $\su(2)$ is comprised of $2 \times 2$ complex anti-hermitian trace zero matricies while $\sl(2, \C)$ is comprised of all $2 \times 2$ trace zero matrices. Since every complex matrix can be written in terms of its hermitian and anti-hermitian parts we find that $\sl(2, \C) = \su(2) \otimes_\R \C = \su(2) \oplus i \su(2)$ since $i \su(2)$ is the algebra of $2 \times 2$ complex trace zero Hermitian matrices. 
\bigskip\\
To complete the classification, we need to determine the real-linear representations of $\sl(2, \C)$ which is most easily done by considering $\sl(2, \C)$ as a real Lie algebra and considering its complexification and then computing the complex-linear representations of its complexification. We have,
\begin{align*}
\g_\C & = \sl(2, \C) \otimes_\R \C = (\su(2) \otimes_\R \C) \otimes_\R \C = \su(2) \otimes_\R ( \C \otimes_\R \C) 
\\
& = \su(2) \otimes_\R (\C \oplus \C) = \su(2)_\C \oplus \su(2)_\C = \sl(2, \C) \oplus \sl(2, \C)
\end{align*}  
Therefore, the representations of $\g = \sl(2, \C)$ are exactly the complex-linear representations of $\su(2)_\C \oplus \su(2)_\C = \sl(2, \C) \oplus \sl(2, \C)$. Furthermore, the finite-dimensional irreps of a sum of Lie algebras (corresponding to a direct product of Lie groups) are the tensor products of irreps of each factor. Thus, the complex-linear representations of $\g_\C$ are given by pairs of complex-linear representations of $\su(2)_\C$ i.e. real-linear representations of $\su(2)$. Thus, we have a clasification of (real-linear) representations  of $\sl(2, \C)$ as $V_{j_1} \otimes_\C V_{j_2}$ where each factor is a finite-dimensional (real-linear) irrep of $\su(2)$ which we know are classified by the spin parameter,  $j \in \frac{1}{2} \Z$. 
\end{proof}

\section{Magnetization}

Consider a system with a control parameter $B$, the magnetic field descirbed by a canonical partition function, $Z(\beta. B)$. We define the magnetization as the thermodynamic conjugate variable to $B$,
\[ M = - \left( \pderiv{E}{B} \right)_S = - \left( \pderiv{F}{B} \right)_T \]
where $F = E - ST = - T \log{Z}$. Thus, immediatly from the definition we have,
\[ \d{E} = T \d{S} - M \d{B} \]
Now consider the suseptibility, 
\[ \chi = \left( \pderiv{M}{B} \right)_T = - \left( \frac{\partial^2 F}{\partial B^2} \right)_T \]
We justify this definition with the following example.

\begin{example}
Consider a system of $N$ spins in a magentic field $B$ with some internal interaction hamiltonian $\hat{H}_{\text{int}}$ and a total hamiltonian,
\[ \hat{H} = \hat{H}_{\text{int}} - \sum_{i = 1}^N B \sigma_i \]
Then the partition function is,
\[ Z(\beta, B) = \sum e^{- \beta (\hat{H}_{\text{int}} - \sum\limits_{i = 1}^N B \sigma_i) } \]
The magnetization should equal,
\begin{align*}
\left< \sum_{i = 1}^N \sigma_i \right> & = \frac{1}{Z} \sum \left( \sum_{i = 1}^N \sigma_i \right) e^{- \beta (\hat{H}_{\text{int}} - \sum\limits_{i = 1}^N B \sigma_i) }
\\
& = \frac{1}{Z \beta} \pderiv{}{B} \bigg|_T \sum e^{- \beta (\hat{H}_{\text{int}} - \sum\limits_{i = 1}^N B \sigma_i) }
\\
& = \frac{1}{Z \beta} \pderiv{Z}{B} \bigg|_T
\\
& = - \pderiv{}{B} \bigg|_T (- T \log{Z} )
\\
& = - \left( \pderiv{F}{B} \right)_T
\end{align*}
Giving the proper definition of magnetization. Now we further compute the suseptibility,
\begin{align*}
\chi & = \left( \pderiv{M}{B} \right)_T = \pderiv{}{B} \bigg|_T \left( \frac{1}{Z} \sum \left( \sum_{i = 1}^N \sigma_i \right) e^{- \beta (\hat{H}_{\text{int}} - \sum\limits_{i = 1}^N B \sigma_i) } \right)
\\
& = \frac{\beta}{Z} \left( \sum \left( \sum_{i = 1}^N \sigma_i \right)^2 e^{- \beta (\hat{H}_{\text{int}} - \sum\limits_{i = 1}^N B \sigma_i) } \right) - \left( \sum \left( \sum_{i = 1}^N \sigma_i \right) e^{- \beta (\hat{H}_{\text{int}} + \sum\limits_{i = 1}^N B \sigma_i) } \right) \pderiv{}{B} \bigg|_T  \left( \frac{1}{Z} \right) 
\\
& = \beta \left< \left( \sum_{i = 1}^N \sigma_i \right)^2 \right> + M Z \pderiv{}{B} \bigg|_T \left( \frac{1}{Z} \right)
\\
& = \beta \left<  \left( \sum_{i = 1}^N \sigma_i \right)^2 \right> - M \frac{1}{Z} \pderiv{Z}{B} \bigg|_T 
\\
& = \beta \left<  \left( \sum_{i = 1}^N \sigma_i \right)^2 \right> - M \pderiv{\log{Z}}{B} \bigg|_T 
\\
& = \beta \left< \left( \sum_{i = 1}^N \sigma_i \right)^2 \right> - \beta M^2
\end{align*}
Therefore, we have computed that,
\[ \chi = \beta \left( \left< \left( \sum_{i = 1}^N \sigma_i \right)^2 \right> - \left<  \sum_{i = 1}^N \sigma_i \right>^2 \right) = \beta N^2 \sigma^2_{\mu} \]
Where $\sigma_\mu$ is the variance in the mean spin,
\[ \mu =  \frac{1}{N}  \sum_{i = 1}^N \sigma_i \]
and thus,
\[ \sigma_\mu^2 = \left< \left( \frac{1}{N} \sum_{i = 1}^N \sigma_i \right)^2 \right> - \left< \frac{1}{N} \sum_{i = 1}^N \sigma_i  \right>^2 \]
In the limit of independent spins we have,
\[ \sigma_\mu^2 = \frac{\sigma^2}{N} \]
where $\sigma$ is the standard deviation in each spin,
\[ \sigma^2 = \left< \sigma_i^2 \right> - \left< \sigma_i \right>^2 \]
Therefore, we find the susceptibility per spin,
\[ \frac{\chi}{N} = \beta \sigma_{\text{avg}}^2 \]
where we define,
\[ \sigma_{\text{avg}}^2 = N \sigma_\mu^2 \]
\end{example}


\section{Generic Smoothness}

\renewcommand{\A}{\mathbb{A}}

\begin{remark}
For proofs see Tag 01V4.
\end{remark}

\begin{proposition}
A morphism $f : X \to Y$ is smooth iff the following,
\begin{enumerate}
\item $f$ is locally of finite presentation
\item $f$ is flat
\item each fibre $X_y \to \Spec{\kappa(y)}$ is smooth.
\end{enumerate} 
\end{proposition}

\begin{proposition}
Let $f : X \to Y$ be locally of finite presentation. Then $f$ is smooth at $x$ if $\stalk{Y}{y} \to \stalk{X}{x}$ is flat and and the fibre $X_{f(x)} \to \Spec{\kappa(f(x))}$ is smooth at $x$.  
\end{proposition}

\begin{proposition}
The subset of points at which $f : X \to Y$ is smooth is open.
\end{proposition}

\begin{proposition}
$f : X \to Y$ is smooth iff it is smooth at each $x \in X$.
\end{proposition}


\begin{proposition}
Let $f : X  \to Y$ be smooth at $x \in X$ then there exists an open neighborhood $x \in U \subset X$ such that $f : U \to Y$ is smooth.
\end{proposition}

\begin{proposition}
Let $f : X \to Y$ be smooth. Then $f$ is universally open. 
\end{proposition}


\begin{remark}
Given $f : X \to Y$. It is generally false that the set of points, 
\[ V = \{ y \in Y \mid X_y \to \Spec{\kappa(y)} \text{ is smooth } \} \]
is open even for varieties. Consider the following example.
\end{remark}

\begin{example}
Consider $X' = \Spec{k[x,y,z]/(y^2 - x^3)}$ and take the open set,
\[ X = D(x) \cup D(z) \subset X' \]
Consider the map $X' \to \mathbb{A}^1_k$ via $k[z] \to k[x,y,z]/(y^2 - x^3)$ and set $Y = \mathbb{A}^1_k$. This restricts to $f : X \to Y$. Consider the fibers, 
\[ X_p = X \times_Y \Spec{\kappa(p)} \] 
For $p \neq (z)$ we have,
\[ X_p = \Spec{k[x,y]/(y^2 - x^3)} \]
which is not a normal scheme and thus not smooth.
However, for $p = (z)$ we have, 
\[ X_p = \Spec{k[x,y, x^{-1}]/(y^2 - x^3)} \]
which is a smooth scheme because there are isomorphisms,
\[ k[x, y, x^{-1}] / (y^2 - x^3) \xrightarrow{\substack{x \mapsto x \\ y \mapsto xu }} k[x,x^{-1}, u]/(u^2 - x) \xrightarrow{\substack{x \mapsto t^2 \\ u \mapsto t}} k[t, t^{-1}] \]
which gives $x \mapsto t^2$ and $y \mapsto t^3$ with inverse $t \mapsto x^{-1} y$. Therefore,
\[ X_p \cong \Spec{k[t, t^{-1}]} = \mathbb{G}_m^k \] 
which is a smooth scheme. 
Therefore $V \subset Y$ is a single point which is not open. 
\end{example}

\begin{remark}
We wonder if its true for proper maps? Is it true if the generic fibre is smooth?
\end{remark}

\begin{theorem}[EGA-IV-4-12.2.4]
Let $f : X \to Y$ be a proper flat morphism of finite presentation and for some $y \in Y$ the fibre $X_y \to \Spec{\kappa(y)}$ is smooth. Then there exists an open neighborhood $y \in U \subset Y$ such that $f : X_U \to U$ is smooth.   
\end{theorem}

\begin{proof}
Let $S \subset X$ be the singular points of $f : X \to Y$ which is a closed set. Since $f$ is closed then $f(S) \subset Y$ is closed. For each $x \in X_y$ we know that $X_y \to \Spec{\kappa(y)}$ is smooth at $x$ and, by hypothesis, $\stalk{Y}{y} \to \stalk{X}{x}$ is flat so $f$ is smooth at $x$ and thus $x \notin S$. Therefore, $y \notin f(S)$ since $f^{-1}(y) \cap S = \varnothing$ which implies that $U = Y \setminus f(S)$ is an open neighborhood of $y$. Furthermore, $f^{-1}(U) = X \setminus f^{-1}(f(S)) \subset X \setminus S$ contained in the smooth locus of $f : X \to Y$ and thus $f : X_U \to U$ is smooth. 
\end{proof}

\begin{corollary}
Let $f : X \to Y$ be a proper flat morphism of finite presentation. Then,
\[ V = \{ y \in Y \mid X_y \to \Spec{\kappa(y)} \text{ is smooth } \} \]
is open.
\end{corollary}

\begin{corollary}
Let $f : X \to S$ be a proper flat morphism of finite presentation and where $S$ is an integral scheme with generic point $\xi \in S$. Then the following are equivalent,
\begin{enumerate}
\item the genric fibre $X_\xi \to \Spec{\kappa(\xi)}$ is smooth
\item there exists a smooth fibre $X_s \to \Spec{\kappa(s)}$
\item there is a dense open set $U \subset S$ such that $f : X_U \to U$ is smooth. 
\end{enumerate}
\end{corollary}

\begin{corollary}
Let $f : X \to \Spec{\Z}$ be a proper flat morphism of finite presentation. Then the following are equivalent,
\begin{enumerate}
\item the generic fibre $X_\Q \to \Spec{\Q}$ is smooth
\item for some prime $p$ the fibre $X_{p} \to \Spec{\mathbb{F}_p}$ is smooth
\item for all but finitely map primes $p$ the fibre $X_p \to \Spec{\mathbb{F}_p}$ is smooth. 
\end{enumerate}
\end{corollary}

\begin{proof}
This is because any dense open $U \subset \Spec{\Z}$ is cofinite and thus if the equivalent conditions of the above lemma hold then there are at most finitely many singular fibres. 
\end{proof}

\begin{remark}
ARE THESE CONDITIONS NECESSARY?? 
\end{remark}

\begin{example}
Properness is needed for the second property to be equivalent. Take, for example,
\[ X = \Spec{k[x, y, z]/(y(xz - 1))} \to \Spec{k[z]} = \A^1_k \]
Then the fibres over $p = (z - \mu)$ are,
\[ X_p = \Spec{k[x,y]/(y(x\mu - 1))} \to \Spec{k} \]
For $\mu = 0$ this fibre is $X_{0} = \Spec{k[x,y]/(y)} = \Spec{k[x]} = \A^1_k$ is smooth. For $\mu \neq 0$ this fibre is,
\[ X_\mu = \Spec{k[x,y]/(y(x - \mu^{-1})} \]
which is not smooth at $(x,y) = (\mu^{-1},0)$. Therefore, the set of open fibres is not open. However, the generic fibre,
\[ X_\xi = \Spec{k(z)[x,y]/(y(x - z^{-1})} \]
is not smooth at $(x,y) = (z^{-1}, 0)$. Thus 2 holds but both 1 and 3 fail. This is because $X \to \A^1_k$ is not proper. 
\end{example}

\begin{example}
A similar example works arithmetically over $\Spec{\Z}$. Consider, for some prime $p$,
\[ X = \Spec{\Z[x,y]/(y(xp - 1))} \to \Spec{\Z} \]
Then the generic fibre,
\[ X_\Q = \Spec{\Q[x,y]/(y(x - p^{-1}))} \to \Spec{\Q} \]
is not smooth at $(x,y) = (p^{-1}, 0)$. Furthermore, for a prime $q \neq p$ we have,
\[ X_q = \Spec{\mathbb{F}_q[x,y]/(y(x - p^{-1}))} \to \Spec{\mathbb{F}_q} \]
which again is not smooth at $(x, y) = (p^{-1}, 0)$. However, the fibre over $p$ is,
\[ X_p = X \times_\Z \mathbb{F}_p = \Spec{\mathbb{F}_p[x,y]/(y)} = \A^1_{\mathbb{F}_p} \]
is smooth. Therefore, the set of open fibres is not open but the generic fibre is smooth. Thus 2 holds but both 1 and 3 fail. This is because $X \to \Spec{\Z}$ is not proper. 
\end{example}

\begin{example}
We can projectivize the previous example as follows. Consider,
\[ X = \Proj{\Z[X, Y, Z] / (Y(X p - Z))} \to \Spec{\Z} \]
which embedds through a closed immersion $X \embed \P_\Z^2$ to give,
\begin{center}
\begin{tikzcd}
X \arrow[rd] \arrow[r, hook] & \P^2_\Z \arrow[d]
\\
& \Spec{\Z}
\end{tikzcd}
\end{center}
Since $\P^2_\Z \to \Spec{\Z}$ is proper and furhtermore closed immersions are proper then $X \to \Spec{\Z}$ is proper. The above factorization shows that $X$ is H-projective over $\Z$ and thus proper.
\bigskip\\
Now consider the fibres of $X \to \Spec{\Z}$. First, the generic fibre,
\[ X_\Q = \Proj{\Q[X,Y,Z]/(Y(X p - Z))} \to \Spec{\Q} \]
is not smooth at $(X : Y : Z) = (1 : 0 : p)$. Furthermore, for $p \neq q$ then the fibre,
\[ X_q = \Proj{\mathbb{F}_q[X, Y, Z]/(Y(X p - Z))} \to \Spec{\mathbb{F}_q} \]
is again not smooth at $(X : Y : Z) = (1 : 0 : p)$. However, the fibre at $p$,
\[ X_p = \Proj{\mathbb{F}_p[X, Y, Z] / (YZ)} \]
is not smooth at $(X : Y : Z) = (1 : 0 : 0)$. Therefore, the projectivized proper version of the above example does not have the single smooth fibre in accordance with the previous theorem. Geometrically, the fibres are two intersecting (projective) lines. At $p$ one of the lines runs off to the $\P^1_\Z$ at infinity which is why it vanishes in the non-projective case and the fibre degenerates into a single smooth line. On the affine open $D(Z)$ we have,
\[ X_p \cap D(Z) = \Spec{\mathbb{F}_p[x, y]/(y)} = \A^1_{\mathbb{F}_p} \]
However, $X_p \cap V(Z) = V(Z) \cong \P^1_\Z$ is the line at infinity. There is an intersection point which is seen in the affine open $D(X)$,
\[ X_p \cap D(X) = \Spec{\mathbb{F}_p[y, z]/(yx)} \]
which is the union of two lines $\A^1_{\mathbb{F}_p}$. 
\end{example}                                                          

\begin{example}
We can do a similar projectivization to the first example. Consider the space,
\[ \P^2_k \times_k \A^1_k = \P^2_{\A^1_k} = \Proj{k[t][X,Y,Z]} \to \A^1_k \]
where $k = \overline{k}$ and $t$ is given degree zero. Then consider the closed subscheme cut out by the section $Y(X t - Z)$ of $\struct{\P^2}(1)$,
\[ X = \Proj{k[t][X, Y, Z]/(Y(X t - Z))} \embed \P^2_{\A^1_k} \]
Now the map $\P^2_k \times_k \A^1_k \to \A^1_k$ is a base change of $\P^2_\Z \to \Spec{\Z}$ ad thus is proper. Therefore $X \to \P^2_{\A^1_k} \to \A^1_k$ is proper since closed immersions are proper. Also $X \to A^1_k$ is an H-projective map over $\A^1_k$ and thus proper. 
\bigskip\\
Now conisder the fibres of $X \to \A^1_k$. Over the generic point $\xi = (0)$ we have,
\[ X_\xi = \Proj{k(t)[X, Y, Z]/(Y (X  - t^{-1} Z))} \to \Spec{k(t)} \]
which is a plane curve over the field $k(t)$ and singular at $(X : Y : Z) = (1 : 0 : t)$ since in local coordinates on $D(Z)$ we have,
\[ X_\xi \cap D(Z) = \Spec{k(t)[x, y]/(y (x - t^{-1} ))} \]
which is clearly not smooth at the intersection of the divisors cut out by $y$ and $x - t^{-1}$.
\bigskip\\
The other points $p \in \A^1_k$ are $p = (x - \mu)$. For $\mu \neq 0$ we have,
\[ X_\mu = \Proj{k[X, Y, Z]/(Y (X - \mu^{-1} Z))} \to \Spec{k} \]
which is a plane curve over the field $k$ and singular at $(X : Y : Z) = (1 : 0 : \mu)$ since in local coordinates on $D(Z)$ we have,
\[ X_\mu \cap D(Z) = \Spec{k[x, y] / (y (x - \mu^{-1}))} \]
which is clearly not smooth at the intersection of the divisors cut out by $y$ and $x - \mu^{-1}$.
\bigskip\\
Finally, for $\mu = 0$ we have,
\[ X_0 = \Proj{k[X, Y, Z]/(Y Z)} \to \Spec{k} \]
which is a plance curve over the field $k$ and singulr at $(X : Y : Z) = (1 : 0 : 0)$. In the local coordinates on the affine open $D(Z)$ we have,
\[ X_0 = \Spec{k[x, y]/(y)} = \A^1_k \]
which is smooth. However, $X_0$ is singular at infinity. The points at infinity $V(Z)$ intersect,
\[ X_0 \cap V(Z) = V(Z) \cong \P^1_k \]
so $X_0$ is comprised of a union of two lines, one line $Y = 0$ which shows up in the finite affine patch and the line at infinity $Z = 0$ which intersect on the affine open $D(X)$. In those local coodinates,
\[ X_0 \cap D(X) = \Spec{k[y, z]/(yx)} \]
which is a union of two lines crossing transversally since $(x y)$ is a normal crossings divisors. 
\bigskip\\
Thus, we see that the fibres of $X$ everywhere have the same sort of normal crossing singularity between two lines. However, the point of intersection in finite local coordinates $(x, y) = (\mu^{-1}, 0)$ goes off to infinity as $\mu \to 0$ and thus at the special fibre $X_0$ one of these lines becomes the line at infinity so the nonprojectivized version looses its singularity at $\mu = 0$ since the singularity goes to infinity. 
\end{example}

\section{Mysteriously Higher Genus Curves}

\renewcommand{\A}{\mathbb{A}}

Consider the class of affine plane curves,
\[ X_d = \Spec{k[x,y]/(y - x^d)} \]
These are abstractly isomorphic to $\A^1_k$ via,
\[ k[t] \xrightarrow{t \mapsto x} k[x,y]/(y - x^d) \]
with inverse $x \mapsto t$ and $y \mapsto t^d$. However, what is special about these curves is their canonical embedding $X_d \embed \mathbb{A}^2_k$ given by the quotient $k[x,y] \to k[x,y]/(y  - x^d)$. However, what is strange is that these are plane curves cut out by a degree $d$ map and thus ``should'' have genus $g = \tfrac{1}{2} (d-1)(d-2)$ but, on the other hand, abstractly $X_d = \A^1_k$ and since curves are determined by their function fields we ``should'' have $g = 0$. This appears to be a contradiction!
\bigskip\\
To make this precise we should be working with proper curves i.e. the projective completion,
\[ \hat{X}_d = \Proj{k[X,Y,Z]/(Y Z^{d-1} - X^d)} \]
of the curve $X_d$ i.e. the unique closed subscheme $\hat{X}_d \embed \P^2_k$ such that the following diagram commutes,
\begin{center}
\begin{tikzcd}
\hat{X}_d \arrow[r, hook] & \P^2_k
\\
X_d \arrow[r, hook] \arrow[u, hook] & \A^2_k \arrow[u, hook]
\end{tikzcd}
\end{center}  
Now it is certianally true that the arithmetic genus,
\[ g_a = \chi(\hat{X}_d, \struct{\hat{X}_d}) = \tfrac{1}{2} (d-1)(d-2) \]
However, $\hat{X}_d$ is not smooth at infinity for $d > 2$ and thus this curve is not determined by its function field so there is no contradiction. The open set $\hat{X}_d \cap D(Z) = X_d$ so the points at infinity are given by,
\[ \hat{X}_d \cap V(Z) = \Proj{k[X, Y]/(X^d)} \]
Thus there is a single point $(1 : 0 : 0)$. To check the smoothness we use the open set where $X$ does not vanish,
\[ \hat{X}_d \cap D(X) = \Spec{k[y,z] /(y z^{d-1} - 1)} \]



\section{Why Does Tensor Product Distribute over Finite Sums?}

\section{Locally Free Properties over Local Rings}

\begin{remark}
It is well know that if $\phi : M \to M$ is an endomorphism of Noetherian $R$-modules which is surjective then it is injective. However, we can remove the Noetherian hypothesis and only require $M$ to be finitely generated (which does not imply Noetherian unless $R$ is Noetherian). 
\end{remark}

\begin{remark}
The following proposition crucially only holds for \textit{commutative} rings.  
\end{remark}

\begin{theorem}
Let $M$ be a finite $R$-module and $\phi : M \to M$ a surjective endomorphism then $\phi$ is injective.
\end{theorem}

\begin{proof}
We consider $M$ as a $R[X]$-module with $X \cdot m  = f(m)$. Let $I = (X) \subset R[X]$ then $I \cdot M = M$ since $f$ is surjective. Thus, by Nakayama, $\exists P(X) \in I$ such that $(1 - P(X)) \cdot M = 0$. Thus, for all $m \in M$ we have $P(X) \cdot m = m$ i.e. $m = P(f)(m)$ so if $f(m) = 0$ then $m = 0$ since $P(X) \in I$ and thus has no constant terms.
\end{proof}

\begin{lemma}
Let $(R, \m, \kappa)$ be a local ring and $M$ a finite $R$-module with $M \otimes_R \kappa = 0$. Then $M = 0$.
\end{lemma}

\begin{proof}
If $M \otimes_R \kappa = M / \m M = 0$ then $\m M = M$. However, since $R$ is local $\m = \Jac{R}$ and $M$ is finite so by Nakayama, $M = 0$.
\end{proof}

\begin{lemma}
Let $(R, \m, \kappa)$ be a local ring and $\phi : M \to N$ a map of $R$ modules with $N$ finite such that $\phi \otimes \id_\kappa : M \otimes_R \kappa \to N \otimes_R \kappa$ is surjective. Then $\phi$ is surjective.
\end{lemma}

\begin{proof}
Consider the exact sequence,
\begin{center}
\begin{tikzcd}
M \arrow[r, "\phi"] & N \arrow[r] & \coker{\phi} \arrow[r] & 0
\end{tikzcd}
\end{center}
Since $- \otimes_R \kappa$ is right-exact, we get an exact sequence,
\begin{center}
\begin{tikzcd}
M \otimes_R \kappa \arrow[r, "\phi \otimes \id_\kappa"] & N \otimes_R \kappa \arrow[r] & \coker{\phi} \otimes_R \kappa \arrow[r] & 0
\end{tikzcd}
\end{center}
However, $\phi \otimes \id_\kappa$ is surjective so by exactness $\coker{\phi} \otimes_R \kappa = 0$. However, since $N$ is finite so is $\coker{\phi}$ and thus $\coker{\phi} = 0$ by the lemma showing that $\phi$ is surjective.
\end{proof}

\begin{lemma}
Let $(R, \m, \kappa)$ be a local ring. Suppose that $M$ is a finite $R$-module with an endomorphism $\phi : M \to M$ such that $\phi \otimes \id : M \otimes_R \kappa \to M \otimes_R \kappa$ is an isomorphism then $\phi$ is an isomorphism. 
\end{lemma}

\begin{proof}
Consider the exact sequence,
\begin{center}
\begin{tikzcd}
M \arrow[r, "\phi"] & M \arrow[r] & \coker{\phi} \arrow[r] & 0
\end{tikzcd}
\end{center}
and apply the right-exact functor $(-) \otimes_R \kappa$ to get,
\begin{center}
\begin{tikzcd}
M \otimes_R \kappa \arrow[r, "\phi \otimes \id"] & M \otimes_R \kappa \arrow[r] & (\coker{\phi}) \otimes_R \kappa \arrow[r] & 0
\end{tikzcd}
\end{center}
But $\phi \otimes \id$ is an isomorphism and the sequence is exact so $(\coker{\phi}) \otimes_R \kappa = 0$ and thus, by the previous lemma, $\coker{\phi} = 0$ so $\phi$ is surjective. Now we apply the previous theorem to get that $\phi$ is an isomorphism.
\end{proof}

\begin{lemma}
Let $M$ be a finite module over $R$ a local ring then bases of $M \otimes_R \kappa$ lift to generating sets $R^n \onto M$ giving,
\[ \mathrm{rank}(M) = \dim_{\kappa}{(M \otimes_R \kappa)} \]
\end{lemma}

\begin{proof}
If $M$ is generated by $m_1, \dots, m_n$ then $M \otimes_R \kappa = M / \m M$ is generated by $\bar{m}_1, \dots, \bar{m}_n$ over $\kappa = R / \m R$ since surjectivity of $R^n \to M$ is preserved after applying $(-) \otimes_R \kappa$. Thus, $\mathrm{rank}(M) = \dim_{\kappa} M \otimes_{R} \kappa \le n$. 
\bigskip\\
Now suppose that $v_1, \dots, v_n$ is a $\kappa$-basis of $M \otimes_{R} \kappa = M / \m M$ then choose lifts $m_1, \dots, m_n \in M$. I claim that $m_1, \dots, m_n$ generate $M$ as an $R$-module. Let $N \subset M$ be the $R$-submodule generated by the $m_1, \dots, m_n$ and let $K = M / N$. Then I claim that $\m K = K$. To see this it suffices to show that $K \subset \m K$. For any $m \in M$ we know that its image $\bar{m} \in M / \m M$ is in the span of the basis $v_1, \dots, v_n$ so,
\[ \bar{m} = r_1 v_1 + \cdots r_n v_n \]
for $r_i \in R$. Thus,
\[ m - (r_1 m_1 + \cdots r_n m_n) \in \m M \]
This implies that in $K$ we have $m \in \m K$ so $K = \m K$. Then since $\Jac{R} = \m$ (because $R$ is local) by Nakayama $K = 0$ so $M$ is generated by $m_1, \dots, m_n$. 
\end{proof}

\begin{theorem}
Every finite projective module over a local ring is free.
\end{theorem}

\begin{proof}
Let $P$ be a finite projective $R$-module where $(R, \m, \kappa)$ is a local ring. Then there is a surjection $R^n \to P$ which we may assume gives a basis $\kappa^n \xrightarrow{\sim} P \otimes_R \kappa$. We extend to a short exact sequence,
\begin{center}
\begin{tikzcd}
0 \arrow[r] & K \arrow[r] & R^n \arrow[r] & P \arrow[r] & 0
\end{tikzcd}
\end{center}
but $P$ is projective so the sequence splits giving $R^n \cong K \oplus P$ and a surjection $R^n \to K$ making $K$ finitely generated. Since split exact sequences are preserved under additive functors,
\begin{center}
\begin{tikzcd}
0 \arrow[r] & K \otimes_R \kappa \arrow[r] & \kappa^n \arrow[r] & P \otimes_R \kappa \arrow[r] & 0
\end{tikzcd}
\end{center}
but the second map is an isomorphism so $K \otimes_R \kappa = 0$ and $K$ is finite so by the lemma $K = 0$. Thus $R^n \xrightarrow{\sim} P$ is an isomorphism so $P$ is free.
\end{proof}

\begin{lemma}
Let $P$ be a projective $R$-module and $S \subset R$ a multiplicative subset. Then $S^{-1} P$ is a projective $S^{-1} R$-module.
\end{lemma}

\begin{proof}
Let $M, N$ be $S^{-1} R$-modules and consider a diagram in the category of $R$-modules,
\begin{center}
\begin{tikzcd}
& & M \arrow[d, two heads]
\\
P \arrow[r] \arrow[rru, dashed, "\phi"] & S^{-1} P \arrow[ru, dashed, "\tilde{\phi}"'] \arrow[r] & N
\end{tikzcd}
\end{center}
then $P \to N$ lifts to $\phi : P \to M$ since $P$ is projective. Now we define $\tilde{\phi} : S^{-1} P \to M$ via $\tilde{\phi}(x \otimes r/s) = (r/s) \cdot \phi(x)$ using the decomposition $S^{-1} P = P \otimes_R S^{-1} R$. This makes the diagram commute. 
\end{proof}

\begin{remark}
We can also use the fact that (See Tag 05G3),
\[ \Hom{S^{-1} R}{S^{-1} P}{-} = \Hom{S^{-1} R}{P \otimes_R S^{-1} R}{-} = \Hom{R}{P}{\mathrm{Res}^{S^{-1} R}_{R} (-)} \]
and that projectiveity of $P$ is equivalent to $\Hom{R}{P}{\mathrm{Res}^{S^{-1} R}_{R} (-)}$ being exact showing that $S^{-1} P$ is $S^{-1} R$-projective.
\end{remark}

\begin{lemma}
Let $M$ be a finitely-presented $R$-module such that $M_\p$ is a free $R_\p$-module at each prime $\p \in \Spec{R}$. Then $M$ is a localy free $R$-module.
\end{lemma}

\begin{proof}
Take a prime $\p \in \Spec{R}$ then $M_\p$ is a finite free $R_\p$-module say $M_\p \cong R_\p^n$. Lift the basis to give a map $R^n \to M$ and an exact sequence,
\begin{center}
\begin{tikzcd}
0 \arrow[r] & C \arrow[r] & R^n \arrow[r] & M \arrow[r] & K \arrow[r] & 0
\end{tikzcd}
\end{center}
Since $M$ is finitely-presented, both $K$ and $C$ are finitely generated. Futhermore, localizing at $\p$ gives,
\begin{center}
\begin{tikzcd}
0 \arrow[r] & C_\p \arrow[r] & R^n_\p \arrow[r] & M_\p \arrow[r] & K_\p \arrow[r] & 0
\end{tikzcd}
\end{center}
but $R^n_\p \to M_\p$ is an isomorphism so $C_\p = 0$ and $K_\p = 0$. Since they are finitely generated, there is an element $f \notin \p$ killing both generating sets and thus $C_f = 0$ and $K_f = 0$. Therefore, 
\begin{center}
\begin{tikzcd}
0 \arrow[r] & C_f \arrow[r] & R^n_f \arrow[r] & M_f \arrow[r] & K_f \arrow[r] & 0
\end{tikzcd}
\end{center}
is exact so $R^n_f \xrightarrow{\sim} M_f$ is an isomorphism so $M$ is free on $D(f) \subset \Spec{R}$ for $\p \in D(f)$ so $M$ is locally free.
\end{proof}

\begin{theorem}
Let $R$ be a ring. Then finite projective $R$-modules are exactly the finite locally free $R$-modules. 
\end{theorem}

\begin{proof}
If $P$ is finite projective then $P_\p$ is finite projective over $R_\p$ and thus free. Furthermore, $P$ is finitely presented because there is an exact sequence,
\begin{center}
\begin{tikzcd}
0 \arrow[r] & K \arrow[r] & R^n \arrow[r] & P \arrow[r] & 0
\end{tikzcd}
\end{center}
which splits $R^n \cong K \oplus P$ since $P$ is projective giving a surjection $R^n \to K$ thus showing that $K$ is finite and giving a finite presentation,
\begin{center}
\begin{tikzcd}
R^n \arrow[r] & R^n \arrow[r] & P \arrow[r] & 0
\end{tikzcd}
\end{center}
Therefore, by the previous lemma, $P$ is locally free. 
\bigskip\\
Conversely, if $P$ is locally free so there exists a finite ($\Spec{R}$ is quasi-compact) open cover $D(f_i)$ of $\Spec{R}$ such that $P_{f_i} \cong R_{f_i}^n$. Then we need to show that $\Hom{R}{P}{-}$ is exact. We use that $\Hom{R}{P}{-}_{f_i} = \Hom{R_{f_i}}{P_{f_i}}{(-)_{f_i}}$ which is exact since $P_{f_i}$ is free and localization $(-)_{f_i}$ is an exact functor. Then $\Hom{R}{P}{-}$ is exact since we can check exactness of the hom sequence locally. 
\end{proof}

\begin{remark}
Look at Tag 00NV for more detailed version.
\end{remark}

\subsection{Why Does This Only Work on Affine Schemes?}

\begin{lemma}
Let $\L$ be a finite locally free $\struct{X}$-module. Then, $\L$ is flat meaning the functor $- \otimes_{\struct{X}} \L$ is exact and likewise,
\[ \shHom{\struct{X}}{\L}{-} = - \otimes_{\struct{X}} \L^\vee \quad \quad \shHom{\struct{X}}{-}{\L} = (-)^\vee \otimes_{\struct{X}} \L \]
are exact. 
\end{lemma}

\begin{proof}
(DO THIS) 
\end{proof}

\begin{remark}
From the above it might appear that finite locally free $\struct{X}$-modules $\L$ are projective and injective in the category of coherent sheaves. However, this is not the case. For $\L$ to be projective we must have $\Hom{\struct{X}}{\L}{-} = H^0(X, \shHom{\struct{X}}{\L}{-})$ exact and while $\shHom{\struct{X}}{\L}{-}$ is exact, the global sections functor $H^0(X, -)$ will not generically be exact unless $X$ is affine. Likewise although $\shHom{\struct{X}}{-}{\L}$ is exact (not just left-exact) generically $\Hom{\struct{X}}{-}{\L} = H^0(X, \shHom{\struct{X}}{-}{\L})$ is only left-exact unless $X$ is affine.
\end{remark}

\begin{remark}
Now we consider the converse to these claims.
\end{remark}

(If flat and exact on sheaf hom and coheret then finite locally free?)

(If coherent cohomology vanishes then affine TAG 01XE )

\section{Stuff With Affines}

\begin{proposition}
Let $X$ be a scheme and $P$ a property of affine opens of $X$. Suppose that,
\begin{enumerate}
\item there is an affine open cover $\{ U_i \}$ of $X$ with $P(U_i)$
\item for each affine open $U \subset X$ if $P(U)$ then for any $f \in \struct{X}(U)$ we have $P(D_U(f))$.
\item for any affine open $U \subset X$ and $f_1, \dots, f_n \in \struct{X}(U)$ generating the unit ideal and $P(D_U(f_i))$ then $P(U)$.
\end{enumerate}
Then $P(U)$ holds for all affine opens $U \subset X$.
\end{proposition}

\begin{proof}
Let $U \subset X$ be an affine open. It suffices to show that for each $x \in U$ there is an $f \in \struct{X}(U)$ s.t. $P(D_U(f))$ and $x \in D_U(f)$. We know $x \in U_i$ for some $i$. Pick $f_i \in \struct{X}(U_i)$ s.t. $x \in D_{U_i}(f_i) \subset U \cap U_i$ and pick $f \in \struct{X}(U)$ s.t. $x \in D_U(f) \subset D_{U_i}(f_i)$. Then $P(U_i)$ and $P(U_i) \implies P(D_{U_i}(f_i)) \implies P(D_U(f))$. because
\[ D_U(f) = D_{D_{U_i}(f_i)}(f|_{D_{U_i}(f_i)}) \]
and thus $P(D_U(f))$. 
\end{proof}

\section{Quasi-Coherent Modules}

\renewcommand{\Mod}[1]{\mathbf{Mod}_{#1}}

\begin{proposition}
Let $X = \Spec{R}$ be affine. The functor $M \mapsto \widetilde{M}$ is the left adjoint to the functor $\F \mapsto \Gamma(X, \F)$.  
\end{proposition}

\begin{proof}
Given an $R$-module map $M \to F(X)$ and $f \in R$ then there is a unique arrow in the following, diagram,
\begin{center}
\begin{tikzcd}
M \arrow[r] \arrow[d] & \F(X) \arrow[d]
\\
M_f \arrow[r, dashed] & \F(D(f))
\end{tikzcd}
\end{center}
such that $\struct{X}$-module maps $\widetilde{M} \to \F$ are uniquely determined by $R$-module maps $M \to \F(X)$.
\end{proof}

\begin{lemma}
Let $f : X \to Y$ be the morphism of affine schemes corresponding to the ring map $\varphi : B \to A$ then,
\begin{enumerate}
\item $f^*(\widetilde{N}) = \widetilde{N \otimes_B A}$ for $N \in \Mod{B}$
\item $f_*(\widetilde{M}) = \widetilde{M_B}$ for $M \in \Mod{A}$. 
\end{enumerate}
\end{lemma}

\begin{proof}
By the adjointness of these functors, it suffices to prove the second and use the fact that these functors are adjoint at the level of modules. Then consider,
\begin{align*}
f_*(\widetilde{M})(D_Y(g)) & = \widetilde{M}(f^{-1}(D(g)) = \widetilde{M}(D_X(\varphi(g))) 
\\
& = M_{\varphi(g)} = (M_B)_g 
\\
& = \widetilde{M_B}(D_X(g))
\end{align*}
\end{proof}

\begin{remark}
In particular, $\widetilde{M}|_{D(f)} = \widetilde{M_f}$ of $D(f) = \Spec{A_f}$. 
\end{remark}

\begin{lemma}
Consider $\F \in \Mod{\struct{X}}$ and $X = \Spec{A}$ is $\widetilde{M}$ for some $M$ iff $\forall f \in A$ the map $\F(X)_f \to \F(D(f))$ is an isomorphism. 
\end{lemma}

\begin{definition}
Let $X$ be a scheme. An $\struct{X}$-module $\F$ is \textit{quasi-coherent} if one of the following equivalent conditions holds,
\begin{enumerate}
\item there is an affine open cover $U_i$ of $X$ such that $\F|_{U_i} \cong \widetilde{M_i}$ for some $\struct{X}(U_i)$-module $\widetilde{M_i}$
\item for each affine open $U \subset X$ we have $\F|_U \cong \widetilde{M}$ for some $\struct{U}$-module $M$. 
\end{enumerate}
\end{definition}

\begin{proof}
Clearly 1. implies 2. To prove the converse we use the lemma on local properties. We have assumed the first property and the above remark shows that localization inherts the property of quasi-coherence. Finally, it suffices to show that if $X$ is affine and $\F \in \Mod{\struct{X}}$ and $X = D(f_1) \cup \cdots \cup D(f_n)$ with $\F|_{D(f_i)} \cong \widetilde{M_i}$ then $\F \cong \widetilde{M}$. We use the previous lemma to reduce this problem to the following lemma. 
\end{proof}

\begin{lemma}
Let $X$ have a finite affine covering $U_i$ with $U_i \cap U_j$ quasi-compact. Let $\F \in \Mod{\struct{X}}$ s.t. $\F |_{U_i} = \widetilde{M_i}$ let $f \in \struct{X}(X)$. Then the canonical map,
\[ \F(X)_f \to \F(X_f) \]
is an isomorphism. 
\end{lemma}

\begin{definition}
A scheme $X$ is \textit{quasi-compact} if every open cover has a finite subcover i.e. it is compact as a topological space.
\end{definition}

\begin{definition}
A scheme $X$ is \textit{quasi-seperated} if one of the following equivalent conditions holds,
\begin{enumerate}
\item for all affine opens $U, V \subset X$ then $U \cap V$ is quasi-compact
\item for all quasi-compact opens $U, V \subset X$ then $U \cap V$ is quasi-compact
\item The diagonal morphism $\Delta : X \to X \times_S X$ is quasi-compact. 
\end{enumerate}
\end{definition}

\begin{lemma}
Let $X$ be quasi-compact and quasi-separated and $\F$ a $\struct{X}$-module. Then $\F$ is a quasi-coherent iff the map $\F(X)_f \to \F(X_f)$ is an isomorphism for each $f \in \struct{X}(X)$. 
\end{lemma}

\begin{definition}
A morphism $f : X \to Y$ of schemes is quasi-compact if one of the following equivalent properties holds,
\begin{enumerate}
\item for every quasi-compact ope $V \subset Y$ then $f^{-1}(V)$ is quasi-compact
\item for every affine open $V \subset Y$ then $f^{-1}(V)$ is quasi-compact
\item there is an affine open $V_i$ cover of $Y$ s.t. $f^{-1}(V_i)$ is quasi-compact. 
\end{enumerate}
\end{definition}

\begin{definition}
A morphism $f : X \to Y$ of schemes is quasi-separated if one of the following equivalent properties holds,
\begin{enumerate}
\item for every affine open $V \subset Y$ then $f^{-1}(V)$ is quasi-separated
\item there is an affine open $V_i$ cover of $Y$ s.t. $f^{-1}(V_i)$ is quasi-separated
\item the diagonal map $X \to X \times_Y X$ is quasi-compact. 
\end{enumerate}
\end{definition}

\begin{corollary}
Let $f : X \to Y$ be a quasi-compact, quasi-seperated morphism of schemes. Then $f_*$ sends quasi-coherent modules to quasi-coherent modules.
\end{corollary}

\begin{example}
Consider $U = \R \setminus \{ 0 \}$ and $X = \R$ and the inclusion $j : U \to X$. Then take $\F = j_{!}(\underline{\Z}_U) \in \Mod{\underline{\Z}_X}$. However, $\F_0 = 0$ but $\F_x = \Z$ for any $x \neq 0$ arbitaritly small so $\F$ cannot be quasi-coherent because $\F(V) = 0$ for any connected neighborhood $V$ of zero meaning that the module would have to be zero contradicting the fact that some stalks are nonzero in any neighbrohood of $0$. 
\end{example}


\section{Homotopy and Category of Vector Bundles}

\newcommand{\Vect}[1]{\mathbf{Vect}\left(#1 \right)}

\begin{theorem}
Let $X, Y$ be paracompact. A homotopy between $f_1, f_2 : X \to Y$ induces a natural isomorphism between $f_1^*, f_2^* : \Vect{Y} \to \Vect{X}$. 
\end{theorem}

\begin{proof}
Hatcher Vector Bundles 1.6.
\end{proof}

\begin{corollary}
A homotopy equivalence $f : X \to Y$ between paracompact spaces induces an equivalence of categories $f^* : \Vect{Y} \to \Vect{X}$. 
\end{corollary}

\begin{corollary}
If $X$ is paracompact and contractible then $K_0(X) = \Z$. 
\end{corollary}

\section{Remark on Sheaves Associated to Modules}

On an affine scheme $X = \Spec{A}$ we can assign a quasi-coherent sheaf of $\struct{X}$-modules $\widetilde{M}$ to an $A$-module $M$ via $\widetilde{M}(D(f)) = M_f$. We can describe this process canonically as follows. Let 


\section{Thoughts on Subschemes cut out by sections of Line Bundles and More Generally by Coherent Sheaves}

\begin{example}
Consider $X = \Spec{k[x, y] / (y(y - x^2))} \embed \A^2$. This is reduced 
\end{example}


\section{Coherent Sheaves Are Generated By Twists of Ample Sheaf}

\newcommand{\E}{\mathcal{E}}
\renewcommand{\L}{\mathcal{L}}

\begin{theorem}
Let $X$ be a Noetherian scheme and $\L$ an ample line bundle on $X$. Any coherent sheaf $\F$ on $X$ is a quotient of some vector bundle of the form,
\[ \E = \bigoplus_{i = 1}^r \L^{\otimes -n} \]
for any sufficently large positive integers $r, n \in \Z_{+}$ i.e. for any $r \ge r_0$ and $n \ge n_0$ with $r_0$ and $n_0$ depending on $\F, \L, X$. 
\end{theorem}

\begin{proof}
Since $\L$ is ample there exists an $n_0$ (depending on $\F$) such that for all $n \ge n_0$ the coherent sheaf $\F \otimes_{\struct{X}} \L^{\otimes n}$ is generated by global sections. Therefore there is a surjection,
\begin{center}
\begin{tikzcd}
\bigoplus\limits_{i = 1}^{r_0} \struct{X} \arrow[r] & \F \otimes_{\struct{X}} \L^{\otimes n} \arrow[r] & 0
\end{tikzcd}
\end{center}
Using the invertibilty of $\L$ to tensor by $\L^{\otimes - n}$ we get a surjection,
\begin{center}
\begin{tikzcd}
\bigoplus\limits_{i = 1}^{r_0} \L^{\otimes -n} \arrow[r] & \F \arrow[r] & 0
\end{tikzcd}
\end{center}
and thus $\F$ is a quotient by the vector bundle,
\[ \E = \bigoplus_{i = 1}^r \L^{\otimes -n} \]
for any $r \ge r_0$ and $n \ge n_0$. 
\end{proof}

\section{Regular Rings and Schemes}

\begin{example}
Consider $X = \Spec{k[x]/(x^2)}$. Then consider the unique point $p = (x)$ and $\stalk{X}{p} = (k[x]/(x^2))_{(x)}$. Then $\m_p = (x)$ and thus we have,
\[ \m_p / \m_p^2 = \m_p = k x \]
so $\dim_k \m_p / \m_p^2 = 1$ but $\dim{\stalk{X}{p}} = 0$. 
\end{example}


\section{Picard Groups of Models}

(WORK ON THIS TODAY)

\begin{lemma}[0C63]
There is an exact sequence,
\begin{center}
\begin{tikzcd}
0 \arrow[r] & \Z \arrow[r] & \Z^{\oplus n} \arrow[r] & \Pic{X} \arrow[r] & \Pic{C} \arrow[r] & 0
\end{tikzcd}
\end{center}
sending $1 \mapsto (m_1, \dots, m_n)$ and $e_i \mapsto \struct{X}(C_i)$ 
\end{lemma}

\section{Neron Model}

\begin{definition}
Let $R$ be a Dedekind domain and $K$ its field of fractions such that $\Spec{K} \to \Spec{R}$ is the inclusion of the generic point. Then given a $K$-scheme $X_K$ we say a \textit{model} of $X_K$ over $R$ is an $R$-scheme $f : X \to \Spec{R}$ such that the generic fiber $X \times_R K$ of the structure map $f$ is $K$-isomorphic to $X_K$. 
\end{definition}

\begin{definition}
Let $A$ be a smooth separated scheme of finite type over $K$
A Neron model of $A_K$ over $R$ is a model $A$ over $R$ such that for any smooth separated $R$-scheme $X$ we have the following extension property, given a $K$-map $f : X_K \to A_K$ there is a unique extension to $\phi : X \to A_R$ such that $f = \phi \times_R K$.  
\begin{center}
\begin{tikzcd}
X_K \arrow[r] \arrow[d] & A_K \arrow[d]
\\
X \arrow[r, dashed, "\exists !"] & A_R
\end{tikzcd}
\end{center}
In particular, take $X = \Spec{R}$ then $X_K = \Spec{K}$ so the $K$-points of $A_K$ give unique $R$-points of $A_R$. Thus $A_K(K) \to A_R(R)$ is an isomorphism since any $R$-point of $A_R$ base changes to a $K$-point of $A_K = A_R \times_R K$ 
\end{definition}


\section{Automorphisms}

\begin{remark}
Recall that the automorphism group of the $n$-torus $\Aut{\Gm{k}^n}$ is exactly $k^\times \times \GL{n}{\Z}$ with the following action on coordinate ring $k[x_1^{\pm 1}, \dots, x_n^{\pm 1}]$,
\begin{equation}
(r,  A) \cdot x_j = r \prod_{i = 1}^n x_i^{a_{ij}} \quad \text{ where } \quad r \in k^\times \quad \text{ and } \quad A = (a_{ij}) \in \GL{n}{\Z} 
\end{equation}
Note that if we restrict to automorphism of the torus \text{as a group scheme} then $\Aut{\Gm{k}^n} = \GL{n}{\Z}$ setting $r = 1$ and thus preserving the identity. 
\end{remark}

\end{document}


